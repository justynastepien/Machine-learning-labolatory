{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03bfb3d4-fcab-476c-aa67-c229474ac14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d185f371-5134-4e11-a2f7-e1081cc7d416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2cd7634-4627-470a-900f-38f1f059b185",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden = 1, n_neurons = 25, optimizer = \"sgd\", learning_rate = 10e-5, momentum=0.5):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    \n",
    "    \n",
    "    \n",
    "    model.add(tf.keras.layers.InputLayer(input_shape=[13]))\n",
    "    for l in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation = \"relu\"))\n",
    "    \n",
    "    \n",
    "    if optimizer == \"sgd\":\n",
    "        op = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    \n",
    "    if optimizer == \"adam\":\n",
    "        op = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    if optimizer == \"nesterov\":\n",
    "        op = tf.keras.optimizers.SGD(learning_rate=learning_rate, nesterov=True)\n",
    "    if optimizer == \"momentum\":\n",
    "        op = tf.keras.optimizers.SGD(learning_rate=learning_rate, momentum = momentum)\n",
    "        \n",
    "    model.compile(loss=\"mse\", optimizer = op, metrics=[\"mae\"])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c39aa90-b3e5-407c-aff1-e67634ec2aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(patience = 10, min_delta = 1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f36324fc-92c0-42c9-9ba0-bc53da0b25ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
    "\n",
    "def get_run_logdir(name = \"n\", value=10):\n",
    "    ts=str(int(time.time()))\n",
    "    \n",
    "    run_id = ts+'_'+name+'_'+str(value)\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "#przeniesc\n",
    "run_logdir = get_run_logdir()\n",
    "\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5962e29-c392-45ab-91ae-985c410c6d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee70ab41-3a9a-4ea1-b046-bdc5aba9e88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"tb_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1474e26-c97a-4d54-ac32-c70fccccade8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a50cdf8-5d78-494d-ac8b-4768d9a7d5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 2070.7725 - mae: 31.1883 - val_loss: 458.3864 - val_mae: 18.1965\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 415.4597 - mae: 17.1667 - val_loss: 406.8241 - val_mae: 17.0098\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 374.0133 - mae: 16.2577 - val_loss: 395.0214 - val_mae: 16.6166\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 355.4528 - mae: 15.7418 - val_loss: 369.1909 - val_mae: 15.9220\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 338.1293 - mae: 15.2848 - val_loss: 355.2568 - val_mae: 15.5040\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 323.2975 - mae: 14.8344 - val_loss: 340.8492 - val_mae: 15.0595\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 311.4189 - mae: 14.4798 - val_loss: 328.3026 - val_mae: 14.6639\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 302.8844 - mae: 14.1919 - val_loss: 320.0667 - val_mae: 14.4464\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 296.3427 - mae: 13.9950 - val_loss: 316.0519 - val_mae: 14.2541\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 291.4673 - mae: 13.8086 - val_loss: 315.8218 - val_mae: 14.1997\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 288.4292 - mae: 13.6941 - val_loss: 308.0820 - val_mae: 13.9683\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 284.7020 - mae: 13.5882 - val_loss: 304.0510 - val_mae: 13.8344\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 282.0377 - mae: 13.5152 - val_loss: 301.2444 - val_mae: 13.7893\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 279.4427 - mae: 13.4375 - val_loss: 304.4216 - val_mae: 13.7938\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 278.4862 - mae: 13.3456 - val_loss: 296.7016 - val_mae: 13.6487\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 276.1182 - mae: 13.3470 - val_loss: 296.7875 - val_mae: 13.6213\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 274.6514 - mae: 13.2677 - val_loss: 296.5944 - val_mae: 13.5912\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 273.8737 - mae: 13.2516 - val_loss: 298.6688 - val_mae: 13.5462\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 273.2223 - mae: 13.1940 - val_loss: 292.6433 - val_mae: 13.5235\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 271.0215 - mae: 13.1526 - val_loss: 289.2918 - val_mae: 13.4860\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 270.8093 - mae: 13.1817 - val_loss: 290.8796 - val_mae: 13.5698\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 270.6491 - mae: 13.1825 - val_loss: 286.8352 - val_mae: 13.5251\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 268.9593 - mae: 13.1954 - val_loss: 288.0096 - val_mae: 13.3287\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 267.1906 - mae: 13.0549 - val_loss: 292.7831 - val_mae: 13.4442\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 266.8635 - mae: 13.0034 - val_loss: 285.5043 - val_mae: 13.2269\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 266.0464 - mae: 13.0198 - val_loss: 284.4331 - val_mae: 13.2732\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 265.0855 - mae: 12.9951 - val_loss: 286.3479 - val_mae: 13.3368\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 264.3313 - mae: 12.9740 - val_loss: 283.0195 - val_mae: 13.2393\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 263.4225 - mae: 12.9398 - val_loss: 283.4377 - val_mae: 13.4040\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 263.6836 - mae: 13.0282 - val_loss: 280.2187 - val_mae: 13.2102\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 262.2317 - mae: 12.9202 - val_loss: 282.3080 - val_mae: 13.1233\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 261.2250 - mae: 12.8391 - val_loss: 285.2001 - val_mae: 13.1267\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 260.8608 - mae: 12.7918 - val_loss: 280.4486 - val_mae: 13.0119\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 259.8859 - mae: 12.7867 - val_loss: 280.4926 - val_mae: 13.0530\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 259.6124 - mae: 12.7998 - val_loss: 281.4891 - val_mae: 13.0722\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 259.4372 - mae: 12.7731 - val_loss: 277.6889 - val_mae: 13.0099\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 257.8658 - mae: 12.7231 - val_loss: 277.4146 - val_mae: 13.0392\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 257.6168 - mae: 12.7590 - val_loss: 279.5782 - val_mae: 13.0294\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 257.0337 - mae: 12.7222 - val_loss: 277.8728 - val_mae: 12.9775\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 256.2028 - mae: 12.6871 - val_loss: 275.7339 - val_mae: 12.8826\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 256.0040 - mae: 12.6767 - val_loss: 276.7054 - val_mae: 12.8803\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 255.2473 - mae: 12.6278 - val_loss: 277.9708 - val_mae: 12.8737\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 254.8875 - mae: 12.6040 - val_loss: 273.9666 - val_mae: 12.8930\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 254.4031 - mae: 12.6189 - val_loss: 278.7374 - val_mae: 12.9293\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 254.3354 - mae: 12.5946 - val_loss: 274.3376 - val_mae: 12.8358\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 253.5315 - mae: 12.5864 - val_loss: 276.2646 - val_mae: 12.7970\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 253.2650 - mae: 12.5187 - val_loss: 273.2598 - val_mae: 12.9435\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 253.1416 - mae: 12.5999 - val_loss: 274.4019 - val_mae: 12.9739\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 252.7155 - mae: 12.5975 - val_loss: 271.4681 - val_mae: 12.7160\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 251.3988 - mae: 12.4892 - val_loss: 273.4471 - val_mae: 13.0959\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 252.4758 - mae: 12.6342 - val_loss: 273.0914 - val_mae: 12.7831\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 250.5071 - mae: 12.4567 - val_loss: 276.2233 - val_mae: 12.8585\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 250.4798 - mae: 12.4373 - val_loss: 271.7982 - val_mae: 12.7599\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 249.5791 - mae: 12.4154 - val_loss: 269.9344 - val_mae: 12.7774\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 249.8669 - mae: 12.4725 - val_loss: 271.9619 - val_mae: 12.6902\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.8171 - mae: 12.3702 - val_loss: 272.2995 - val_mae: 12.6767\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.7011 - mae: 12.3661 - val_loss: 269.2050 - val_mae: 12.6579\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 247.8915 - mae: 12.3808 - val_loss: 269.5459 - val_mae: 12.6257\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 247.6099 - mae: 12.3441 - val_loss: 267.5569 - val_mae: 12.6684\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 247.4582 - mae: 12.3844 - val_loss: 269.0775 - val_mae: 12.6228\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 246.9947 - mae: 12.3323 - val_loss: 267.7731 - val_mae: 12.6402\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 246.4690 - mae: 12.3292 - val_loss: 268.9728 - val_mae: 12.5979\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 246.0033 - mae: 12.2938 - val_loss: 267.1656 - val_mae: 12.6209\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 245.4359 - mae: 12.2919 - val_loss: 267.7693 - val_mae: 12.5487\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 245.1370 - mae: 12.2509 - val_loss: 266.2822 - val_mae: 12.6280\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 244.8336 - mae: 12.2666 - val_loss: 266.5356 - val_mae: 12.5925\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 244.3327 - mae: 12.2365 - val_loss: 265.2914 - val_mae: 12.5126\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 244.2276 - mae: 12.2458 - val_loss: 268.8485 - val_mae: 12.5278\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 243.7420 - mae: 12.1778 - val_loss: 267.7164 - val_mae: 12.5218\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 243.2886 - mae: 12.1737 - val_loss: 265.4034 - val_mae: 12.5129\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 242.5961 - mae: 12.1582 - val_loss: 263.4049 - val_mae: 12.4758\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 242.4768 - mae: 12.1927 - val_loss: 265.5264 - val_mae: 12.5167\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 242.1176 - mae: 12.1465 - val_loss: 263.9765 - val_mae: 12.4157\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 242.0014 - mae: 12.1061 - val_loss: 262.7408 - val_mae: 12.4529\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 241.3966 - mae: 12.1553 - val_loss: 264.5437 - val_mae: 12.3798\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 241.0333 - mae: 12.0883 - val_loss: 264.8881 - val_mae: 12.3497\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 240.6202 - mae: 12.0334 - val_loss: 262.0837 - val_mae: 12.3790\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 240.5297 - mae: 12.0979 - val_loss: 262.5515 - val_mae: 12.4119\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 240.3999 - mae: 12.0845 - val_loss: 262.7717 - val_mae: 12.3322\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 239.6167 - mae: 12.0283 - val_loss: 261.6458 - val_mae: 12.3779\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 239.2373 - mae: 12.0504 - val_loss: 261.1039 - val_mae: 12.5213\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 239.2403 - mae: 12.1196 - val_loss: 263.4942 - val_mae: 12.3013\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 238.6897 - mae: 11.9804 - val_loss: 263.3775 - val_mae: 12.3542\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 238.3893 - mae: 11.9862 - val_loss: 264.8113 - val_mae: 12.3467\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 238.3407 - mae: 11.9563 - val_loss: 260.2930 - val_mae: 12.2964\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 237.4916 - mae: 11.9528 - val_loss: 261.1095 - val_mae: 12.3217\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 237.3995 - mae: 11.9470 - val_loss: 260.5178 - val_mae: 12.2817\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 237.1823 - mae: 11.9403 - val_loss: 259.8220 - val_mae: 12.2650\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 236.3589 - mae: 11.9160 - val_loss: 261.3484 - val_mae: 12.2675\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 236.3423 - mae: 11.9006 - val_loss: 259.7007 - val_mae: 12.1906\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 235.8105 - mae: 11.8769 - val_loss: 258.8487 - val_mae: 12.2506\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 235.6717 - mae: 11.8988 - val_loss: 257.3831 - val_mae: 12.1907\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 235.3411 - mae: 11.8835 - val_loss: 259.2077 - val_mae: 12.1820\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 234.8921 - mae: 11.8437 - val_loss: 255.8215 - val_mae: 12.2505\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 234.6170 - mae: 11.9190 - val_loss: 264.7337 - val_mae: 12.2843\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 235.6109 - mae: 11.8244 - val_loss: 256.9472 - val_mae: 12.1268\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 233.9435 - mae: 11.8183 - val_loss: 255.6319 - val_mae: 12.1851\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 233.4818 - mae: 11.8410 - val_loss: 257.7550 - val_mae: 12.1536\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 233.2988 - mae: 11.7902 - val_loss: 258.4957 - val_mae: 12.1344\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 233.0114 - mae: 11.7572 - val_loss: 261.6113 - val_mae: 12.2499\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1310.5674 - mae: 24.5500 - val_loss: 621.8439 - val_mae: 22.5655\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 503.7111 - mae: 20.1219 - val_loss: 566.2386 - val_mae: 21.5612\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 485.8787 - mae: 19.6210 - val_loss: 554.2220 - val_mae: 21.1516\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 468.2612 - mae: 19.0736 - val_loss: 530.7058 - val_mae: 20.4974\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 464.9243 - mae: 18.9672 - val_loss: 548.4066 - val_mae: 21.0541\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 462.6477 - mae: 18.8851 - val_loss: 564.0413 - val_mae: 21.5356\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 464.9135 - mae: 18.9687 - val_loss: 546.9935 - val_mae: 21.1085\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 465.4724 - mae: 18.9346 - val_loss: 517.6007 - val_mae: 20.3483\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 455.5221 - mae: 18.6651 - val_loss: 518.8406 - val_mae: 20.3228\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 456.9557 - mae: 18.7312 - val_loss: 524.4442 - val_mae: 20.3677\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 453.5202 - mae: 18.5666 - val_loss: 522.6474 - val_mae: 20.3401\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.6086 - mae: 18.8926 - val_loss: 534.9924 - val_mae: 20.6587\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 452.0529 - mae: 18.5532 - val_loss: 501.0381 - val_mae: 19.5755\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 449.4356 - mae: 18.4565 - val_loss: 564.3410 - val_mae: 21.5619\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.9031 - mae: 18.8088 - val_loss: 530.1591 - val_mae: 20.5822\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 462.6431 - mae: 18.9037 - val_loss: 504.6439 - val_mae: 19.6990\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.8774 - mae: 18.8132 - val_loss: 509.1048 - val_mae: 19.9273\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.6153 - mae: 18.8189 - val_loss: 635.0413 - val_mae: 23.0372\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 506.3010 - mae: 20.0967 - val_loss: 532.8376 - val_mae: 20.3313\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 474.0590 - mae: 19.1928 - val_loss: 539.1672 - val_mae: 20.7422\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 469.8656 - mae: 19.0789 - val_loss: 553.4017 - val_mae: 21.2109\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 470.8587 - mae: 19.1449 - val_loss: 547.1567 - val_mae: 21.1099\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 474.1538 - mae: 19.2478 - val_loss: 529.7903 - val_mae: 20.5351\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 924.9104 - mae: 23.8064 - val_loss: 643.5601 - val_mae: 23.6433\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 571.6806 - mae: 22.0770 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7463 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "lista_lr = []\n",
    "for v in [10e-6, 10e-5, 10e-4]:\n",
    "    model = build_model(learning_rate = v)\n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_split = (0.2), callbacks = [es,tensorboard_cb])\n",
    "    \n",
    "    loss = model.history.history.get('loss')\n",
    "    loss.reverse()\n",
    "    loss[0]\n",
    "    \n",
    "    mae = model.history.history.get('mae')\n",
    "    mae.reverse()\n",
    "    mae[0]\n",
    "    lista_lr.append((v, loss[0], mae[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0049fecb-95fd-4d43-9e2a-8c0174ff9a31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1e-05, 233.0113983154297, 11.757220268249512),\n",
       " (0.0001, 474.1538391113281, 19.247846603393555),\n",
       " (0.001, 571.7462158203125, 22.081424713134766)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a5042dd-bc7a-49f0-a261-9263bd07e3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = open(\"lr.pkl\", \"wb\")\n",
    "pickle.dump(lista_lr, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba200e-6baa-4ce7-b914-06122e747485",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48019a7e-ddbb-4723-b274-1e68be8f76e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69733a65-48e5-4387-b032-2c12691a686b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 23335.2656 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2656 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2676 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2656 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2695 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2676 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2695 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2695 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2695 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2656 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 23335.2715 - mae: 72.1997 - val_loss: 22976.6406 - val_mae: 73.0028\n",
      "Epoch 11: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 1344.2676 - mae: 24.8953 - val_loss: 564.9777 - val_mae: 21.5510\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 491.5608 - mae: 19.8463 - val_loss: 554.2720 - val_mae: 21.2326\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 486.4597 - mae: 19.6682 - val_loss: 587.6403 - val_mae: 22.1352\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 485.6096 - mae: 19.6315 - val_loss: 545.0009 - val_mae: 20.8757\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 483.4449 - mae: 19.5939 - val_loss: 563.4008 - val_mae: 21.5395\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 479.4306 - mae: 19.4368 - val_loss: 571.4193 - val_mae: 21.7022\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 481.4930 - mae: 19.5300 - val_loss: 550.9611 - val_mae: 21.0076\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 482.9129 - mae: 19.5232 - val_loss: 543.8285 - val_mae: 20.9803\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 475.7722 - mae: 19.3340 - val_loss: 542.9241 - val_mae: 20.7694\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 472.4508 - mae: 19.2427 - val_loss: 560.4380 - val_mae: 21.4126\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 464.8683 - mae: 19.0271 - val_loss: 540.8375 - val_mae: 20.8558\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 455.7380 - mae: 18.7403 - val_loss: 532.6882 - val_mae: 20.4722\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 452.9283 - mae: 18.6586 - val_loss: 536.4700 - val_mae: 20.7455\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 450.2515 - mae: 18.6069 - val_loss: 532.0084 - val_mae: 20.5545\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 440.3850 - mae: 18.2162 - val_loss: 507.6927 - val_mae: 19.8317\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 451.0542 - mae: 18.5731 - val_loss: 523.9920 - val_mae: 20.4701\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 451.2126 - mae: 18.6182 - val_loss: 512.1263 - val_mae: 20.0327\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 438.7986 - mae: 18.1831 - val_loss: 564.2787 - val_mae: 21.4118\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 448.4559 - mae: 18.3791 - val_loss: 479.5293 - val_mae: 18.7717\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 432.6244 - mae: 17.9432 - val_loss: 515.6182 - val_mae: 20.1530\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 440.1627 - mae: 18.1866 - val_loss: 556.6475 - val_mae: 21.4468\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 438.9544 - mae: 18.1778 - val_loss: 628.6876 - val_mae: 22.7013\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 482.7632 - mae: 19.4042 - val_loss: 508.9534 - val_mae: 19.9961\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 451.3381 - mae: 18.5784 - val_loss: 532.8717 - val_mae: 20.5856\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 453.6884 - mae: 18.5987 - val_loss: 509.3442 - val_mae: 19.7159\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 446.8757 - mae: 18.3661 - val_loss: 504.4742 - val_mae: 19.7340\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 457.5966 - mae: 18.7475 - val_loss: 530.9807 - val_mae: 20.5712\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 451.9598 - mae: 18.5853 - val_loss: 508.8978 - val_mae: 19.9097\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 449.9088 - mae: 18.4937 - val_loss: 540.6975 - val_mae: 21.0493\n",
      "Epoch 29: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 821.5212 - mae: 21.5760 - val_loss: 494.7363 - val_mae: 19.3562\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 414.3075 - mae: 17.2208 - val_loss: 465.6332 - val_mae: 18.6058\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 405.3391 - mae: 16.9687 - val_loss: 459.5831 - val_mae: 18.2044\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 403.2140 - mae: 16.8390 - val_loss: 452.6059 - val_mae: 17.8817\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 400.8863 - mae: 16.7646 - val_loss: 450.9467 - val_mae: 17.7601\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 399.3438 - mae: 16.6651 - val_loss: 452.1552 - val_mae: 17.7905\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 399.4263 - mae: 16.7089 - val_loss: 442.9681 - val_mae: 17.6672\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 397.8024 - mae: 16.6245 - val_loss: 463.5519 - val_mae: 18.8340\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 397.0828 - mae: 16.6417 - val_loss: 446.7322 - val_mae: 17.9147\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 396.4035 - mae: 16.5880 - val_loss: 444.9145 - val_mae: 17.5153\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 395.9080 - mae: 16.5485 - val_loss: 442.1493 - val_mae: 17.5255\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 394.2824 - mae: 16.4605 - val_loss: 442.9585 - val_mae: 17.5192\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 394.0851 - mae: 16.4722 - val_loss: 441.9939 - val_mae: 17.4452\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 393.1599 - mae: 16.4402 - val_loss: 452.3656 - val_mae: 17.7850\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 380.5910 - mae: 16.0744 - val_loss: 420.3703 - val_mae: 17.1449\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 374.5289 - mae: 15.9125 - val_loss: 421.2772 - val_mae: 16.7659\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 366.6486 - mae: 15.6276 - val_loss: 376.6420 - val_mae: 15.5545\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 340.1518 - mae: 14.8840 - val_loss: 374.9200 - val_mae: 15.4048\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 331.6041 - mae: 14.4244 - val_loss: 370.0715 - val_mae: 15.2677\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 332.9782 - mae: 14.4974 - val_loss: 368.6129 - val_mae: 15.2405\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 332.3325 - mae: 14.5459 - val_loss: 370.4073 - val_mae: 15.3381\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 330.4002 - mae: 14.4324 - val_loss: 439.3857 - val_mae: 18.4117\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 345.0474 - mae: 15.0532 - val_loss: 369.3206 - val_mae: 15.1883\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 329.1411 - mae: 14.3657 - val_loss: 392.5885 - val_mae: 16.0280\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 330.4366 - mae: 14.3758 - val_loss: 376.1418 - val_mae: 15.3525\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 330.1865 - mae: 14.3829 - val_loss: 368.2083 - val_mae: 15.2143\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 331.5593 - mae: 14.5452 - val_loss: 393.6383 - val_mae: 16.1123\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 324.8060 - mae: 14.2942 - val_loss: 349.7540 - val_mae: 14.9562\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 312.3992 - mae: 13.8467 - val_loss: 423.4219 - val_mae: 18.0973\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 331.8064 - mae: 14.6513 - val_loss: 363.5873 - val_mae: 15.8477\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 314.7673 - mae: 14.1404 - val_loss: 377.3951 - val_mae: 15.9247\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 293.5705 - mae: 13.3153 - val_loss: 419.3132 - val_mae: 17.5144\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.1754 - mae: 13.4113 - val_loss: 336.1949 - val_mae: 14.0754\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 289.6641 - mae: 13.1017 - val_loss: 333.3777 - val_mae: 13.9813\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.4099 - mae: 13.4606 - val_loss: 343.3030 - val_mae: 14.3972\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 288.9994 - mae: 13.0514 - val_loss: 324.0514 - val_mae: 13.7036\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 289.8118 - mae: 13.0654 - val_loss: 325.2300 - val_mae: 13.7163\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 289.9555 - mae: 13.0669 - val_loss: 329.5338 - val_mae: 13.8100\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 290.4725 - mae: 13.0754 - val_loss: 324.0491 - val_mae: 13.6802\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 289.5068 - mae: 13.0688 - val_loss: 324.4453 - val_mae: 14.0864\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 292.0740 - mae: 13.1480 - val_loss: 333.8266 - val_mae: 13.9618\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 288.3463 - mae: 12.9382 - val_loss: 346.8380 - val_mae: 14.5732\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 288.5313 - mae: 13.0280 - val_loss: 321.4439 - val_mae: 13.8463\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 288.6584 - mae: 12.9903 - val_loss: 387.6570 - val_mae: 16.3551\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 294.1007 - mae: 13.2718 - val_loss: 321.8712 - val_mae: 13.8639\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 288.0838 - mae: 13.0008 - val_loss: 354.3048 - val_mae: 14.9286\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 291.1104 - mae: 12.9865 - val_loss: 331.2430 - val_mae: 14.7143\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 291.6633 - mae: 13.1911 - val_loss: 322.3805 - val_mae: 13.8411\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 287.0678 - mae: 12.9426 - val_loss: 324.3255 - val_mae: 13.6086\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 287.5563 - mae: 12.9371 - val_loss: 469.8275 - val_mae: 19.4712\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 305.5991 - mae: 13.5640 - val_loss: 328.5353 - val_mae: 13.7644\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 288.4725 - mae: 12.9277 - val_loss: 358.2994 - val_mae: 15.1298\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 279.3179 - mae: 12.7653 - val_loss: 303.2609 - val_mae: 13.0158\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 263.9786 - mae: 12.2698 - val_loss: 287.6889 - val_mae: 13.0749\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 261.1228 - mae: 12.3029 - val_loss: 346.9694 - val_mae: 15.0483\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 252.0731 - mae: 11.8619 - val_loss: 306.4458 - val_mae: 13.3599\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 252.4236 - mae: 11.7898 - val_loss: 277.7643 - val_mae: 12.2009\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 247.6073 - mae: 11.6976 - val_loss: 283.2941 - val_mae: 12.3035\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 249.0805 - mae: 11.6590 - val_loss: 281.4454 - val_mae: 13.0553\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.6822 - mae: 11.7836 - val_loss: 279.3465 - val_mae: 12.2251\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 252.3574 - mae: 11.8029 - val_loss: 279.4876 - val_mae: 12.9455\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 250.9182 - mae: 11.8805 - val_loss: 285.9660 - val_mae: 12.3890\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.5015 - mae: 11.6629 - val_loss: 277.1547 - val_mae: 12.6498\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.5047 - mae: 11.7409 - val_loss: 285.8453 - val_mae: 12.3941\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 247.1641 - mae: 11.5636 - val_loss: 280.9254 - val_mae: 13.0564\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 249.6720 - mae: 11.6992 - val_loss: 274.8438 - val_mae: 12.2720\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 246.7110 - mae: 11.5510 - val_loss: 275.0721 - val_mae: 12.1634\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.0266 - mae: 11.7195 - val_loss: 293.9209 - val_mae: 12.7467\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.4926 - mae: 11.6304 - val_loss: 287.7191 - val_mae: 12.4886\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 247.6451 - mae: 11.5790 - val_loss: 274.9122 - val_mae: 12.2426\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 245.9359 - mae: 11.5954 - val_loss: 277.0888 - val_mae: 12.7372\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.4074 - mae: 11.7696 - val_loss: 275.1006 - val_mae: 12.1764\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.0344 - mae: 11.6118 - val_loss: 278.2547 - val_mae: 12.1468\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 248.3079 - mae: 11.5741 - val_loss: 286.4212 - val_mae: 12.5310\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 246.2111 - mae: 11.5679 - val_loss: 284.6086 - val_mae: 12.3299\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 246.7724 - mae: 11.5311 - val_loss: 291.8225 - val_mae: 12.6623\n",
      "Epoch 76: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 416.9087 - mae: 17.0209 - val_loss: 469.8090 - val_mae: 19.0516\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 326.2525 - mae: 14.6065 - val_loss: 298.1903 - val_mae: 13.6873\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 256.5086 - mae: 12.0870 - val_loss: 327.6692 - val_mae: 14.2326\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 266.4722 - mae: 12.4981 - val_loss: 285.8276 - val_mae: 12.4898\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 242.8325 - mae: 11.7070 - val_loss: 331.5273 - val_mae: 14.6263\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 240.8471 - mae: 11.4984 - val_loss: 288.3372 - val_mae: 12.7522\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 245.0423 - mae: 12.0441 - val_loss: 265.2173 - val_mae: 12.7575\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 226.9062 - mae: 11.1523 - val_loss: 290.1674 - val_mae: 14.5932\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 212.6517 - mae: 10.7384 - val_loss: 234.6427 - val_mae: 11.4479\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 215.6400 - mae: 10.8310 - val_loss: 242.5818 - val_mae: 10.9264\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 212.7930 - mae: 10.6275 - val_loss: 233.3278 - val_mae: 11.3424\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 207.8472 - mae: 10.3861 - val_loss: 242.0047 - val_mae: 10.9278\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 209.0579 - mae: 10.4612 - val_loss: 233.3756 - val_mae: 10.8075\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 207.6702 - mae: 10.4316 - val_loss: 284.4960 - val_mae: 12.9055\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 214.9103 - mae: 10.6854 - val_loss: 225.3523 - val_mae: 11.5664\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 194.5416 - mae: 10.2033 - val_loss: 216.9698 - val_mae: 10.0606\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 193.7142 - mae: 9.9971 - val_loss: 210.4984 - val_mae: 10.3191\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 190.1910 - mae: 9.8576 - val_loss: 215.1499 - val_mae: 9.9800\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 189.2517 - mae: 9.6623 - val_loss: 209.5418 - val_mae: 10.0228\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 185.9277 - mae: 9.5372 - val_loss: 210.5960 - val_mae: 10.8205\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 187.7125 - mae: 9.8534 - val_loss: 217.9969 - val_mae: 11.4295\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 187.4728 - mae: 9.7427 - val_loss: 369.5599 - val_mae: 17.5780\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 215.7785 - mae: 10.8587 - val_loss: 211.4369 - val_mae: 9.9842\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 182.9380 - mae: 9.4691 - val_loss: 239.8227 - val_mae: 11.0550\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 185.0484 - mae: 9.5468 - val_loss: 232.8921 - val_mae: 10.6751\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 185.4178 - mae: 9.5061 - val_loss: 208.4213 - val_mae: 9.9784\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 186.7195 - mae: 9.7490 - val_loss: 225.9098 - val_mae: 10.3812\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 188.0745 - mae: 9.6701 - val_loss: 225.2793 - val_mae: 11.8988\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 186.6953 - mae: 9.5876 - val_loss: 391.8468 - val_mae: 18.2647\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 228.4269 - mae: 11.3373 - val_loss: 224.5259 - val_mae: 11.8028\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 192.1332 - mae: 9.9624 - val_loss: 271.3351 - val_mae: 12.6894\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 186.9671 - mae: 9.7157 - val_loss: 287.9591 - val_mae: 13.4004\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 191.4323 - mae: 9.8754 - val_loss: 220.7788 - val_mae: 10.1384\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 183.1219 - mae: 9.4594 - val_loss: 213.3627 - val_mae: 10.0246\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 190.6685 - mae: 9.8409 - val_loss: 227.0240 - val_mae: 10.3966\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 183.0797 - mae: 9.4227 - val_loss: 216.8232 - val_mae: 10.0964\n",
      "Epoch 36: early stopping\n"
     ]
    }
   ],
   "source": [
    "lista_hl = []\n",
    "for v in [0, 1, 2, 3]:\n",
    "    model = build_model(n_hidden = v)\n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_split = (0.2), callbacks = [es,tensorboard_cb])\n",
    "    \n",
    "    loss = model.history.history.get('loss')\n",
    "    loss.reverse()\n",
    "    loss[0]\n",
    "    \n",
    "    mae = model.history.history.get('mae')\n",
    "    mae.reverse()\n",
    "    mae[0]\n",
    "    lista_hl.append((v, loss[0], mae[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e30dd711-86a9-48d4-9847-e1ddc64ee083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 23335.271484375, 72.19966125488281),\n",
       " (1, 449.9088134765625, 18.49371337890625),\n",
       " (2, 246.77236938476562, 11.531109809875488),\n",
       " (3, 183.0796661376953, 9.422745704650879)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_hl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a26a007-86c7-4098-8f68-a53f4d36a734",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(\"hl.pkl\", \"wb\")\n",
    "pickle.dump(lista_hl, f2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec10f310-c02b-4772-855d-4fb81a9036fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3c3202dd-b0b2-4d70-b363-7695fcd82526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 2738.9709 - mae: 30.3956 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7463 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 11: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 11ms/step - loss: 1310.5674 - mae: 24.5500 - val_loss: 621.8439 - val_mae: 22.5655\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 503.7111 - mae: 20.1219 - val_loss: 566.2386 - val_mae: 21.5612\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 485.8787 - mae: 19.6210 - val_loss: 554.2220 - val_mae: 21.1516\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 468.2612 - mae: 19.0736 - val_loss: 530.7058 - val_mae: 20.4974\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 464.9243 - mae: 18.9672 - val_loss: 548.4066 - val_mae: 21.0541\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 462.6477 - mae: 18.8851 - val_loss: 564.0413 - val_mae: 21.5356\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 464.9135 - mae: 18.9687 - val_loss: 546.9935 - val_mae: 21.1085\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 465.4724 - mae: 18.9346 - val_loss: 517.6007 - val_mae: 20.3483\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 455.5221 - mae: 18.6651 - val_loss: 518.8406 - val_mae: 20.3228\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 456.9557 - mae: 18.7312 - val_loss: 524.4442 - val_mae: 20.3677\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 453.5202 - mae: 18.5666 - val_loss: 522.6474 - val_mae: 20.3401\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.6086 - mae: 18.8926 - val_loss: 534.9924 - val_mae: 20.6587\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 452.0529 - mae: 18.5532 - val_loss: 501.0381 - val_mae: 19.5755\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 449.4356 - mae: 18.4565 - val_loss: 564.3410 - val_mae: 21.5619\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.9031 - mae: 18.8088 - val_loss: 530.1591 - val_mae: 20.5822\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 462.6431 - mae: 18.9037 - val_loss: 504.6439 - val_mae: 19.6990\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.8774 - mae: 18.8132 - val_loss: 509.1048 - val_mae: 19.9273\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.6153 - mae: 18.8189 - val_loss: 635.0413 - val_mae: 23.0372\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 506.3010 - mae: 20.0967 - val_loss: 532.8376 - val_mae: 20.3313\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 474.0590 - mae: 19.1928 - val_loss: 539.1672 - val_mae: 20.7422\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 469.8656 - mae: 19.0789 - val_loss: 553.4017 - val_mae: 21.2109\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 470.8587 - mae: 19.1449 - val_loss: 547.1567 - val_mae: 21.1099\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 474.1538 - mae: 19.2478 - val_loss: 529.7903 - val_mae: 20.5351\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 651.9628 - mae: 20.1301 - val_loss: 433.1995 - val_mae: 17.4883\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 385.8672 - mae: 16.3998 - val_loss: 409.8090 - val_mae: 16.8810\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 367.9427 - mae: 15.9346 - val_loss: 404.9229 - val_mae: 16.5650\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 358.8207 - mae: 15.6035 - val_loss: 389.0863 - val_mae: 16.0960\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 348.8012 - mae: 15.3253 - val_loss: 381.4146 - val_mae: 15.7945\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 339.5447 - mae: 14.9866 - val_loss: 370.6851 - val_mae: 15.5179\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 334.8440 - mae: 14.9007 - val_loss: 363.4776 - val_mae: 15.3371\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 329.3340 - mae: 14.7027 - val_loss: 361.4749 - val_mae: 15.5840\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 325.2029 - mae: 14.6414 - val_loss: 355.9306 - val_mae: 15.1692\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 321.7647 - mae: 14.4870 - val_loss: 355.9073 - val_mae: 14.9942\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 319.8226 - mae: 14.3567 - val_loss: 349.7373 - val_mae: 14.9449\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 317.3596 - mae: 14.2940 - val_loss: 348.2487 - val_mae: 14.8188\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 316.3329 - mae: 14.2701 - val_loss: 348.7442 - val_mae: 14.8111\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 315.1953 - mae: 14.2264 - val_loss: 357.4208 - val_mae: 14.9470\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 315.9679 - mae: 14.1576 - val_loss: 348.1841 - val_mae: 15.0804\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 314.1741 - mae: 14.2537 - val_loss: 348.5545 - val_mae: 14.6977\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 313.1919 - mae: 14.1215 - val_loss: 346.5358 - val_mae: 14.7141\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 312.8051 - mae: 14.1259 - val_loss: 354.0068 - val_mae: 14.8577\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 312.3906 - mae: 14.0476 - val_loss: 343.7532 - val_mae: 14.6384\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 310.1434 - mae: 13.9864 - val_loss: 342.0962 - val_mae: 14.7478\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 310.1468 - mae: 14.0526 - val_loss: 345.4607 - val_mae: 14.9516\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 310.3230 - mae: 14.0409 - val_loss: 347.5487 - val_mae: 15.2594\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 309.9817 - mae: 14.1486 - val_loss: 343.1898 - val_mae: 14.4789\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 307.0615 - mae: 13.8792 - val_loss: 348.1948 - val_mae: 14.6678\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 305.7144 - mae: 13.8065 - val_loss: 338.3850 - val_mae: 14.3473\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 304.4712 - mae: 13.7923 - val_loss: 334.9422 - val_mae: 14.4020\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 304.1216 - mae: 13.8219 - val_loss: 337.9720 - val_mae: 14.3751\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 303.5782 - mae: 13.7489 - val_loss: 334.2050 - val_mae: 14.4222\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 302.7866 - mae: 13.7582 - val_loss: 342.6797 - val_mae: 15.1909\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 305.0290 - mae: 13.9647 - val_loss: 333.8582 - val_mae: 14.5132\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 302.4516 - mae: 13.7734 - val_loss: 337.8150 - val_mae: 14.2943\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 301.3653 - mae: 13.6522 - val_loss: 348.9826 - val_mae: 14.6399\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 302.1027 - mae: 13.6539 - val_loss: 336.1989 - val_mae: 14.2105\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 300.3979 - mae: 13.6203 - val_loss: 334.4940 - val_mae: 14.2362\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 300.7587 - mae: 13.6556 - val_loss: 336.1284 - val_mae: 14.2302\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 299.8846 - mae: 13.5652 - val_loss: 330.7240 - val_mae: 14.2053\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.8239 - mae: 13.5473 - val_loss: 330.5047 - val_mae: 14.2450\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 299.4728 - mae: 13.6384 - val_loss: 331.6778 - val_mae: 14.1184\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.8578 - mae: 13.5684 - val_loss: 331.1962 - val_mae: 14.1255\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.3492 - mae: 13.5484 - val_loss: 330.3216 - val_mae: 14.1059\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.5079 - mae: 13.5359 - val_loss: 334.0343 - val_mae: 14.0845\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.1151 - mae: 13.4775 - val_loss: 336.2823 - val_mae: 14.1294\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 297.7805 - mae: 13.4692 - val_loss: 329.4731 - val_mae: 14.1979\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 297.9206 - mae: 13.5019 - val_loss: 340.3747 - val_mae: 14.2980\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.9619 - mae: 13.5253 - val_loss: 330.1152 - val_mae: 14.0948\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 297.6565 - mae: 13.4992 - val_loss: 337.5571 - val_mae: 14.1526\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.0451 - mae: 13.4134 - val_loss: 331.4128 - val_mae: 14.5157\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 298.2310 - mae: 13.5828 - val_loss: 333.5542 - val_mae: 14.5694\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 297.6469 - mae: 13.5542 - val_loss: 330.3500 - val_mae: 14.0244\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 296.9329 - mae: 13.4348 - val_loss: 346.2893 - val_mae: 15.4822\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 300.3896 - mae: 13.7465 - val_loss: 331.1329 - val_mae: 14.0408\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 296.7834 - mae: 13.4022 - val_loss: 341.4339 - val_mae: 14.3563\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 297.2102 - mae: 13.4208 - val_loss: 330.2289 - val_mae: 14.1001\n",
      "Epoch 53: early stopping\n"
     ]
    }
   ],
   "source": [
    "lista_nn = []\n",
    "for v in [5, 25, 125]:\n",
    "    model = build_model(n_neurons = v)\n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_split = (0.2), callbacks = [es,tensorboard_cb])\n",
    "    \n",
    "    loss = model.history.history.get('loss')\n",
    "    loss.reverse()\n",
    "    loss[0]\n",
    "    \n",
    "    mae = model.history.history.get('mae')\n",
    "    mae.reverse()\n",
    "    mae[0]\n",
    "    lista_nn.append((v, loss[0], mae[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62508cd0-cc97-433c-9016-10f06c52d1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 571.7462158203125, 22.081424713134766),\n",
       " (25, 474.1538391113281, 19.247846603393555),\n",
       " (125, 297.2101745605469, 13.420838356018066)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce7edffb-759a-4619-86c7-3cb4ea7ce6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f3 = open(\"nn.pkl\", \"wb\")\n",
    "pickle.dump(lista_nn, f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcd656ea-4886-4aa9-b536-66fd8ef23dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2547b7b0-7a21-48b6-a7cb-b21320a2afe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1344.2676 - mae: 24.8953 - val_loss: 564.9777 - val_mae: 21.5510\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 491.5608 - mae: 19.8463 - val_loss: 554.2720 - val_mae: 21.2326\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 486.4597 - mae: 19.6682 - val_loss: 587.6403 - val_mae: 22.1352\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 485.6096 - mae: 19.6315 - val_loss: 545.0009 - val_mae: 20.8757\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 483.4449 - mae: 19.5939 - val_loss: 563.4008 - val_mae: 21.5395\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 479.4306 - mae: 19.4368 - val_loss: 571.4193 - val_mae: 21.7022\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 481.4930 - mae: 19.5300 - val_loss: 550.9611 - val_mae: 21.0076\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 482.9129 - mae: 19.5232 - val_loss: 543.8285 - val_mae: 20.9803\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 475.7722 - mae: 19.3340 - val_loss: 542.9241 - val_mae: 20.7694\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 472.4508 - mae: 19.2427 - val_loss: 560.4380 - val_mae: 21.4126\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 464.8683 - mae: 19.0271 - val_loss: 540.8375 - val_mae: 20.8558\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 455.7380 - mae: 18.7403 - val_loss: 532.6882 - val_mae: 20.4722\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 452.9283 - mae: 18.6586 - val_loss: 536.4700 - val_mae: 20.7455\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 450.2515 - mae: 18.6069 - val_loss: 532.0084 - val_mae: 20.5545\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 440.3850 - mae: 18.2162 - val_loss: 507.6927 - val_mae: 19.8317\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 451.0542 - mae: 18.5731 - val_loss: 523.9920 - val_mae: 20.4701\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 451.2126 - mae: 18.6182 - val_loss: 512.1263 - val_mae: 20.0327\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 438.7986 - mae: 18.1831 - val_loss: 564.2787 - val_mae: 21.4118\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 448.4559 - mae: 18.3791 - val_loss: 479.5293 - val_mae: 18.7717\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 432.6244 - mae: 17.9432 - val_loss: 515.6182 - val_mae: 20.1530\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 440.1627 - mae: 18.1866 - val_loss: 556.6475 - val_mae: 21.4468\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 438.9544 - mae: 18.1778 - val_loss: 628.6876 - val_mae: 22.7013\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 482.7632 - mae: 19.4042 - val_loss: 508.9534 - val_mae: 19.9961\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 451.3381 - mae: 18.5784 - val_loss: 532.8717 - val_mae: 20.5856\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 453.6884 - mae: 18.5987 - val_loss: 509.3442 - val_mae: 19.7159\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 446.8757 - mae: 18.3661 - val_loss: 504.4742 - val_mae: 19.7340\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 457.5966 - mae: 18.7475 - val_loss: 530.9807 - val_mae: 20.5712\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 451.9598 - mae: 18.5853 - val_loss: 508.8978 - val_mae: 19.9097\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 449.9088 - mae: 18.4937 - val_loss: 540.6975 - val_mae: 21.0493\n",
      "Epoch 29: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1310.5674 - mae: 24.5500 - val_loss: 621.8439 - val_mae: 22.5655\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 503.7111 - mae: 20.1219 - val_loss: 566.2386 - val_mae: 21.5612\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 485.8787 - mae: 19.6210 - val_loss: 554.2220 - val_mae: 21.1516\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 468.2612 - mae: 19.0736 - val_loss: 530.7058 - val_mae: 20.4974\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 464.9243 - mae: 18.9672 - val_loss: 548.4066 - val_mae: 21.0541\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 462.6477 - mae: 18.8851 - val_loss: 564.0413 - val_mae: 21.5356\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 464.9135 - mae: 18.9687 - val_loss: 546.9935 - val_mae: 21.1085\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 465.4724 - mae: 18.9346 - val_loss: 517.6007 - val_mae: 20.3483\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 455.5221 - mae: 18.6651 - val_loss: 518.8406 - val_mae: 20.3228\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 456.9557 - mae: 18.7312 - val_loss: 524.4442 - val_mae: 20.3677\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 453.5202 - mae: 18.5666 - val_loss: 522.6474 - val_mae: 20.3401\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.6086 - mae: 18.8926 - val_loss: 534.9924 - val_mae: 20.6587\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 452.0529 - mae: 18.5532 - val_loss: 501.0381 - val_mae: 19.5755\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 449.4356 - mae: 18.4565 - val_loss: 564.3410 - val_mae: 21.5619\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.9031 - mae: 18.8088 - val_loss: 530.1591 - val_mae: 20.5822\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 462.6431 - mae: 18.9037 - val_loss: 504.6439 - val_mae: 19.6990\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.8774 - mae: 18.8132 - val_loss: 509.1048 - val_mae: 19.9273\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 459.6153 - mae: 18.8189 - val_loss: 635.0413 - val_mae: 23.0372\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 506.3010 - mae: 20.0967 - val_loss: 532.8376 - val_mae: 20.3313\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 474.0590 - mae: 19.1928 - val_loss: 539.1672 - val_mae: 20.7422\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 469.8656 - mae: 19.0789 - val_loss: 553.4017 - val_mae: 21.2109\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 470.8587 - mae: 19.1449 - val_loss: 547.1567 - val_mae: 21.1099\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 474.1538 - mae: 19.2478 - val_loss: 529.7903 - val_mae: 20.5351\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 868.1351 - mae: 22.9092 - val_loss: 610.0872 - val_mae: 22.6476\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 545.4420 - mae: 21.2933 - val_loss: 641.0784 - val_mae: 23.4502\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 547.2977 - mae: 21.3806 - val_loss: 613.2812 - val_mae: 22.7662\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 544.4338 - mae: 21.2904 - val_loss: 612.4769 - val_mae: 22.7413\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 541.5728 - mae: 21.2071 - val_loss: 607.8279 - val_mae: 22.6434\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 539.9304 - mae: 21.1388 - val_loss: 609.8970 - val_mae: 22.6836\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 540.5776 - mae: 21.1704 - val_loss: 606.1252 - val_mae: 22.5913\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 538.2871 - mae: 21.0772 - val_loss: 645.7439 - val_mae: 23.6572\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 538.7809 - mae: 21.0777 - val_loss: 621.3053 - val_mae: 23.1255\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 539.7650 - mae: 21.1201 - val_loss: 605.0789 - val_mae: 22.4715\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 539.3768 - mae: 21.1229 - val_loss: 605.0237 - val_mae: 22.6335\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 535.5712 - mae: 20.9899 - val_loss: 604.7485 - val_mae: 22.4589\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 536.2468 - mae: 21.0109 - val_loss: 601.9534 - val_mae: 22.3736\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 535.4417 - mae: 20.9824 - val_loss: 612.0661 - val_mae: 22.7247\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 538.2145 - mae: 21.0717 - val_loss: 601.9081 - val_mae: 22.4950\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 534.9056 - mae: 20.9563 - val_loss: 603.7335 - val_mae: 22.4368\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 534.5393 - mae: 20.9339 - val_loss: 601.3593 - val_mae: 22.4585\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 536.3646 - mae: 21.0084 - val_loss: 614.3364 - val_mae: 22.8305\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 536.0645 - mae: 20.9948 - val_loss: 600.5480 - val_mae: 22.4070\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 535.6640 - mae: 20.9775 - val_loss: 604.2146 - val_mae: 22.6027\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 534.8089 - mae: 20.9716 - val_loss: 607.1692 - val_mae: 22.7171\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 535.3348 - mae: 20.9805 - val_loss: 641.7858 - val_mae: 23.5717\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 541.7268 - mae: 21.1828 - val_loss: 601.2736 - val_mae: 22.4731\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 533.2925 - mae: 20.8948 - val_loss: 612.2860 - val_mae: 22.7609\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 535.5849 - mae: 20.9952 - val_loss: 613.8019 - val_mae: 22.8323\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 534.8889 - mae: 20.9504 - val_loss: 603.0718 - val_mae: 22.5412\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 550.7745 - mae: 21.4756 - val_loss: 623.2545 - val_mae: 23.1438\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 541.0411 - mae: 21.1767 - val_loss: 660.4038 - val_mae: 23.8468\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 560.5285 - mae: 21.7155 - val_loss: 648.7195 - val_mae: 23.7372\n",
      "Epoch 29: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 9349.0811 - mae: 70.5863 - val_loss: 8968.8379 - val_mae: 69.5784\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 9227.0068 - mae: 70.1115 - val_loss: 8851.5576 - val_mae: 69.1182\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 9104.1914 - mae: 69.6291 - val_loss: 8733.6123 - val_mae: 68.6553\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8985.1367 - mae: 69.1627 - val_loss: 8618.6406 - val_mae: 68.1999\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8866.8799 - mae: 68.6976 - val_loss: 8505.3486 - val_mae: 67.7479\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8752.5332 - mae: 68.2395 - val_loss: 8392.1855 - val_mae: 67.2947\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8634.3408 - mae: 67.7730 - val_loss: 8279.8838 - val_mae: 66.8422\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8520.3369 - mae: 67.3139 - val_loss: 8168.3740 - val_mae: 66.3902\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8405.6758 - mae: 66.8559 - val_loss: 8060.7622 - val_mae: 65.9520\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8294.8574 - mae: 66.4057 - val_loss: 7952.7422 - val_mae: 65.5081\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8184.2900 - mae: 65.9539 - val_loss: 7844.4292 - val_mae: 65.0611\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 8073.5249 - mae: 65.5014 - val_loss: 7738.1558 - val_mae: 64.6194\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7963.8164 - mae: 65.0475 - val_loss: 7632.7700 - val_mae: 64.1793\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7856.5757 - mae: 64.6027 - val_loss: 7532.1357 - val_mae: 63.7546\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7752.2603 - mae: 64.1631 - val_loss: 7428.8965 - val_mae: 63.3167\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7646.5610 - mae: 63.7147 - val_loss: 7328.9878 - val_mae: 62.8898\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7546.0386 - mae: 63.2825 - val_loss: 7231.1904 - val_mae: 62.4682\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7445.5449 - mae: 62.8469 - val_loss: 7133.3472 - val_mae: 62.0446\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7344.1333 - mae: 62.4070 - val_loss: 7032.6885 - val_mae: 61.6056\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7243.4189 - mae: 61.9637 - val_loss: 6937.8960 - val_mae: 61.1876\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7145.9575 - mae: 61.5367 - val_loss: 6846.8979 - val_mae: 60.7852\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 7053.7979 - mae: 61.1253 - val_loss: 6756.8403 - val_mae: 60.3843\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6960.6045 - mae: 60.7104 - val_loss: 6666.9751 - val_mae: 59.9823\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6868.0117 - mae: 60.2954 - val_loss: 6577.3628 - val_mae: 59.5783\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6776.2886 - mae: 59.8787 - val_loss: 6487.8110 - val_mae: 59.1706\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6685.9312 - mae: 59.4683 - val_loss: 6402.1240 - val_mae: 58.7756\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6598.7808 - mae: 59.0658 - val_loss: 6316.5034 - val_mae: 58.3791\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6510.5049 - mae: 58.6632 - val_loss: 6234.6055 - val_mae: 57.9976\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6425.8589 - mae: 58.2697 - val_loss: 6151.2197 - val_mae: 57.6075\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6341.5435 - mae: 57.8781 - val_loss: 6070.7515 - val_mae: 57.2294\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6258.9028 - mae: 57.4911 - val_loss: 5990.0391 - val_mae: 56.8478\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6174.6870 - mae: 57.0970 - val_loss: 5909.2471 - val_mae: 56.4632\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6091.3926 - mae: 56.7021 - val_loss: 5826.1255 - val_mae: 56.0655\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 6005.7021 - mae: 56.2987 - val_loss: 5746.1606 - val_mae: 55.6814\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5923.3613 - mae: 55.9090 - val_loss: 5666.4697 - val_mae: 55.2986\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5843.5859 - mae: 55.5271 - val_loss: 5590.3203 - val_mae: 54.9304\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5765.8491 - mae: 55.1512 - val_loss: 5515.0410 - val_mae: 54.5643\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5689.1807 - mae: 54.7813 - val_loss: 5442.8882 - val_mae: 54.2099\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 5614.5303 - mae: 54.4208 - val_loss: 5372.7168 - val_mae: 53.8624\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5542.3018 - mae: 54.0669 - val_loss: 5302.2559 - val_mae: 53.5122\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5470.1919 - mae: 53.7092 - val_loss: 5230.7251 - val_mae: 53.1554\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5396.6875 - mae: 53.3492 - val_loss: 5161.6333 - val_mae: 52.8098\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5325.5513 - mae: 52.9933 - val_loss: 5092.0464 - val_mae: 52.4600\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5254.7471 - mae: 52.6413 - val_loss: 5024.7510 - val_mae: 52.1194\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5183.8062 - mae: 52.2865 - val_loss: 4955.4863 - val_mae: 51.7682\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5111.6958 - mae: 51.9235 - val_loss: 4885.5796 - val_mae: 51.4133\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 5040.6182 - mae: 51.5637 - val_loss: 4818.2437 - val_mae: 51.0705\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4972.7778 - mae: 51.2201 - val_loss: 4754.1904 - val_mae: 50.7442\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4907.2505 - mae: 50.8876 - val_loss: 4692.1855 - val_mae: 50.4288\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4843.8086 - mae: 50.5621 - val_loss: 4630.0962 - val_mae: 50.1121\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4778.9556 - mae: 50.2307 - val_loss: 4566.9985 - val_mae: 49.7889\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4714.4878 - mae: 49.8999 - val_loss: 4506.3008 - val_mae: 49.4769\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4650.9487 - mae: 49.5702 - val_loss: 4444.1396 - val_mae: 49.1549\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4588.4082 - mae: 49.2454 - val_loss: 4385.1343 - val_mae: 48.8485\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4528.2842 - mae: 48.9316 - val_loss: 4328.0137 - val_mae: 48.5508\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4468.4971 - mae: 48.6168 - val_loss: 4269.8481 - val_mae: 48.2463\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4407.8247 - mae: 48.2968 - val_loss: 4212.0869 - val_mae: 47.9427\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4350.1309 - mae: 47.9887 - val_loss: 4156.2261 - val_mae: 47.6482\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4291.8242 - mae: 47.6801 - val_loss: 4101.6621 - val_mae: 47.3600\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4234.6665 - mae: 47.3721 - val_loss: 4046.4536 - val_mae: 47.0670\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4178.0786 - mae: 47.0695 - val_loss: 3992.6431 - val_mae: 46.7796\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4121.9399 - mae: 46.7665 - val_loss: 3938.0691 - val_mae: 46.4857\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4066.8203 - mae: 46.4693 - val_loss: 3886.5054 - val_mae: 46.2077\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 4014.9678 - mae: 46.1857 - val_loss: 3835.6541 - val_mae: 45.9331\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3963.1079 - mae: 45.9028 - val_loss: 3785.4756 - val_mae: 45.6607\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3909.9939 - mae: 45.6149 - val_loss: 3735.9709 - val_mae: 45.3906\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3859.2673 - mae: 45.3334 - val_loss: 3686.4429 - val_mae: 45.1174\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3808.3438 - mae: 45.0514 - val_loss: 3637.9175 - val_mae: 44.8474\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3757.1880 - mae: 44.7636 - val_loss: 3587.4414 - val_mae: 44.5647\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3706.3572 - mae: 44.4780 - val_loss: 3539.5085 - val_mae: 44.2949\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3657.0979 - mae: 44.2013 - val_loss: 3492.2620 - val_mae: 44.0279\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3608.0178 - mae: 43.9256 - val_loss: 3445.8306 - val_mae: 43.7633\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3560.5640 - mae: 43.6542 - val_loss: 3399.5903 - val_mae: 43.4976\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3513.1826 - mae: 43.3830 - val_loss: 3355.0659 - val_mae: 43.2399\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3467.4343 - mae: 43.1190 - val_loss: 3311.0999 - val_mae: 42.9834\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3422.6040 - mae: 42.8577 - val_loss: 3267.5410 - val_mae: 42.7278\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3377.6423 - mae: 42.5952 - val_loss: 3223.8472 - val_mae: 42.4697\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3332.0305 - mae: 42.3294 - val_loss: 3180.1228 - val_mae: 42.2088\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3287.5085 - mae: 42.0640 - val_loss: 3136.3616 - val_mae: 41.9451\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3242.6553 - mae: 41.7993 - val_loss: 3094.9248 - val_mae: 41.6930\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3200.1543 - mae: 41.5453 - val_loss: 3053.8167 - val_mae: 41.4412\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3158.0229 - mae: 41.2914 - val_loss: 3013.3350 - val_mae: 41.1896\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3115.8914 - mae: 41.0384 - val_loss: 2973.6343 - val_mae: 40.9402\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 3075.1772 - mae: 40.7914 - val_loss: 2934.0312 - val_mae: 40.6895\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 3034.4956 - mae: 40.5406 - val_loss: 2894.3479 - val_mae: 40.4356\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2994.0793 - mae: 40.2914 - val_loss: 2855.7151 - val_mae: 40.1856\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2954.3848 - mae: 40.0468 - val_loss: 2818.2515 - val_mae: 39.9411\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2915.6943 - mae: 39.8077 - val_loss: 2781.8538 - val_mae: 39.7037\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2878.4492 - mae: 39.5763 - val_loss: 2746.4692 - val_mae: 39.4717\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2842.3479 - mae: 39.3498 - val_loss: 2711.4995 - val_mae: 39.2421\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2806.1284 - mae: 39.1239 - val_loss: 2676.6211 - val_mae: 39.0120\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2769.7139 - mae: 38.8953 - val_loss: 2641.4409 - val_mae: 38.7805\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2734.2188 - mae: 38.6698 - val_loss: 2606.3589 - val_mae: 38.5475\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2698.4536 - mae: 38.4444 - val_loss: 2572.8462 - val_mae: 38.3222\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 2663.8406 - mae: 38.2226 - val_loss: 2539.1353 - val_mae: 38.0944\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2628.9604 - mae: 37.9974 - val_loss: 2504.5535 - val_mae: 37.8592\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2593.9436 - mae: 37.7716 - val_loss: 2472.1401 - val_mae: 37.6383\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2560.7468 - mae: 37.5560 - val_loss: 2440.6157 - val_mae: 37.4217\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2528.3091 - mae: 37.3452 - val_loss: 2410.1458 - val_mae: 37.2112\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 2497.2112 - mae: 37.1389 - val_loss: 2379.4880 - val_mae: 36.9986\n"
     ]
    }
   ],
   "source": [
    "lista_opt = []\n",
    "for v in [\"sgd\", \"nesterov\", \"momentum\", \"adam\"]:\n",
    "    \n",
    "    if v == \"momentum\":\n",
    "        model = build_model(optimizer = v)\n",
    "    else:\n",
    "        model = build_model(optimizer = v)\n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_split = (0.2), callbacks = [es,tensorboard_cb])\n",
    "    \n",
    "    loss = model.history.history.get('loss')\n",
    "    loss.reverse()\n",
    "    loss[0]\n",
    "    \n",
    "    mae = model.history.history.get('mae')\n",
    "    mae.reverse()\n",
    "    mae[0]\n",
    "    lista_opt.append((v, loss[0], mae[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b939ad84-661f-4381-b3f7-c2692e827e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sgd', 449.9088134765625, 18.49371337890625),\n",
       " ('nesterov', 474.1538391113281, 19.247846603393555),\n",
       " ('momentum', 560.5285034179688, 21.71548843383789),\n",
       " ('adam', 2497.211181640625, 37.138912200927734)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f7b1c4c5-0db0-44e7-9c92-a98f0850d23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f4 = open(\"opt.pkl\", \"wb\")\n",
    "pickle.dump(lista_opt, f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a4b3cfa-7198-40b6-92c9-be1a6a4a4e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14079766-15a1-4432-814e-65866f0237ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 1350.7036 - mae: 25.0829 - val_loss: 579.9218 - val_mae: 21.9772\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 499.5491 - mae: 20.0928 - val_loss: 558.3324 - val_mae: 21.3138\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 487.6421 - mae: 19.7080 - val_loss: 584.6796 - val_mae: 22.0723\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 485.8438 - mae: 19.6356 - val_loss: 544.3733 - val_mae: 20.8668\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 481.2461 - mae: 19.5248 - val_loss: 562.3028 - val_mae: 21.4927\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 481.1878 - mae: 19.5173 - val_loss: 580.5062 - val_mae: 21.8259\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 479.0777 - mae: 19.4280 - val_loss: 564.0371 - val_mae: 21.4648\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 482.7498 - mae: 19.5106 - val_loss: 539.2221 - val_mae: 20.8748\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 473.2016 - mae: 19.2505 - val_loss: 537.5753 - val_mae: 20.6586\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 469.9218 - mae: 19.1762 - val_loss: 560.4257 - val_mae: 21.4054\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 469.3806 - mae: 19.1582 - val_loss: 535.2022 - val_mae: 20.6227\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 464.6335 - mae: 18.9937 - val_loss: 529.5032 - val_mae: 20.3731\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 463.2320 - mae: 18.9522 - val_loss: 525.5031 - val_mae: 20.3298\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 456.6298 - mae: 18.7309 - val_loss: 545.7219 - val_mae: 20.9662\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 440.6345 - mae: 18.2395 - val_loss: 512.5267 - val_mae: 19.9453\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 444.6747 - mae: 18.3524 - val_loss: 498.8292 - val_mae: 19.5044\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 440.6677 - mae: 18.2425 - val_loss: 502.5057 - val_mae: 19.7267\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 435.1563 - mae: 18.0687 - val_loss: 512.9590 - val_mae: 20.0309\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 435.7540 - mae: 18.0612 - val_loss: 475.8900 - val_mae: 18.7032\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 429.9557 - mae: 17.8570 - val_loss: 506.1060 - val_mae: 19.8735\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 434.9121 - mae: 17.9710 - val_loss: 539.4668 - val_mae: 20.8494\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 437.2924 - mae: 18.1037 - val_loss: 622.1872 - val_mae: 22.8096\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 482.3070 - mae: 19.3577 - val_loss: 504.5963 - val_mae: 19.7022\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 444.4216 - mae: 18.2329 - val_loss: 509.2178 - val_mae: 19.7258\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 439.7895 - mae: 18.0577 - val_loss: 504.3236 - val_mae: 19.5823\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 439.2113 - mae: 18.0471 - val_loss: 488.1799 - val_mae: 19.0246\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 442.7263 - mae: 18.2310 - val_loss: 532.1234 - val_mae: 20.5924\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 452.3170 - mae: 18.6097 - val_loss: 524.8049 - val_mae: 20.3646\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 452.2073 - mae: 18.4849 - val_loss: 546.6778 - val_mae: 21.2923\n",
      "Epoch 29: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 1324.5264 - mae: 24.9769 - val_loss: 597.0571 - val_mae: 22.3726\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 523.1990 - mae: 20.7375 - val_loss: 599.5469 - val_mae: 22.3666\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 518.3380 - mae: 20.5787 - val_loss: 598.6307 - val_mae: 22.4270\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 517.4880 - mae: 20.5349 - val_loss: 573.2074 - val_mae: 21.6744\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 508.5938 - mae: 20.2631 - val_loss: 567.7181 - val_mae: 21.4190\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 502.8643 - mae: 20.0261 - val_loss: 568.8091 - val_mae: 21.4739\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 503.3280 - mae: 20.0668 - val_loss: 557.9246 - val_mae: 21.1442\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 499.0678 - mae: 19.8553 - val_loss: 625.2999 - val_mae: 23.1269\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 501.2935 - mae: 19.9119 - val_loss: 577.1194 - val_mae: 21.8926\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 501.0675 - mae: 19.9732 - val_loss: 569.5703 - val_mae: 21.4835\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 500.0776 - mae: 19.9573 - val_loss: 557.4918 - val_mae: 21.2268\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 494.6648 - mae: 19.7030 - val_loss: 561.5440 - val_mae: 21.2837\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 495.1733 - mae: 19.7198 - val_loss: 553.4736 - val_mae: 20.8726\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 493.8958 - mae: 19.6696 - val_loss: 577.0629 - val_mae: 21.8468\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 499.5544 - mae: 19.9051 - val_loss: 555.6238 - val_mae: 21.0392\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 493.9826 - mae: 19.6542 - val_loss: 557.5151 - val_mae: 20.9741\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 494.0018 - mae: 19.6631 - val_loss: 554.0047 - val_mae: 20.9294\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 497.9644 - mae: 19.8421 - val_loss: 576.0110 - val_mae: 21.8061\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 497.7875 - mae: 19.7944 - val_loss: 553.2448 - val_mae: 20.8818\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 494.1118 - mae: 19.6630 - val_loss: 557.5989 - val_mae: 21.2709\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 493.5851 - mae: 19.6682 - val_loss: 553.4255 - val_mae: 21.0033\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 493.3138 - mae: 19.6514 - val_loss: 629.7830 - val_mae: 23.3076\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 508.0786 - mae: 20.1783 - val_loss: 553.9033 - val_mae: 21.0152\n",
      "Epoch 23: early stopping\n",
      "Epoch 1/100\n",
      "11/11 [==============================] - 0s 13ms/step - loss: 872.7275 - mae: 23.0264 - val_loss: 621.1192 - val_mae: 23.0212\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 4ms/step - loss: 557.4514 - mae: 21.6875 - val_loss: 624.9966 - val_mae: 23.1224\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 554.9558 - mae: 21.5874 - val_loss: 622.6656 - val_mae: 23.0167\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 553.1991 - mae: 21.5049 - val_loss: 627.7167 - val_mae: 23.1958\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 554.8792 - mae: 21.5714 - val_loss: 621.7910 - val_mae: 23.0318\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 552.9899 - mae: 21.5121 - val_loss: 621.0345 - val_mae: 22.9448\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 556.9045 - mae: 21.6498 - val_loss: 678.6029 - val_mae: 24.1957\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 573.2308 - mae: 22.0726 - val_loss: 643.2559 - val_mae: 23.6393\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 566.4413 - mae: 21.9318 - val_loss: 627.2374 - val_mae: 23.1812\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 568.4680 - mae: 21.9882 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 571.7462 - mae: 22.0814 - val_loss: 643.6396 - val_mae: 23.6457\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "lista_mom = []\n",
    "for v in [0.1, 0.5, 0.9]:\n",
    "    model = build_model(optimizer = \"momentum\", momentum = v)\n",
    "    history = model.fit(X_train, y_train, epochs=100, validation_split = (0.2), callbacks = [es,tensorboard_cb])\n",
    "    \n",
    "    loss = model.history.history.get('loss')\n",
    "    loss.reverse()\n",
    "    loss[0]\n",
    "    \n",
    "    mae = model.history.history.get('mae')\n",
    "    mae.reverse()\n",
    "    mae[0]\n",
    "    lista_mom.append((v, loss[0], mae[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5e70414-9d6a-46de-89c3-8b74f332e9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.1, 452.207275390625, 18.484941482543945),\n",
       " (0.5, 508.0786437988281, 20.178321838378906),\n",
       " (0.9, 571.7462158203125, 22.081424713134766)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista_mom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba7f3751-d21d-45d0-8ed8-aacd79274af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f5 = open(\"mom.pkl\", \"wb\")\n",
    "pickle.dump(lista_mom, f5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa5bfd2-06de-4008-998e-6132861d900e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "585632aa-88bc-4051-81ba-be0b8855fd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "\"model__n_hidden\": [0,1,2,3],\n",
    "\"model__n_neurons\": [5,25,125],\n",
    "\"model__learning_rate\": [10e-6, 10e-5, 10e-4],\n",
    "\"model__optimizer\": [\"sgd\", \"nesterov\", \"momentum\", \"adam\"],\n",
    "\"model__momentum\": [0.1, 0.5, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf4b0276-43b2-4fe9-9477-0eafab28e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikeras\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "es = tf.keras.callbacks.EarlyStopping(patience=10, min_delta=1.0, verbose=1)\n",
    "keras_reg = KerasRegressor(build_model, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b772c95-e1b5-46b8-9aad-2e7a449c6159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 1252.5726 - mae: 24.9121 - val_loss: 387.2557 - val_mae: 18.3422\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.5853 - mae: 22.5874 - val_loss: 449.0363 - val_mae: 20.2712\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.2661 - mae: 22.6934 - val_loss: 448.7089 - val_mae: 20.2632\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.8995 - mae: 22.6853 - val_loss: 448.3768 - val_mae: 20.2550\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.5281 - mae: 22.6771 - val_loss: 448.0488 - val_mae: 20.2469\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.1613 - mae: 22.6689 - val_loss: 447.7228 - val_mae: 20.2388\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.7961 - mae: 22.6609 - val_loss: 447.3964 - val_mae: 20.2307\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.4307 - mae: 22.6529 - val_loss: 447.0687 - val_mae: 20.2226\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.0635 - mae: 22.6448 - val_loss: 446.7395 - val_mae: 20.2144\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.6951 - mae: 22.6366 - val_loss: 446.4145 - val_mae: 20.2064\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.3312 - mae: 22.6286 - val_loss: 446.0881 - val_mae: 20.1983\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=25, model__optimizer=sgd; total time=   0.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 715623.6875 - mae: 179.2123 - val_loss: 448.3985 - val_mae: 20.2554\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.2079 - mae: 23.0984 - val_loss: 448.1760 - val_mae: 20.2498\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.9524 - mae: 23.0929 - val_loss: 447.9485 - val_mae: 20.2442\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.6913 - mae: 23.0871 - val_loss: 447.7184 - val_mae: 20.2384\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.4272 - mae: 23.0814 - val_loss: 447.4860 - val_mae: 20.2326\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.1601 - mae: 23.0755 - val_loss: 447.2509 - val_mae: 20.2267\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.8894 - mae: 23.0696 - val_loss: 447.0116 - val_mae: 20.2207\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.6138 - mae: 23.0637 - val_loss: 446.7658 - val_mae: 20.2146\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.3301 - mae: 23.0573 - val_loss: 446.5132 - val_mae: 20.2082\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.0385 - mae: 23.0509 - val_loss: 446.2551 - val_mae: 20.2017\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.7408 - mae: 23.0443 - val_loss: 445.9937 - val_mae: 20.1951\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.4385 - mae: 23.0377 - val_loss: 445.7231 - val_mae: 20.1882\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.1256 - mae: 23.0308 - val_loss: 445.4459 - val_mae: 20.1812\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.8049 - mae: 23.0236 - val_loss: 445.1626 - val_mae: 20.1740\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.4765 - mae: 23.0164 - val_loss: 444.8689 - val_mae: 20.1665\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.1362 - mae: 23.0087 - val_loss: 444.5679 - val_mae: 20.1588\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.7869 - mae: 23.0010 - val_loss: 444.2551 - val_mae: 20.1508\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.4241 - mae: 22.9928 - val_loss: 443.9354 - val_mae: 20.1426\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.0527 - mae: 22.9846 - val_loss: 443.6035 - val_mae: 20.1340\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.6668 - mae: 22.9758 - val_loss: 443.2617 - val_mae: 20.1252\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.2695 - mae: 22.9667 - val_loss: 442.9089 - val_mae: 20.1160\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.8591 - mae: 22.9576 - val_loss: 442.5453 - val_mae: 20.1066\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.4372 - mae: 22.9480 - val_loss: 442.1706 - val_mae: 20.0968\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.0007 - mae: 22.9380 - val_loss: 441.7796 - val_mae: 20.0866\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.5448 - mae: 22.9276 - val_loss: 441.3795 - val_mae: 20.0761\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.0809 - mae: 22.9170 - val_loss: 440.9689 - val_mae: 20.0653\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.6022 - mae: 22.9060 - val_loss: 440.5500 - val_mae: 20.0542\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.1125 - mae: 22.8948 - val_loss: 440.1118 - val_mae: 20.0425\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.6000 - mae: 22.8830 - val_loss: 439.6567 - val_mae: 20.0304\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.0676 - mae: 22.8706 - val_loss: 439.1832 - val_mae: 20.0177\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.5141 - mae: 22.8577 - val_loss: 438.6973 - val_mae: 20.0047\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.9442 - mae: 22.8445 - val_loss: 438.1820 - val_mae: 19.9908\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.3407 - mae: 22.8302 - val_loss: 437.6521 - val_mae: 19.9764\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.7198 - mae: 22.8157 - val_loss: 437.1035 - val_mae: 19.9614\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.0758 - mae: 22.8006 - val_loss: 436.5302 - val_mae: 19.9457\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.4033 - mae: 22.7843 - val_loss: 435.9390 - val_mae: 19.9294\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.7095 - mae: 22.7679 - val_loss: 435.3323 - val_mae: 19.9126\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.9965 - mae: 22.7508 - val_loss: 434.7034 - val_mae: 19.8951\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.2565 - mae: 22.7328 - val_loss: 434.0481 - val_mae: 19.8767\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 619.4854 - mae: 22.7144 - val_loss: 433.3685 - val_mae: 19.8575\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 618.6855 - mae: 22.6945 - val_loss: 432.6673 - val_mae: 19.8376\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 617.8592 - mae: 22.6742 - val_loss: 431.9440 - val_mae: 19.8168\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 617.0060 - mae: 22.6534 - val_loss: 431.1950 - val_mae: 19.7952\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.1219 - mae: 22.6315 - val_loss: 430.4198 - val_mae: 19.7727\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.2073 - mae: 22.6079 - val_loss: 429.6245 - val_mae: 19.7493\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 614.2667 - mae: 22.5847 - val_loss: 428.8094 - val_mae: 19.7252\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.3027 - mae: 22.5601 - val_loss: 427.9729 - val_mae: 19.7002\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.3113 - mae: 22.5349 - val_loss: 427.0995 - val_mae: 19.6739\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 611.2748 - mae: 22.5084 - val_loss: 426.1968 - val_mae: 19.6464\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 610.2053 - mae: 22.4804 - val_loss: 425.2882 - val_mae: 19.6184\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 609.1247 - mae: 22.4518 - val_loss: 424.3481 - val_mae: 19.5891\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 608.0074 - mae: 22.4220 - val_loss: 423.3863 - val_mae: 19.5588\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.8602 - mae: 22.3914 - val_loss: 422.4022 - val_mae: 19.5274\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 605.6883 - mae: 22.3594 - val_loss: 421.4090 - val_mae: 19.4954\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 604.4997 - mae: 22.3270 - val_loss: 420.3785 - val_mae: 19.4616\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 603.2678 - mae: 22.2929 - val_loss: 419.3321 - val_mae: 19.4269\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 602.0146 - mae: 22.2579 - val_loss: 418.2759 - val_mae: 19.3913\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 600.7465 - mae: 22.2216 - val_loss: 417.2046 - val_mae: 19.3547\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 599.4577 - mae: 22.1852 - val_loss: 416.1050 - val_mae: 19.3164\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.1330 - mae: 22.1458 - val_loss: 414.9973 - val_mae: 19.2773\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.7977 - mae: 22.1061 - val_loss: 413.8938 - val_mae: 19.2377\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.4612 - mae: 22.0663 - val_loss: 412.7824 - val_mae: 19.1977\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.1126 - mae: 22.0255 - val_loss: 411.6622 - val_mae: 19.1567\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.7501 - mae: 21.9838 - val_loss: 410.5368 - val_mae: 19.1155\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.3801 - mae: 21.9418 - val_loss: 409.4193 - val_mae: 19.0752\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.0104 - mae: 21.8990 - val_loss: 408.2856 - val_mae: 19.0335\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.6219 - mae: 21.8536 - val_loss: 407.1772 - val_mae: 18.9918\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.2555 - mae: 21.8105 - val_loss: 406.0490 - val_mae: 18.9483\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 585.8636 - mae: 21.7646 - val_loss: 404.9428 - val_mae: 18.9046\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.4897 - mae: 21.7211 - val_loss: 403.8459 - val_mae: 18.8601\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 583.1262 - mae: 21.6741 - val_loss: 402.7809 - val_mae: 18.8157\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.7911 - mae: 21.6305 - val_loss: 401.7109 - val_mae: 18.7699\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.4463 - mae: 21.5853 - val_loss: 400.6606 - val_mae: 18.7240\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 579.1180 - mae: 21.5391 - val_loss: 399.6262 - val_mae: 18.6779\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.8043 - mae: 21.4921 - val_loss: 398.6210 - val_mae: 18.6319\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 576.5234 - mae: 21.4480 - val_loss: 397.6580 - val_mae: 18.5885\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.2792 - mae: 21.4008 - val_loss: 396.6930 - val_mae: 18.5440\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.0330 - mae: 21.3543 - val_loss: 395.7941 - val_mae: 18.5020\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.8572 - mae: 21.3109 - val_loss: 394.9107 - val_mae: 18.4591\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.6974 - mae: 21.2667 - val_loss: 394.0564 - val_mae: 18.4181\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.5641 - mae: 21.2243 - val_loss: 393.2542 - val_mae: 18.3798\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.4870 - mae: 21.1830 - val_loss: 392.4746 - val_mae: 18.3417\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.4316 - mae: 21.1424 - val_loss: 391.7188 - val_mae: 18.3059\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.3998 - mae: 21.0995 - val_loss: 391.0183 - val_mae: 18.2725\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.4290 - mae: 21.0626 - val_loss: 390.3483 - val_mae: 18.2412\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.4907 - mae: 21.0251 - val_loss: 389.7210 - val_mae: 18.2116\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.5989 - mae: 20.9897 - val_loss: 389.1164 - val_mae: 18.1839\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.7278 - mae: 20.9572 - val_loss: 388.5458 - val_mae: 18.1564\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.8933 - mae: 20.9227 - val_loss: 388.0204 - val_mae: 18.1296\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.1127 - mae: 20.8935 - val_loss: 387.5449 - val_mae: 18.1040\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.3891 - mae: 20.8676 - val_loss: 387.0918 - val_mae: 18.0782\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.6909 - mae: 20.8420 - val_loss: 386.6776 - val_mae: 18.0531\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.0306 - mae: 20.8177 - val_loss: 386.2844 - val_mae: 18.0285\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.3954 - mae: 20.7946 - val_loss: 385.9370 - val_mae: 18.0053\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.8167 - mae: 20.7738 - val_loss: 385.6215 - val_mae: 17.9834\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.2750 - mae: 20.7529 - val_loss: 385.3329 - val_mae: 17.9637\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.7654 - mae: 20.7351 - val_loss: 385.0630 - val_mae: 17.9449\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2736 - mae: 20.7171 - val_loss: 384.8305 - val_mae: 17.9280\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.8338 - mae: 20.7019 - val_loss: 384.6194 - val_mae: 17.9128\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.4147 - mae: 20.6869 - val_loss: 384.4387 - val_mae: 17.9018\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=25, model__optimizer=sgd; total time=   2.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 9274.3838 - mae: 40.1214 - val_loss: 548.6116 - val_mae: 21.8362\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2147 - mae: 21.8943 - val_loss: 548.5750 - val_mae: 21.8353\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.1630 - mae: 21.8931 - val_loss: 548.5030 - val_mae: 21.8337\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.0929 - mae: 21.8915 - val_loss: 548.4350 - val_mae: 21.8321\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.0248 - mae: 21.8899 - val_loss: 548.3672 - val_mae: 21.8306\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.9568 - mae: 21.8884 - val_loss: 548.2994 - val_mae: 21.8290\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.8887 - mae: 21.8868 - val_loss: 548.2309 - val_mae: 21.8274\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.8201 - mae: 21.8852 - val_loss: 548.1627 - val_mae: 21.8259\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.7517 - mae: 21.8837 - val_loss: 548.0947 - val_mae: 21.8243\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.6834 - mae: 21.8821 - val_loss: 548.0261 - val_mae: 21.8227\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.6146 - mae: 21.8805 - val_loss: 547.9576 - val_mae: 21.8211\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 753us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=25, model__optimizer=sgd; total time=   0.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 687.7164 - mae: 22.2375 - val_loss: 694.2960 - val_mae: 21.4985\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 687.3140 - mae: 22.2323 - val_loss: 693.4875 - val_mae: 21.4898\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.8774 - mae: 22.2270 - val_loss: 692.7159 - val_mae: 21.4813\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.4901 - mae: 22.2221 - val_loss: 691.9056 - val_mae: 21.4725\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 686.0781 - mae: 22.2169 - val_loss: 691.1425 - val_mae: 21.4641\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.6750 - mae: 22.2121 - val_loss: 690.3981 - val_mae: 21.4559\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 685.2983 - mae: 22.2072 - val_loss: 689.6489 - val_mae: 21.4477\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.9586 - mae: 22.2026 - val_loss: 688.8335 - val_mae: 21.4390\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.5074 - mae: 22.1974 - val_loss: 688.0957 - val_mae: 21.4309\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 684.1157 - mae: 22.1925 - val_loss: 687.3582 - val_mae: 21.4228\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.7518 - mae: 22.1878 - val_loss: 686.5734 - val_mae: 21.4144\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 683.3647 - mae: 22.1829 - val_loss: 685.8001 - val_mae: 21.4061\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.9803 - mae: 22.1782 - val_loss: 685.0472 - val_mae: 21.3979\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.6265 - mae: 22.1735 - val_loss: 684.3041 - val_mae: 21.3899\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 682.2489 - mae: 22.1688 - val_loss: 683.6016 - val_mae: 21.3822\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.8837 - mae: 22.1641 - val_loss: 682.9102 - val_mae: 21.3745\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.5527 - mae: 22.1598 - val_loss: 682.1526 - val_mae: 21.3662\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.1495 - mae: 22.1550 - val_loss: 681.4363 - val_mae: 21.3583\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.7643 - mae: 22.1503 - val_loss: 680.7134 - val_mae: 21.3503\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.4216 - mae: 22.1455 - val_loss: 679.9397 - val_mae: 21.3420\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 680.0398 - mae: 22.1408 - val_loss: 679.2153 - val_mae: 21.3342\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.6488 - mae: 22.1363 - val_loss: 678.5410 - val_mae: 21.3268\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 679.3088 - mae: 22.1319 - val_loss: 677.8140 - val_mae: 21.3191\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.9589 - mae: 22.1273 - val_loss: 677.0497 - val_mae: 21.3109\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.5718 - mae: 22.1226 - val_loss: 676.3488 - val_mae: 21.3032\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 678.2035 - mae: 22.1181 - val_loss: 675.6614 - val_mae: 21.2957\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.8723 - mae: 22.1138 - val_loss: 674.9637 - val_mae: 21.2881\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.5351 - mae: 22.1093 - val_loss: 674.2598 - val_mae: 21.2806\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 677.1484 - mae: 22.1050 - val_loss: 673.6362 - val_mae: 21.2736\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.8233 - mae: 22.1006 - val_loss: 672.9469 - val_mae: 21.2662\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.5015 - mae: 22.0965 - val_loss: 672.2159 - val_mae: 21.2583\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.1238 - mae: 22.0920 - val_loss: 671.5529 - val_mae: 21.2510\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.7689 - mae: 22.0876 - val_loss: 670.8892 - val_mae: 21.2436\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.4376 - mae: 22.0833 - val_loss: 670.1634 - val_mae: 21.2356\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 675.1025 - mae: 22.0786 - val_loss: 669.4159 - val_mae: 21.2275\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.6707 - mae: 22.0740 - val_loss: 668.7903 - val_mae: 21.2203\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.3317 - mae: 22.0693 - val_loss: 668.1519 - val_mae: 21.2131\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 674.0241 - mae: 22.0654 - val_loss: 667.4031 - val_mae: 21.2050\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.6276 - mae: 22.0608 - val_loss: 666.7365 - val_mae: 21.1975\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 673.2919 - mae: 22.0564 - val_loss: 666.0270 - val_mae: 21.1897\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.9401 - mae: 22.0521 - val_loss: 665.2944 - val_mae: 21.1814\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.5598 - mae: 22.0475 - val_loss: 664.5942 - val_mae: 21.1735\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 672.2023 - mae: 22.0428 - val_loss: 663.8656 - val_mae: 21.1653\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.8247 - mae: 22.0379 - val_loss: 663.1440 - val_mae: 21.1571\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.4617 - mae: 22.0332 - val_loss: 662.4019 - val_mae: 21.1488\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 671.0629 - mae: 22.0283 - val_loss: 661.7156 - val_mae: 21.1410\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.6797 - mae: 22.0236 - val_loss: 661.0416 - val_mae: 21.1332\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 670.3559 - mae: 22.0193 - val_loss: 660.2573 - val_mae: 21.1244\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.9560 - mae: 22.0143 - val_loss: 659.5405 - val_mae: 21.1162\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.6094 - mae: 22.0099 - val_loss: 658.8055 - val_mae: 21.1080\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 669.2244 - mae: 22.0053 - val_loss: 658.1085 - val_mae: 21.1000\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.8655 - mae: 22.0008 - val_loss: 657.4026 - val_mae: 21.0919\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.4857 - mae: 21.9962 - val_loss: 656.7269 - val_mae: 21.0841\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 668.1414 - mae: 21.9917 - val_loss: 656.0223 - val_mae: 21.0760\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.7579 - mae: 21.9870 - val_loss: 655.3249 - val_mae: 21.0682\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.4174 - mae: 21.9828 - val_loss: 654.5985 - val_mae: 21.0598\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 667.0479 - mae: 21.9783 - val_loss: 653.9126 - val_mae: 21.0519\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.7315 - mae: 21.9736 - val_loss: 653.1230 - val_mae: 21.0430\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 666.3167 - mae: 21.9687 - val_loss: 652.4387 - val_mae: 21.0349\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.9235 - mae: 21.9639 - val_loss: 651.8204 - val_mae: 21.0277\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.6052 - mae: 21.9596 - val_loss: 651.1141 - val_mae: 21.0195\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 665.2250 - mae: 21.9545 - val_loss: 650.4479 - val_mae: 21.0116\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.8774 - mae: 21.9501 - val_loss: 649.7759 - val_mae: 21.0037\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.5303 - mae: 21.9454 - val_loss: 649.0761 - val_mae: 20.9955\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 664.1433 - mae: 21.9406 - val_loss: 648.4368 - val_mae: 20.9878\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.8243 - mae: 21.9361 - val_loss: 647.7007 - val_mae: 20.9792\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.4217 - mae: 21.9309 - val_loss: 647.0275 - val_mae: 20.9712\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 663.0922 - mae: 21.9261 - val_loss: 646.2977 - val_mae: 20.9626\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.6649 - mae: 21.9210 - val_loss: 645.7039 - val_mae: 20.9552\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 662.3531 - mae: 21.9164 - val_loss: 644.9899 - val_mae: 20.9468\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.9824 - mae: 21.9115 - val_loss: 644.2991 - val_mae: 20.9386\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.6483 - mae: 21.9067 - val_loss: 643.5812 - val_mae: 20.9301\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 661.2490 - mae: 21.9016 - val_loss: 642.9550 - val_mae: 20.9225\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.9491 - mae: 21.8973 - val_loss: 642.2634 - val_mae: 20.9142\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.5551 - mae: 21.8921 - val_loss: 641.6239 - val_mae: 20.9064\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.2270 - mae: 21.8875 - val_loss: 640.9432 - val_mae: 20.8982\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 659.8900 - mae: 21.8827 - val_loss: 640.2509 - val_mae: 20.8899\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 659.4932 - mae: 21.8777 - val_loss: 639.6593 - val_mae: 20.8827\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 659.1901 - mae: 21.8733 - val_loss: 638.9991 - val_mae: 20.8747\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.8302 - mae: 21.8686 - val_loss: 638.3817 - val_mae: 20.8671\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.4954 - mae: 21.8637 - val_loss: 637.7275 - val_mae: 20.8591\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 658.1494 - mae: 21.8591 - val_loss: 637.0042 - val_mae: 20.8504\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.7591 - mae: 21.8541 - val_loss: 636.3585 - val_mae: 20.8427\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.4307 - mae: 21.8496 - val_loss: 635.6859 - val_mae: 20.8349\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 657.0689 - mae: 21.8449 - val_loss: 635.0298 - val_mae: 20.8272\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.7158 - mae: 21.8402 - val_loss: 634.3644 - val_mae: 20.8193\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.3718 - mae: 21.8356 - val_loss: 633.6968 - val_mae: 20.8113\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 656.0103 - mae: 21.8307 - val_loss: 633.0357 - val_mae: 20.8035\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 655.6722 - mae: 21.8259 - val_loss: 632.3455 - val_mae: 20.7953\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 655.2795 - mae: 21.8211 - val_loss: 631.6981 - val_mae: 20.7876\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.9412 - mae: 21.8168 - val_loss: 631.0544 - val_mae: 20.7800\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.6067 - mae: 21.8125 - val_loss: 630.3461 - val_mae: 20.7716\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 654.2349 - mae: 21.8076 - val_loss: 629.6925 - val_mae: 20.7638\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 653.8724 - mae: 21.8032 - val_loss: 629.0508 - val_mae: 20.7562\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 653.4901 - mae: 21.7985 - val_loss: 628.4606 - val_mae: 20.7488\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 653.1840 - mae: 21.7942 - val_loss: 627.7712 - val_mae: 20.7406\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.8083 - mae: 21.7893 - val_loss: 627.1199 - val_mae: 20.7328\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.4249 - mae: 21.7848 - val_loss: 626.5470 - val_mae: 20.7257\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 652.1224 - mae: 21.7804 - val_loss: 625.8722 - val_mae: 20.7177\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 651.7673 - mae: 21.7758 - val_loss: 625.2310 - val_mae: 20.7100\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=adam; total time=   2.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 48685.2227 - mae: 184.6966 - val_loss: 48418.0898 - val_mae: 182.0879\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48627.7578 - mae: 184.5826 - val_loss: 48361.0156 - val_mae: 181.9750\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48570.6562 - mae: 184.4689 - val_loss: 48303.8906 - val_mae: 181.8622\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48513.7539 - mae: 184.3552 - val_loss: 48246.8906 - val_mae: 181.7492\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48456.3789 - mae: 184.2411 - val_loss: 48190.2305 - val_mae: 181.6367\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48399.2422 - mae: 184.1274 - val_loss: 48133.6953 - val_mae: 181.5248\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48342.3438 - mae: 184.0138 - val_loss: 48077.0742 - val_mae: 181.4125\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48285.4922 - mae: 183.9007 - val_loss: 48020.5156 - val_mae: 181.3011\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48228.7305 - mae: 183.7879 - val_loss: 47964.0195 - val_mae: 181.1888\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48172.2812 - mae: 183.6751 - val_loss: 47907.4531 - val_mae: 181.0767\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48115.4883 - mae: 183.5618 - val_loss: 47851.0742 - val_mae: 180.9652\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48058.8672 - mae: 183.4488 - val_loss: 47794.9297 - val_mae: 180.8535\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 48002.2695 - mae: 183.3362 - val_loss: 47738.7461 - val_mae: 180.7421\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47946.0000 - mae: 183.2238 - val_loss: 47682.4258 - val_mae: 180.6312\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47889.5586 - mae: 183.1116 - val_loss: 47626.3164 - val_mae: 180.5199\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47832.8164 - mae: 182.9985 - val_loss: 47570.3906 - val_mae: 180.4083\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47776.8359 - mae: 182.8861 - val_loss: 47514.2852 - val_mae: 180.2970\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47720.9062 - mae: 182.7741 - val_loss: 47458.0938 - val_mae: 180.1854\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47664.2891 - mae: 182.6612 - val_loss: 47402.5000 - val_mae: 180.0750\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47608.1016 - mae: 182.5492 - val_loss: 47346.8906 - val_mae: 179.9643\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47552.1328 - mae: 182.4373 - val_loss: 47290.9844 - val_mae: 179.8536\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47496.3086 - mae: 182.3256 - val_loss: 47234.8750 - val_mae: 179.7424\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47440.0234 - mae: 182.2131 - val_loss: 47179.0039 - val_mae: 179.6312\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47383.8242 - mae: 182.1008 - val_loss: 47123.4961 - val_mae: 179.5209\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47328.3125 - mae: 181.9899 - val_loss: 47067.8828 - val_mae: 179.4104\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47272.5664 - mae: 181.8780 - val_loss: 47012.3906 - val_mae: 179.3000\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47216.7930 - mae: 181.7663 - val_loss: 46957.1211 - val_mae: 179.1897\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47161.2773 - mae: 181.6553 - val_loss: 46901.8594 - val_mae: 179.0807\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47106.1875 - mae: 181.5452 - val_loss: 46846.4766 - val_mae: 178.9701\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 47050.8594 - mae: 181.4339 - val_loss: 46791.2539 - val_mae: 178.8601\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46995.0312 - mae: 181.3220 - val_loss: 46736.4844 - val_mae: 178.7504\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46940.1641 - mae: 181.2110 - val_loss: 46681.4453 - val_mae: 178.6400\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46885.0703 - mae: 181.1001 - val_loss: 46626.5664 - val_mae: 178.5303\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46829.9023 - mae: 180.9889 - val_loss: 46572.0469 - val_mae: 178.4211\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 46775.0430 - mae: 180.8788 - val_loss: 46517.5078 - val_mae: 178.3130\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46720.1953 - mae: 180.7691 - val_loss: 46462.9805 - val_mae: 178.2035\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46665.6719 - mae: 180.6585 - val_loss: 46408.0352 - val_mae: 178.0937\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46610.5664 - mae: 180.5480 - val_loss: 46353.5000 - val_mae: 177.9850\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46556.1133 - mae: 180.4386 - val_loss: 46298.8750 - val_mae: 177.8761\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46501.2656 - mae: 180.3283 - val_loss: 46244.5234 - val_mae: 177.7676\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46446.2148 - mae: 180.2184 - val_loss: 46190.5312 - val_mae: 177.6598\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46392.0273 - mae: 180.1096 - val_loss: 46136.2188 - val_mae: 177.5514\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46337.4062 - mae: 179.9995 - val_loss: 46081.9219 - val_mae: 177.4427\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46283.0938 - mae: 179.8903 - val_loss: 46027.4453 - val_mae: 177.3344\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46228.1914 - mae: 179.7805 - val_loss: 45973.4453 - val_mae: 177.2259\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46174.5000 - mae: 179.6714 - val_loss: 45919.0078 - val_mae: 177.1167\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46120.0781 - mae: 179.5615 - val_loss: 45864.6953 - val_mae: 177.0076\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46065.3164 - mae: 179.4512 - val_loss: 45810.8789 - val_mae: 176.9002\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 46011.6875 - mae: 179.3431 - val_loss: 45756.8789 - val_mae: 176.7921\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45957.2266 - mae: 179.2339 - val_loss: 45703.2812 - val_mae: 176.6852\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45903.2188 - mae: 179.1255 - val_loss: 45649.5195 - val_mae: 176.5779\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45849.4570 - mae: 179.0173 - val_loss: 45595.5156 - val_mae: 176.4701\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45795.1602 - mae: 178.9088 - val_loss: 45541.9414 - val_mae: 176.3635\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45741.2227 - mae: 178.8004 - val_loss: 45488.3516 - val_mae: 176.2562\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45687.7773 - mae: 178.6923 - val_loss: 45434.5664 - val_mae: 176.1487\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45634.1406 - mae: 178.5844 - val_loss: 45380.9414 - val_mae: 176.0417\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45580.4336 - mae: 178.4760 - val_loss: 45327.5547 - val_mae: 175.9344\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45526.9688 - mae: 178.3682 - val_loss: 45274.1172 - val_mae: 175.8273\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45473.1172 - mae: 178.2596 - val_loss: 45220.9180 - val_mae: 175.7204\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45420.1328 - mae: 178.1519 - val_loss: 45167.3750 - val_mae: 175.6126\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45366.2266 - mae: 178.0428 - val_loss: 45114.3438 - val_mae: 175.5056\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 45313.0391 - mae: 177.9352 - val_loss: 45061.4062 - val_mae: 175.3991\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45259.5938 - mae: 177.8272 - val_loss: 45008.6484 - val_mae: 175.2929\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45206.7617 - mae: 177.7201 - val_loss: 44955.5781 - val_mae: 175.1859\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45153.8906 - mae: 177.6122 - val_loss: 44902.2539 - val_mae: 175.0786\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45100.6211 - mae: 177.5048 - val_loss: 44849.3945 - val_mae: 174.9731\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 45047.5898 - mae: 177.3977 - val_loss: 44796.6719 - val_mae: 174.8666\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44994.8398 - mae: 177.2909 - val_loss: 44743.8047 - val_mae: 174.7609\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44942.0234 - mae: 177.1841 - val_loss: 44691.0078 - val_mae: 174.6544\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44889.0078 - mae: 177.0764 - val_loss: 44638.4844 - val_mae: 174.5483\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44836.3555 - mae: 176.9697 - val_loss: 44585.9102 - val_mae: 174.4424\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44783.4492 - mae: 176.8623 - val_loss: 44533.4766 - val_mae: 174.3368\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44730.8164 - mae: 176.7554 - val_loss: 44481.1250 - val_mae: 174.2306\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44678.0859 - mae: 176.6480 - val_loss: 44428.8086 - val_mae: 174.1245\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44625.9297 - mae: 176.5416 - val_loss: 44376.1250 - val_mae: 174.0185\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44573.0977 - mae: 176.4345 - val_loss: 44323.8320 - val_mae: 173.9132\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44520.7891 - mae: 176.3284 - val_loss: 44271.6484 - val_mae: 173.8082\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44468.2734 - mae: 176.2219 - val_loss: 44219.6484 - val_mae: 173.7027\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44416.3320 - mae: 176.1158 - val_loss: 44167.2148 - val_mae: 173.5974\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44364.0703 - mae: 176.0095 - val_loss: 44114.8281 - val_mae: 173.4913\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44311.4141 - mae: 175.9029 - val_loss: 44062.9570 - val_mae: 173.3867\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 44259.3984 - mae: 175.7970 - val_loss: 44011.1328 - val_mae: 173.2819\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44207.5859 - mae: 175.6913 - val_loss: 43959.2734 - val_mae: 173.1771\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44155.6250 - mae: 175.5852 - val_loss: 43907.6680 - val_mae: 173.0722\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44104.1328 - mae: 175.4796 - val_loss: 43855.8242 - val_mae: 172.9671\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44052.3164 - mae: 175.3740 - val_loss: 43804.2422 - val_mae: 172.8631\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 44000.0977 - mae: 175.2682 - val_loss: 43752.8789 - val_mae: 172.7593\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43948.5117 - mae: 175.1632 - val_loss: 43701.3281 - val_mae: 172.6548\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43896.7109 - mae: 175.0575 - val_loss: 43649.9297 - val_mae: 172.5507\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43845.2031 - mae: 174.9522 - val_loss: 43598.3789 - val_mae: 172.4459\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43793.9336 - mae: 174.8467 - val_loss: 43546.4570 - val_mae: 172.3409\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43741.5977 - mae: 174.7399 - val_loss: 43495.3906 - val_mae: 172.2364\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43690.0664 - mae: 174.6340 - val_loss: 43444.2266 - val_mae: 172.1326\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43639.3477 - mae: 174.5294 - val_loss: 43392.5547 - val_mae: 172.0272\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43587.5508 - mae: 174.4234 - val_loss: 43341.4727 - val_mae: 171.9230\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43536.1680 - mae: 174.3180 - val_loss: 43290.5273 - val_mae: 171.8199\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43484.8906 - mae: 174.2129 - val_loss: 43239.5352 - val_mae: 171.7157\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43434.1211 - mae: 174.1080 - val_loss: 43188.1719 - val_mae: 171.6114\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 43382.5156 - mae: 174.0026 - val_loss: 43137.2266 - val_mae: 171.5080\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 43331.6367 - mae: 173.8980 - val_loss: 43086.1016 - val_mae: 171.4041\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=adam; total time=   2.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 11404.6621 - mae: 68.4916 - val_loss: 12502.6074 - val_mae: 71.3571\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11388.1592 - mae: 68.4274 - val_loss: 12485.2490 - val_mae: 71.2934\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11372.3564 - mae: 68.3642 - val_loss: 12467.6729 - val_mae: 71.2288\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11356.1914 - mae: 68.2997 - val_loss: 12450.2168 - val_mae: 71.1646\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11340.1230 - mae: 68.2351 - val_loss: 12432.7393 - val_mae: 71.1002\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11323.7324 - mae: 68.1706 - val_loss: 12415.5020 - val_mae: 71.0366\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 11307.7617 - mae: 68.1062 - val_loss: 12398.2324 - val_mae: 70.9729\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11291.7764 - mae: 68.0430 - val_loss: 12380.9678 - val_mae: 70.9091\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 11275.6885 - mae: 67.9788 - val_loss: 12363.7734 - val_mae: 70.8456\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11259.8096 - mae: 67.9155 - val_loss: 12346.4111 - val_mae: 70.7815\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11243.7510 - mae: 67.8514 - val_loss: 12329.1670 - val_mae: 70.7177\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11227.7861 - mae: 67.7883 - val_loss: 12312.0400 - val_mae: 70.6543\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11212.2520 - mae: 67.7248 - val_loss: 12294.5928 - val_mae: 70.5897\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11196.0459 - mae: 67.6607 - val_loss: 12277.3701 - val_mae: 70.5255\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11180.0391 - mae: 67.5968 - val_loss: 12260.3164 - val_mae: 70.4627\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11164.0615 - mae: 67.5341 - val_loss: 12243.4688 - val_mae: 70.4009\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11148.2383 - mae: 67.4710 - val_loss: 12226.5420 - val_mae: 70.3389\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11132.8076 - mae: 67.4088 - val_loss: 12209.2568 - val_mae: 70.2755\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11117.0156 - mae: 67.3452 - val_loss: 12191.9990 - val_mae: 70.2123\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11100.9756 - mae: 67.2808 - val_loss: 12174.9766 - val_mae: 70.1504\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11085.2959 - mae: 67.2182 - val_loss: 12157.9893 - val_mae: 70.0881\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11069.6064 - mae: 67.1549 - val_loss: 12141.0000 - val_mae: 70.0259\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11053.8516 - mae: 67.0918 - val_loss: 12124.1621 - val_mae: 69.9648\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11038.4551 - mae: 67.0298 - val_loss: 12107.2695 - val_mae: 69.9043\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11022.6641 - mae: 66.9670 - val_loss: 12090.6572 - val_mae: 69.8447\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 11007.0986 - mae: 66.9045 - val_loss: 12074.1104 - val_mae: 69.7854\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10991.8975 - mae: 66.8432 - val_loss: 12057.1006 - val_mae: 69.7245\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10976.6143 - mae: 66.7813 - val_loss: 12039.9697 - val_mae: 69.6629\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10960.8223 - mae: 66.7189 - val_loss: 12023.3086 - val_mae: 69.6031\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10945.3057 - mae: 66.6577 - val_loss: 12006.6680 - val_mae: 69.5435\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10930.2568 - mae: 66.5975 - val_loss: 11989.6494 - val_mae: 69.4822\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10915.0078 - mae: 66.5359 - val_loss: 11972.6367 - val_mae: 69.4207\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10899.3320 - mae: 66.4751 - val_loss: 11955.9355 - val_mae: 69.3602\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10884.0039 - mae: 66.4141 - val_loss: 11939.1680 - val_mae: 69.2996\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10868.7939 - mae: 66.3533 - val_loss: 11922.4150 - val_mae: 69.2390\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10853.3867 - mae: 66.2923 - val_loss: 11905.7920 - val_mae: 69.1787\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10837.8350 - mae: 66.2315 - val_loss: 11889.2432 - val_mae: 69.1187\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10822.7432 - mae: 66.1716 - val_loss: 11872.3574 - val_mae: 69.0573\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10807.6768 - mae: 66.1119 - val_loss: 11855.2109 - val_mae: 68.9949\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10792.1523 - mae: 66.0498 - val_loss: 11838.3945 - val_mae: 68.9338\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10776.6230 - mae: 65.9895 - val_loss: 11821.9502 - val_mae: 68.8741\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10761.4463 - mae: 65.9292 - val_loss: 11805.4463 - val_mae: 68.8141\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10746.4941 - mae: 65.8707 - val_loss: 11788.7666 - val_mae: 68.7533\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10731.1768 - mae: 65.8104 - val_loss: 11772.2373 - val_mae: 68.6930\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10716.2275 - mae: 65.7507 - val_loss: 11755.5635 - val_mae: 68.6323\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10700.7373 - mae: 65.6899 - val_loss: 11739.2744 - val_mae: 68.5728\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10685.8408 - mae: 65.6313 - val_loss: 11722.7197 - val_mae: 68.5123\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10670.9268 - mae: 65.5721 - val_loss: 11706.0234 - val_mae: 68.4513\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10656.0225 - mae: 65.5126 - val_loss: 11689.2070 - val_mae: 68.3893\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10640.3623 - mae: 65.4523 - val_loss: 11672.9893 - val_mae: 68.3296\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10625.5273 - mae: 65.3937 - val_loss: 11656.5791 - val_mae: 68.2689\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10610.4385 - mae: 65.3343 - val_loss: 11640.1318 - val_mae: 68.2081\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10595.8047 - mae: 65.2754 - val_loss: 11623.4385 - val_mae: 68.1464\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10580.7305 - mae: 65.2160 - val_loss: 11607.0859 - val_mae: 68.0860\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10565.6729 - mae: 65.1568 - val_loss: 11591.0303 - val_mae: 68.0266\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10551.0703 - mae: 65.0996 - val_loss: 11574.7002 - val_mae: 67.9661\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10536.2197 - mae: 65.0399 - val_loss: 11558.3203 - val_mae: 67.9052\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10521.3564 - mae: 64.9819 - val_loss: 11542.0117 - val_mae: 67.8442\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10506.5400 - mae: 64.9237 - val_loss: 11525.8574 - val_mae: 67.7835\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10491.7891 - mae: 64.8658 - val_loss: 11509.7129 - val_mae: 67.7227\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10477.3916 - mae: 64.8085 - val_loss: 11493.3242 - val_mae: 67.6609\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10462.3672 - mae: 64.7501 - val_loss: 11477.3887 - val_mae: 67.6007\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10447.6914 - mae: 64.6926 - val_loss: 11461.4668 - val_mae: 67.5409\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10433.4736 - mae: 64.6360 - val_loss: 11445.0195 - val_mae: 67.4800\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10418.1602 - mae: 64.5760 - val_loss: 11429.1436 - val_mae: 67.4210\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10403.7959 - mae: 64.5189 - val_loss: 11412.9873 - val_mae: 67.3610\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10389.1914 - mae: 64.4613 - val_loss: 11396.8457 - val_mae: 67.3011\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10374.4785 - mae: 64.4027 - val_loss: 11380.7705 - val_mae: 67.2413\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10359.8574 - mae: 64.3447 - val_loss: 11364.5771 - val_mae: 67.1810\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10345.2148 - mae: 64.2861 - val_loss: 11348.6260 - val_mae: 67.1215\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10330.8760 - mae: 64.2291 - val_loss: 11332.5576 - val_mae: 67.0615\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10316.1162 - mae: 64.1712 - val_loss: 11316.8076 - val_mae: 67.0025\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10301.9219 - mae: 64.1138 - val_loss: 11300.8574 - val_mae: 66.9430\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10287.1660 - mae: 64.0557 - val_loss: 11285.0537 - val_mae: 66.8843\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10272.8281 - mae: 63.9988 - val_loss: 11269.0049 - val_mae: 66.8254\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10258.2646 - mae: 63.9405 - val_loss: 11253.0928 - val_mae: 66.7669\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10243.6289 - mae: 63.8821 - val_loss: 11237.3574 - val_mae: 66.7091\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10229.2617 - mae: 63.8251 - val_loss: 11221.5898 - val_mae: 66.6510\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10214.8799 - mae: 63.7669 - val_loss: 11205.8936 - val_mae: 66.5932\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10200.7080 - mae: 63.7101 - val_loss: 11189.8818 - val_mae: 66.5342\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10186.3828 - mae: 63.6521 - val_loss: 11173.8066 - val_mae: 66.4749\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10171.6689 - mae: 63.5939 - val_loss: 11158.2256 - val_mae: 66.4175\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10157.4590 - mae: 63.5368 - val_loss: 11142.6992 - val_mae: 66.3600\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10143.2832 - mae: 63.4804 - val_loss: 11127.2461 - val_mae: 66.3026\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10128.8770 - mae: 63.4237 - val_loss: 11111.9443 - val_mae: 66.2455\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10114.8926 - mae: 63.3671 - val_loss: 11096.3389 - val_mae: 66.1875\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10100.9502 - mae: 63.3109 - val_loss: 11080.4082 - val_mae: 66.1280\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10086.4346 - mae: 63.2534 - val_loss: 11064.8291 - val_mae: 66.0699\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10072.2197 - mae: 63.1959 - val_loss: 11049.2812 - val_mae: 66.0119\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10058.0791 - mae: 63.1390 - val_loss: 11033.6992 - val_mae: 65.9537\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 10043.9492 - mae: 63.0818 - val_loss: 11018.1055 - val_mae: 65.8952\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10029.9492 - mae: 63.0256 - val_loss: 11002.5986 - val_mae: 65.8371\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10015.8867 - mae: 62.9690 - val_loss: 10987.2334 - val_mae: 65.7799\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 10001.5361 - mae: 62.9124 - val_loss: 10972.1338 - val_mae: 65.7240\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9987.9590 - mae: 62.8583 - val_loss: 10956.3916 - val_mae: 65.6655\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9973.5703 - mae: 62.8001 - val_loss: 10941.0068 - val_mae: 65.6087\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9959.8262 - mae: 62.7462 - val_loss: 10925.4980 - val_mae: 65.5519\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9945.4199 - mae: 62.6880 - val_loss: 10910.4395 - val_mae: 65.4970\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9931.9404 - mae: 62.6334 - val_loss: 10895.0605 - val_mae: 65.4408\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 9917.7441 - mae: 62.5779 - val_loss: 10880.1133 - val_mae: 65.3860\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=adam; total time=   2.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 632.0947 - mae: 20.6378 - val_loss: 294.4866 - val_mae: 14.8517\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 406.8235 - mae: 16.9361 - val_loss: 284.9319 - val_mae: 14.0912\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 394.0422 - mae: 16.4238 - val_loss: 286.0034 - val_mae: 14.3527\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 397.5779 - mae: 16.5466 - val_loss: 292.8165 - val_mae: 14.5929\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 398.7384 - mae: 16.5551 - val_loss: 280.8254 - val_mae: 13.9379\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 398.7137 - mae: 16.6639 - val_loss: 287.4084 - val_mae: 14.4359\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 397.4704 - mae: 16.4466 - val_loss: 280.5352 - val_mae: 13.8729\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 402.0796 - mae: 16.7726 - val_loss: 287.3614 - val_mae: 14.1956\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 392.7220 - mae: 16.3173 - val_loss: 295.5775 - val_mae: 14.7537\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 396.6584 - mae: 16.5331 - val_loss: 280.4720 - val_mae: 13.8506\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 393.1500 - mae: 16.3401 - val_loss: 280.5878 - val_mae: 13.8394\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 394.1192 - mae: 16.3543 - val_loss: 281.1261 - val_mae: 13.8384\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 393.2961 - mae: 16.3996 - val_loss: 295.5470 - val_mae: 14.7465\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 401.3104 - mae: 16.8158 - val_loss: 280.4434 - val_mae: 13.9234\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 391.3973 - mae: 16.2681 - val_loss: 280.7635 - val_mae: 13.8323\n",
      "Epoch 15: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=sgd; total time=   0.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 646.5110 - mae: 21.6669 - val_loss: 292.4208 - val_mae: 14.7187\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 426.4615 - mae: 17.0377 - val_loss: 280.9435 - val_mae: 13.8374\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 421.5255 - mae: 16.7792 - val_loss: 283.8203 - val_mae: 14.2917\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 418.7914 - mae: 16.7478 - val_loss: 284.3111 - val_mae: 14.3285\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 418.3373 - mae: 16.7228 - val_loss: 281.0291 - val_mae: 14.0425\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 419.5945 - mae: 16.7359 - val_loss: 279.5290 - val_mae: 13.7747\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 418.7766 - mae: 16.6472 - val_loss: 280.4763 - val_mae: 13.9903\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 423.2325 - mae: 16.7922 - val_loss: 281.6891 - val_mae: 14.0886\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 414.7676 - mae: 16.4781 - val_loss: 290.1238 - val_mae: 14.7135\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.5673 - mae: 16.5547 - val_loss: 292.6495 - val_mae: 14.8573\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 417.8094 - mae: 16.6763 - val_loss: 278.2704 - val_mae: 13.6446\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.2627 - mae: 16.4758 - val_loss: 285.5058 - val_mae: 14.3833\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 415.4762 - mae: 16.5546 - val_loss: 283.8289 - val_mae: 14.2535\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 416.5083 - mae: 16.6177 - val_loss: 278.5831 - val_mae: 13.7641\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 414.4811 - mae: 16.4841 - val_loss: 279.4745 - val_mae: 13.8597\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 414.9382 - mae: 16.4204 - val_loss: 279.0862 - val_mae: 13.8356\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.6925 - mae: 16.4764 - val_loss: 286.9621 - val_mae: 14.5011\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 417.2854 - mae: 16.5570 - val_loss: 279.1071 - val_mae: 13.8276\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.4765 - mae: 16.4075 - val_loss: 280.6919 - val_mae: 14.0083\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 414.7846 - mae: 16.4747 - val_loss: 282.8882 - val_mae: 14.1732\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.8247 - mae: 16.4357 - val_loss: 280.3061 - val_mae: 13.9724\n",
      "Epoch 21: early stopping\n",
      "5/5 [==============================] - 0s 648us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=sgd; total time=   0.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 333.4097 - mae: 15.0115 - val_loss: 198.0051 - val_mae: 11.7659\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 234.5921 - mae: 12.1003 - val_loss: 181.9061 - val_mae: 10.6772\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 194.0910 - mae: 10.9221 - val_loss: 232.3562 - val_mae: 13.0535\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.8213 - mae: 12.7298 - val_loss: 182.8980 - val_mae: 10.8558\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 216.7404 - mae: 11.6288 - val_loss: 347.5511 - val_mae: 16.6415\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 272.9976 - mae: 13.6413 - val_loss: 331.3383 - val_mae: 16.1538\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.3242 - mae: 11.9346 - val_loss: 208.0483 - val_mae: 12.1251\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.5100 - mae: 10.5009 - val_loss: 185.9504 - val_mae: 10.2271\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.4757 - mae: 10.9734 - val_loss: 286.6127 - val_mae: 14.5460\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 182.0577 - mae: 10.1474 - val_loss: 184.7906 - val_mae: 10.2152\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 197.1147 - mae: 10.9143 - val_loss: 252.4016 - val_mae: 13.2692\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 206.3871 - mae: 10.9608 - val_loss: 400.6270 - val_mae: 18.3381\n",
      "Epoch 12: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=sgd; total time=   0.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 706.7510 - mae: 21.2682 - val_loss: 364.1323 - val_mae: 16.8178\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 443.5637 - mae: 18.1203 - val_loss: 334.5940 - val_mae: 16.1488\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 427.4171 - mae: 17.6819 - val_loss: 321.2320 - val_mae: 15.7514\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 418.9711 - mae: 17.4269 - val_loss: 314.1529 - val_mae: 15.4790\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 412.0507 - mae: 17.2256 - val_loss: 307.3709 - val_mae: 15.2605\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 407.2481 - mae: 17.0725 - val_loss: 301.3309 - val_mae: 15.0691\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 402.3348 - mae: 16.9280 - val_loss: 295.7913 - val_mae: 14.8822\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 396.7198 - mae: 16.7414 - val_loss: 289.9285 - val_mae: 14.6695\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 385.3416 - mae: 16.4478 - val_loss: 279.6793 - val_mae: 14.2954\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 373.2377 - mae: 16.1039 - val_loss: 270.2231 - val_mae: 13.9503\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.7071 - mae: 15.8417 - val_loss: 264.8584 - val_mae: 13.7339\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 360.3665 - mae: 15.6321 - val_loss: 260.1368 - val_mae: 13.5372\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 356.7481 - mae: 15.4908 - val_loss: 258.3524 - val_mae: 13.4773\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.4999 - mae: 15.4383 - val_loss: 254.7045 - val_mae: 13.2959\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 351.9430 - mae: 15.3043 - val_loss: 252.4727 - val_mae: 13.1889\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 350.4978 - mae: 15.2513 - val_loss: 250.7885 - val_mae: 13.0886\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 349.1846 - mae: 15.1796 - val_loss: 250.1756 - val_mae: 13.0604\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 347.8712 - mae: 15.1414 - val_loss: 249.2778 - val_mae: 13.0061\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 346.8103 - mae: 15.0861 - val_loss: 249.5260 - val_mae: 13.0181\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 346.3593 - mae: 15.0873 - val_loss: 248.6076 - val_mae: 12.9759\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 345.4156 - mae: 15.0841 - val_loss: 246.6976 - val_mae: 12.8725\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 344.8832 - mae: 15.0236 - val_loss: 245.9669 - val_mae: 12.8237\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 344.2119 - mae: 14.9780 - val_loss: 246.3648 - val_mae: 12.8303\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 343.6003 - mae: 14.9719 - val_loss: 246.0607 - val_mae: 12.8267\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 343.3441 - mae: 14.9913 - val_loss: 244.8325 - val_mae: 12.7528\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.7003 - mae: 14.9336 - val_loss: 245.1421 - val_mae: 12.7691\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.6054 - mae: 14.9408 - val_loss: 244.3937 - val_mae: 12.7250\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.3221 - mae: 14.9208 - val_loss: 243.8748 - val_mae: 12.6902\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.0172 - mae: 14.8991 - val_loss: 244.3888 - val_mae: 12.7239\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 341.4313 - mae: 14.9194 - val_loss: 243.0686 - val_mae: 12.6470\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 341.3167 - mae: 14.8732 - val_loss: 242.6729 - val_mae: 12.6195\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 341.0952 - mae: 14.8250 - val_loss: 243.4843 - val_mae: 12.6794\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.9803 - mae: 14.8932 - val_loss: 242.7993 - val_mae: 12.6452\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.5161 - mae: 14.8469 - val_loss: 242.8902 - val_mae: 12.6461\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.4105 - mae: 14.8304 - val_loss: 243.0793 - val_mae: 12.6715\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.4274 - mae: 14.8592 - val_loss: 242.3315 - val_mae: 12.6160\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.0807 - mae: 14.8396 - val_loss: 241.9354 - val_mae: 12.5858\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.1289 - mae: 14.8283 - val_loss: 241.4877 - val_mae: 12.5645\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.7481 - mae: 14.7841 - val_loss: 242.0496 - val_mae: 12.6135\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.7957 - mae: 14.8033 - val_loss: 242.5751 - val_mae: 12.6525\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.6467 - mae: 14.8564 - val_loss: 241.1603 - val_mae: 12.5496\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.3004 - mae: 14.7947 - val_loss: 241.1723 - val_mae: 12.5549\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.3851 - mae: 14.8022 - val_loss: 240.8996 - val_mae: 12.5425\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.0085 - mae: 14.7904 - val_loss: 240.7310 - val_mae: 12.5308\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.0779 - mae: 14.8077 - val_loss: 240.5126 - val_mae: 12.5188\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.7736 - mae: 14.7794 - val_loss: 240.4422 - val_mae: 12.5207\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.3127 - mae: 14.7668 - val_loss: 240.7020 - val_mae: 12.5425\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.5903 - mae: 14.7632 - val_loss: 240.7661 - val_mae: 12.5452\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.4238 - mae: 14.7528 - val_loss: 241.6725 - val_mae: 12.6242\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.4138 - mae: 14.7783 - val_loss: 240.6084 - val_mae: 12.5442\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.1427 - mae: 14.7356 - val_loss: 240.8298 - val_mae: 12.5566\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.2602 - mae: 14.7693 - val_loss: 240.4218 - val_mae: 12.5333\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 338.0097 - mae: 14.7348 - val_loss: 240.6502 - val_mae: 12.5585\n",
      "Epoch 53: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   1.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 1152.4910 - mae: 25.6223 - val_loss: 484.2113 - val_mae: 19.1455\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 543.1503 - mae: 19.9640 - val_loss: 367.9087 - val_mae: 16.7479\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 484.3420 - mae: 18.6919 - val_loss: 333.3621 - val_mae: 15.8137\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 463.0931 - mae: 18.1685 - val_loss: 318.2404 - val_mae: 15.3846\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 452.3306 - mae: 17.8684 - val_loss: 310.8645 - val_mae: 15.1779\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 446.1323 - mae: 17.7128 - val_loss: 305.3330 - val_mae: 15.0199\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 441.0329 - mae: 17.5462 - val_loss: 301.5154 - val_mae: 14.9148\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 437.0476 - mae: 17.4316 - val_loss: 298.6889 - val_mae: 14.8342\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 433.1496 - mae: 17.3341 - val_loss: 295.7711 - val_mae: 14.7473\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 430.1387 - mae: 17.2577 - val_loss: 292.9238 - val_mae: 14.6752\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 427.3247 - mae: 17.1784 - val_loss: 290.2292 - val_mae: 14.5848\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 424.7856 - mae: 17.0927 - val_loss: 288.1616 - val_mae: 14.5434\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 421.4564 - mae: 17.0248 - val_loss: 285.8903 - val_mae: 14.4735\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 418.9857 - mae: 16.9584 - val_loss: 283.3749 - val_mae: 14.3578\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 416.8352 - mae: 16.8664 - val_loss: 281.8593 - val_mae: 14.3018\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.1227 - mae: 16.8403 - val_loss: 279.9992 - val_mae: 14.2344\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.3227 - mae: 16.7841 - val_loss: 279.1997 - val_mae: 14.2215\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 411.5908 - mae: 16.7478 - val_loss: 277.5983 - val_mae: 14.1598\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 410.0957 - mae: 16.6812 - val_loss: 277.0498 - val_mae: 14.1421\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 408.6619 - mae: 16.6544 - val_loss: 275.6580 - val_mae: 14.0977\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 406.6903 - mae: 16.6138 - val_loss: 272.6344 - val_mae: 13.9791\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 403.9304 - mae: 16.5088 - val_loss: 270.2915 - val_mae: 13.9141\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 400.5526 - mae: 16.4192 - val_loss: 267.8705 - val_mae: 13.8435\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 396.7933 - mae: 16.3368 - val_loss: 265.1473 - val_mae: 13.7144\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 392.2764 - mae: 16.2201 - val_loss: 261.1390 - val_mae: 13.5830\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 388.3227 - mae: 16.0834 - val_loss: 258.5462 - val_mae: 13.4938\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 384.8696 - mae: 15.9918 - val_loss: 254.9492 - val_mae: 13.3567\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 382.0778 - mae: 15.9049 - val_loss: 252.7518 - val_mae: 13.2626\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 379.7270 - mae: 15.8270 - val_loss: 251.3704 - val_mae: 13.2001\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 378.1090 - mae: 15.7731 - val_loss: 250.3018 - val_mae: 13.1446\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 377.0254 - mae: 15.7402 - val_loss: 248.7638 - val_mae: 13.0649\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 376.0900 - mae: 15.6847 - val_loss: 249.1706 - val_mae: 13.0733\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 374.9687 - mae: 15.6948 - val_loss: 247.8596 - val_mae: 12.9956\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 374.2809 - mae: 15.6522 - val_loss: 247.3995 - val_mae: 12.9664\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 373.5586 - mae: 15.6266 - val_loss: 246.9888 - val_mae: 12.9351\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 373.0387 - mae: 15.6258 - val_loss: 245.5879 - val_mae: 12.8573\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 372.6817 - mae: 15.5910 - val_loss: 244.9521 - val_mae: 12.8204\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 372.1738 - mae: 15.5693 - val_loss: 244.2434 - val_mae: 12.7813\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 371.7024 - mae: 15.5617 - val_loss: 243.7878 - val_mae: 12.7544\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 371.2753 - mae: 15.5170 - val_loss: 244.7928 - val_mae: 12.8078\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 371.0959 - mae: 15.5684 - val_loss: 243.0748 - val_mae: 12.7105\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.6096 - mae: 15.5261 - val_loss: 242.5303 - val_mae: 12.6822\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.3734 - mae: 15.4934 - val_loss: 242.9042 - val_mae: 12.6993\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.0613 - mae: 15.5036 - val_loss: 242.6249 - val_mae: 12.6804\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.1245 - mae: 15.5566 - val_loss: 241.3616 - val_mae: 12.6197\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.7748 - mae: 15.4584 - val_loss: 241.7634 - val_mae: 12.6327\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.4786 - mae: 15.4633 - val_loss: 241.7417 - val_mae: 12.6298\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.2567 - mae: 15.4648 - val_loss: 241.7845 - val_mae: 12.6303\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.9423 - mae: 15.4397 - val_loss: 243.5281 - val_mae: 12.7257\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.8910 - mae: 15.4954 - val_loss: 241.4710 - val_mae: 12.6135\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.5388 - mae: 15.4522 - val_loss: 241.1542 - val_mae: 12.5973\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 368.6589 - mae: 15.4548 - val_loss: 241.3101 - val_mae: 12.6020\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.1185 - mae: 15.4426 - val_loss: 240.9619 - val_mae: 12.5864\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.1146 - mae: 15.4483 - val_loss: 239.9480 - val_mae: 12.5289\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.8414 - mae: 15.3989 - val_loss: 241.0084 - val_mae: 12.5860\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.8542 - mae: 15.4473 - val_loss: 240.3103 - val_mae: 12.5476\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.5246 - mae: 15.4036 - val_loss: 240.7974 - val_mae: 12.5678\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.3538 - mae: 15.4210 - val_loss: 240.3183 - val_mae: 12.5431\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.3001 - mae: 15.3952 - val_loss: 240.2478 - val_mae: 12.5364\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.2320 - mae: 15.4048 - val_loss: 240.2016 - val_mae: 12.5337\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.2435 - mae: 15.4137 - val_loss: 239.5628 - val_mae: 12.4955\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.7973 - mae: 15.3987 - val_loss: 238.6677 - val_mae: 12.4414\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.7120 - mae: 15.3748 - val_loss: 238.5724 - val_mae: 12.4380\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.5793 - mae: 15.3642 - val_loss: 238.7505 - val_mae: 12.4476\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.7122 - mae: 15.3388 - val_loss: 239.3346 - val_mae: 12.4779\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.3579 - mae: 15.3614 - val_loss: 239.7409 - val_mae: 12.4983\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.2513 - mae: 15.3903 - val_loss: 238.5771 - val_mae: 12.4364\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.2011 - mae: 15.3556 - val_loss: 238.7045 - val_mae: 12.4356\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.1992 - mae: 15.3688 - val_loss: 238.6560 - val_mae: 12.4349\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.9025 - mae: 15.3372 - val_loss: 238.6132 - val_mae: 12.4258\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.7379 - mae: 15.3724 - val_loss: 237.5440 - val_mae: 12.3648\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.9839 - mae: 15.3143 - val_loss: 238.1694 - val_mae: 12.3928\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.6851 - mae: 15.3372 - val_loss: 237.9574 - val_mae: 12.3821\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.3929 - mae: 15.3159 - val_loss: 238.8545 - val_mae: 12.4285\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.5074 - mae: 15.3526 - val_loss: 238.4040 - val_mae: 12.4028\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.6541 - mae: 15.3142 - val_loss: 238.6411 - val_mae: 12.4105\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.1491 - mae: 15.3306 - val_loss: 238.3301 - val_mae: 12.3914\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.0144 - mae: 15.3649 - val_loss: 236.8769 - val_mae: 12.3150\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 364.9141 - mae: 15.2862 - val_loss: 237.1785 - val_mae: 12.3295\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 364.9352 - mae: 15.3040 - val_loss: 237.1398 - val_mae: 12.3227\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 364.7505 - mae: 15.3042 - val_loss: 236.6121 - val_mae: 12.2908\n",
      "Epoch 81: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   2.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 1372.7035 - mae: 25.0605 - val_loss: 441.1451 - val_mae: 17.5940\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 455.0650 - mae: 17.2977 - val_loss: 340.8990 - val_mae: 15.3964\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 364.7400 - mae: 15.4974 - val_loss: 309.3277 - val_mae: 14.4484\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 327.6800 - mae: 14.5834 - val_loss: 294.0529 - val_mae: 13.9292\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 308.5345 - mae: 14.1134 - val_loss: 285.7701 - val_mae: 13.6396\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.9011 - mae: 13.8024 - val_loss: 279.8739 - val_mae: 13.4525\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 291.7677 - mae: 13.6411 - val_loss: 275.5580 - val_mae: 13.3650\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 285.8141 - mae: 13.5371 - val_loss: 270.8241 - val_mae: 13.1429\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.9989 - mae: 13.2629 - val_loss: 258.6612 - val_mae: 12.8125\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.8366 - mae: 12.8807 - val_loss: 251.0931 - val_mae: 12.4793\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.6221 - mae: 12.5418 - val_loss: 246.1807 - val_mae: 12.3701\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 251.6601 - mae: 12.4257 - val_loss: 243.5710 - val_mae: 12.2562\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 248.5845 - mae: 12.2764 - val_loss: 241.7856 - val_mae: 12.2233\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.4689 - mae: 12.2040 - val_loss: 240.5478 - val_mae: 12.1730\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 244.7204 - mae: 12.1550 - val_loss: 239.8923 - val_mae: 12.1179\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 243.3847 - mae: 12.0692 - val_loss: 238.4713 - val_mae: 12.1295\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 241.8560 - mae: 12.0782 - val_loss: 239.4249 - val_mae: 12.0375\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 241.3642 - mae: 11.9762 - val_loss: 236.8338 - val_mae: 11.9825\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.1533 - mae: 11.9311 - val_loss: 235.9140 - val_mae: 11.9820\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 239.0463 - mae: 11.8888 - val_loss: 234.8620 - val_mae: 11.9261\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.4469 - mae: 11.8804 - val_loss: 233.6736 - val_mae: 11.9003\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.9718 - mae: 11.8096 - val_loss: 231.9645 - val_mae: 11.9085\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.2683 - mae: 11.8086 - val_loss: 230.5342 - val_mae: 11.8703\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 235.0405 - mae: 11.7846 - val_loss: 229.1767 - val_mae: 11.8190\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.7207 - mae: 11.7547 - val_loss: 227.9728 - val_mae: 11.7582\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 232.4697 - mae: 11.6843 - val_loss: 226.3361 - val_mae: 11.7538\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 231.6353 - mae: 11.7147 - val_loss: 224.6544 - val_mae: 11.6107\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.8506 - mae: 11.6137 - val_loss: 222.6560 - val_mae: 11.5198\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 227.8916 - mae: 11.5210 - val_loss: 220.7251 - val_mae: 11.4386\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 226.8962 - mae: 11.5021 - val_loss: 218.9230 - val_mae: 11.4153\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.4756 - mae: 11.4792 - val_loss: 218.2276 - val_mae: 11.3595\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.5094 - mae: 11.3935 - val_loss: 216.3521 - val_mae: 11.3736\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.5584 - mae: 11.4124 - val_loss: 215.0719 - val_mae: 11.2873\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.1338 - mae: 11.2970 - val_loss: 212.0518 - val_mae: 11.1986\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 217.5349 - mae: 11.1947 - val_loss: 209.7281 - val_mae: 11.1796\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.5853 - mae: 11.1947 - val_loss: 209.2347 - val_mae: 11.0970\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.4573 - mae: 11.1679 - val_loss: 208.6190 - val_mae: 11.0576\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.6355 - mae: 11.0852 - val_loss: 207.2546 - val_mae: 11.0147\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.1470 - mae: 11.0794 - val_loss: 206.1836 - val_mae: 10.9983\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 212.5789 - mae: 11.0327 - val_loss: 205.8123 - val_mae: 10.9593\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 212.0530 - mae: 11.0031 - val_loss: 204.9849 - val_mae: 10.9372\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.2002 - mae: 10.9093 - val_loss: 208.1270 - val_mae: 11.2309\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.7886 - mae: 11.0920 - val_loss: 203.3936 - val_mae: 10.8970\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 210.4189 - mae: 10.9281 - val_loss: 202.9034 - val_mae: 10.8586\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.5168 - mae: 10.8749 - val_loss: 201.9988 - val_mae: 10.8561\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.7968 - mae: 10.8548 - val_loss: 201.8940 - val_mae: 10.8907\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.5281 - mae: 10.9107 - val_loss: 202.5323 - val_mae: 10.7831\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.4199 - mae: 10.7958 - val_loss: 200.5202 - val_mae: 10.7735\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.8930 - mae: 10.8423 - val_loss: 200.1385 - val_mae: 10.7520\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.4235 - mae: 10.7739 - val_loss: 199.8199 - val_mae: 10.7848\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 206.9348 - mae: 10.7991 - val_loss: 199.1887 - val_mae: 10.7120\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.0914 - mae: 10.7634 - val_loss: 198.5494 - val_mae: 10.7082\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 206.1463 - mae: 10.7290 - val_loss: 198.2368 - val_mae: 10.7345\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.7786 - mae: 10.7488 - val_loss: 197.6023 - val_mae: 10.6989\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.7931 - mae: 10.7222 - val_loss: 197.2569 - val_mae: 10.6825\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.5054 - mae: 10.7339 - val_loss: 197.1819 - val_mae: 10.6189\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.9281 - mae: 10.6671 - val_loss: 196.2643 - val_mae: 10.6172\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.9332 - mae: 10.6858 - val_loss: 196.1892 - val_mae: 10.6132\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.4724 - mae: 10.6427 - val_loss: 195.4605 - val_mae: 10.6419\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.0658 - mae: 10.7046 - val_loss: 195.8161 - val_mae: 10.5641\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 203.6829 - mae: 10.5972 - val_loss: 195.1189 - val_mae: 10.5751\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 203.1893 - mae: 10.6407 - val_loss: 194.5231 - val_mae: 10.5387\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.9783 - mae: 10.6143 - val_loss: 194.5869 - val_mae: 10.5037\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.9100 - mae: 10.5651 - val_loss: 193.5879 - val_mae: 10.5290\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.4569 - mae: 10.6234 - val_loss: 193.9039 - val_mae: 10.4705\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.7464 - mae: 10.5470 - val_loss: 193.2448 - val_mae: 10.5336\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.0945 - mae: 10.5746 - val_loss: 192.7158 - val_mae: 10.4955\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.2863 - mae: 10.6120 - val_loss: 193.0128 - val_mae: 10.4209\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 201.6083 - mae: 10.5035 - val_loss: 191.8090 - val_mae: 10.4673\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 201.2804 - mae: 10.5754 - val_loss: 192.4299 - val_mae: 10.4011\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.9198 - mae: 10.4686 - val_loss: 191.3707 - val_mae: 10.4275\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.7032 - mae: 10.5235 - val_loss: 191.3919 - val_mae: 10.3778\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.3542 - mae: 10.4151 - val_loss: 190.9461 - val_mae: 10.4543\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.6629 - mae: 10.5285 - val_loss: 190.6956 - val_mae: 10.4102\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.1191 - mae: 10.5003 - val_loss: 190.5727 - val_mae: 10.3420\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.9811 - mae: 10.4255 - val_loss: 190.2728 - val_mae: 10.4277\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.8016 - mae: 10.5176 - val_loss: 189.7410 - val_mae: 10.3217\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.6982 - mae: 10.4399 - val_loss: 189.4380 - val_mae: 10.3720\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 198.8194 - mae: 10.5013 - val_loss: 190.9573 - val_mae: 10.3107\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.5636 - mae: 10.3938 - val_loss: 189.2430 - val_mae: 10.2737\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.1568 - mae: 10.3914 - val_loss: 188.4203 - val_mae: 10.3150\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.6395 - mae: 10.4561 - val_loss: 188.4570 - val_mae: 10.2660\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.6626 - mae: 10.3761 - val_loss: 187.9982 - val_mae: 10.3260\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.3820 - mae: 10.4200 - val_loss: 187.7371 - val_mae: 10.3030\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.0087 - mae: 10.4340 - val_loss: 188.0611 - val_mae: 10.2294\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.3687 - mae: 10.3827 - val_loss: 187.8301 - val_mae: 10.2104\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.1935 - mae: 10.3617 - val_loss: 187.4143 - val_mae: 10.2061\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.4219 - mae: 10.3303 - val_loss: 186.8988 - val_mae: 10.2010\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.2499 - mae: 10.3243 - val_loss: 186.4114 - val_mae: 10.2229\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.8418 - mae: 10.3680 - val_loss: 186.5229 - val_mae: 10.2560\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.1764 - mae: 10.3528 - val_loss: 185.9856 - val_mae: 10.2107\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.0159 - mae: 10.3241 - val_loss: 186.4591 - val_mae: 10.2934\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 196.7458 - mae: 10.4097 - val_loss: 185.6233 - val_mae: 10.1632\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.9465 - mae: 10.3638 - val_loss: 185.6737 - val_mae: 10.1322\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.7396 - mae: 10.2833 - val_loss: 185.1041 - val_mae: 10.1674\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.3131 - mae: 10.3242 - val_loss: 184.9834 - val_mae: 10.1162\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.1219 - mae: 10.2850 - val_loss: 184.9563 - val_mae: 10.1039\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 195.8683 - mae: 10.2678 - val_loss: 184.5396 - val_mae: 10.0959\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 195.8568 - mae: 10.2692 - val_loss: 184.2958 - val_mae: 10.0841\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 195.5152 - mae: 10.2878 - val_loss: 184.5766 - val_mae: 10.0666\n",
      "5/5 [==============================] - 0s 567us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   2.7s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24492.2461 - mae: 74.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=0, model__n_neurons=125, model__optimizer=sgd; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=0, model__n_neurons=125, model__optimizer=sgd; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 754us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=0, model__n_neurons=125, model__optimizer=sgd; total time=   0.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 867.4385 - mae: 22.8652 - val_loss: 793.8186 - val_mae: 21.3826\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 798.9672 - mae: 21.8645 - val_loss: 724.0364 - val_mae: 20.3704\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 736.5084 - mae: 20.9473 - val_loss: 662.4423 - val_mae: 19.4549\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 681.8459 - mae: 20.1258 - val_loss: 607.6594 - val_mae: 18.6299\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.8713 - mae: 19.3900 - val_loss: 559.0445 - val_mae: 17.8856\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.7199 - mae: 18.7002 - val_loss: 516.2678 - val_mae: 17.2028\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 551.3243 - mae: 18.0630 - val_loss: 477.4118 - val_mae: 16.5476\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 516.4276 - mae: 17.4588 - val_loss: 442.8824 - val_mae: 15.9423\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 485.1994 - mae: 16.8994 - val_loss: 412.3209 - val_mae: 15.3806\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 457.5935 - mae: 16.3947 - val_loss: 385.7408 - val_mae: 14.8808\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 433.9065 - mae: 15.9427 - val_loss: 361.7413 - val_mae: 14.4161\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.4105 - mae: 15.5335 - val_loss: 340.8591 - val_mae: 14.0040\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 393.4497 - mae: 15.1714 - val_loss: 321.8669 - val_mae: 13.6203\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 376.7288 - mae: 14.8390 - val_loss: 304.4598 - val_mae: 13.2718\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 360.2753 - mae: 14.5208 - val_loss: 288.6469 - val_mae: 12.9305\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 345.8391 - mae: 14.2234 - val_loss: 274.5505 - val_mae: 12.6142\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 333.4962 - mae: 13.9622 - val_loss: 261.6541 - val_mae: 12.3308\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 322.4220 - mae: 13.7219 - val_loss: 250.1112 - val_mae: 12.0745\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 312.1744 - mae: 13.4989 - val_loss: 239.6793 - val_mae: 11.8315\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.6949 - mae: 13.2918 - val_loss: 230.1886 - val_mae: 11.6093\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.8805 - mae: 13.0970 - val_loss: 221.3672 - val_mae: 11.4028\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 285.3288 - mae: 12.8979 - val_loss: 212.2265 - val_mae: 11.1598\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.6124 - mae: 12.6636 - val_loss: 203.0176 - val_mae: 10.8907\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 268.6312 - mae: 12.4359 - val_loss: 195.6241 - val_mae: 10.6677\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.0696 - mae: 12.2549 - val_loss: 189.7445 - val_mae: 10.4868\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 256.6792 - mae: 12.0983 - val_loss: 184.5374 - val_mae: 10.3207\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 252.3536 - mae: 11.9697 - val_loss: 179.8609 - val_mae: 10.1734\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 248.2988 - mae: 11.8563 - val_loss: 175.4622 - val_mae: 10.0307\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 244.2199 - mae: 11.7330 - val_loss: 170.4200 - val_mae: 9.8559\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 239.7691 - mae: 11.6072 - val_loss: 166.7018 - val_mae: 9.7309\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.4078 - mae: 11.5001 - val_loss: 163.5839 - val_mae: 9.6147\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.8316 - mae: 11.4083 - val_loss: 160.7535 - val_mae: 9.5000\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 231.6717 - mae: 11.3271 - val_loss: 158.4881 - val_mae: 9.4189\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.6531 - mae: 11.2672 - val_loss: 156.4979 - val_mae: 9.3440\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 227.6630 - mae: 11.2074 - val_loss: 153.9225 - val_mae: 9.2506\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.4841 - mae: 11.1144 - val_loss: 150.8630 - val_mae: 9.1352\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 221.6899 - mae: 11.0219 - val_loss: 148.5435 - val_mae: 9.0446\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.8320 - mae: 10.9471 - val_loss: 147.0104 - val_mae: 8.9769\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 218.5402 - mae: 10.8928 - val_loss: 145.3916 - val_mae: 8.9032\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 217.1445 - mae: 10.8371 - val_loss: 143.4762 - val_mae: 8.8291\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 215.0342 - mae: 10.7836 - val_loss: 141.6178 - val_mae: 8.7706\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 212.5491 - mae: 10.7159 - val_loss: 140.0418 - val_mae: 8.6865\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.0314 - mae: 10.6543 - val_loss: 139.1042 - val_mae: 8.6330\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 210.0648 - mae: 10.6091 - val_loss: 138.0146 - val_mae: 8.5825\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.2728 - mae: 10.5739 - val_loss: 137.0268 - val_mae: 8.5379\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.4246 - mae: 10.5370 - val_loss: 136.0317 - val_mae: 8.4903\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.7496 - mae: 10.5030 - val_loss: 135.0677 - val_mae: 8.4404\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.0468 - mae: 10.4646 - val_loss: 134.4350 - val_mae: 8.4110\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 206.3793 - mae: 10.4438 - val_loss: 133.8870 - val_mae: 8.3879\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.5899 - mae: 10.4263 - val_loss: 133.4182 - val_mae: 8.3777\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.6266 - mae: 10.4064 - val_loss: 132.2417 - val_mae: 8.3330\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.9186 - mae: 10.3576 - val_loss: 130.5853 - val_mae: 8.2757\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.8720 - mae: 10.2954 - val_loss: 128.4418 - val_mae: 8.1861\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.6928 - mae: 10.2287 - val_loss: 127.1336 - val_mae: 8.1459\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.7420 - mae: 10.1423 - val_loss: 125.1794 - val_mae: 8.0267\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 195.3947 - mae: 10.0699 - val_loss: 124.4512 - val_mae: 7.9964\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 194.8476 - mae: 10.0547 - val_loss: 123.8948 - val_mae: 7.9728\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 194.3197 - mae: 10.0365 - val_loss: 123.3715 - val_mae: 7.9429\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.8279 - mae: 10.0295 - val_loss: 123.2996 - val_mae: 7.9499\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.3484 - mae: 10.0107 - val_loss: 122.6101 - val_mae: 7.9001\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 192.9062 - mae: 9.9737 - val_loss: 122.0220 - val_mae: 7.8546\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 192.5479 - mae: 9.9534 - val_loss: 121.8804 - val_mae: 7.8513\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 192.1149 - mae: 9.9332 - val_loss: 121.3419 - val_mae: 7.8090\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.7827 - mae: 9.9062 - val_loss: 120.9562 - val_mae: 7.7826\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.4656 - mae: 9.8837 - val_loss: 120.7073 - val_mae: 7.7715\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.0959 - mae: 9.8852 - val_loss: 120.5693 - val_mae: 7.7683\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.7637 - mae: 9.8720 - val_loss: 120.1954 - val_mae: 7.7405\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 190.4729 - mae: 9.8630 - val_loss: 120.0027 - val_mae: 7.7318\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.2542 - mae: 9.8639 - val_loss: 119.9866 - val_mae: 7.7391\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 189.8661 - mae: 9.8425 - val_loss: 119.5306 - val_mae: 7.7029\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.5827 - mae: 9.8229 - val_loss: 119.2027 - val_mae: 7.6771\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 189.3760 - mae: 9.7843 - val_loss: 118.5304 - val_mae: 7.6177\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 189.1201 - mae: 9.7595 - val_loss: 118.5084 - val_mae: 7.6235\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 188.8242 - mae: 9.7560 - val_loss: 118.2843 - val_mae: 7.6077\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.5366 - mae: 9.7535 - val_loss: 118.4065 - val_mae: 7.6271\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 188.3109 - mae: 9.7509 - val_loss: 118.0934 - val_mae: 7.6070\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 187.7815 - mae: 9.7416 - val_loss: 117.8670 - val_mae: 7.5923\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 187.2535 - mae: 9.7277 - val_loss: 117.4181 - val_mae: 7.5825\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 186.0132 - mae: 9.6858 - val_loss: 116.2822 - val_mae: 7.5287\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 184.9598 - mae: 9.6416 - val_loss: 115.6233 - val_mae: 7.4867\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 184.3652 - mae: 9.6302 - val_loss: 115.3237 - val_mae: 7.4981\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 183.7157 - mae: 9.6060 - val_loss: 114.2977 - val_mae: 7.4303\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 183.2113 - mae: 9.5716 - val_loss: 113.9780 - val_mae: 7.4198\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 182.8735 - mae: 9.5537 - val_loss: 113.7222 - val_mae: 7.4063\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 182.6629 - mae: 9.5416 - val_loss: 113.3798 - val_mae: 7.3807\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 182.2893 - mae: 9.5206 - val_loss: 113.3072 - val_mae: 7.3806\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 182.1063 - mae: 9.5503 - val_loss: 113.6542 - val_mae: 7.4226\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 181.8856 - mae: 9.5484 - val_loss: 113.1286 - val_mae: 7.3735\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 181.7246 - mae: 9.5224 - val_loss: 112.7792 - val_mae: 7.3394\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 181.5014 - mae: 9.5215 - val_loss: 112.8361 - val_mae: 7.3519\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 181.2396 - mae: 9.4991 - val_loss: 112.3723 - val_mae: 7.3084\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 181.0968 - mae: 9.4731 - val_loss: 112.2594 - val_mae: 7.3008\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 180.8967 - mae: 9.4549 - val_loss: 111.8876 - val_mae: 7.2635\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 180.7226 - mae: 9.4309 - val_loss: 111.6644 - val_mae: 7.2437\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 180.4970 - mae: 9.4356 - val_loss: 111.8578 - val_mae: 7.2710\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 180.3206 - mae: 9.4424 - val_loss: 111.7869 - val_mae: 7.2653\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 180.1873 - mae: 9.4257 - val_loss: 111.5146 - val_mae: 7.2397\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 180.1220 - mae: 9.4468 - val_loss: 111.9081 - val_mae: 7.2871\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 179.8293 - mae: 9.4530 - val_loss: 111.6340 - val_mae: 7.2576\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 179.8944 - mae: 9.4073 - val_loss: 110.9212 - val_mae: 7.1819\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=2, model__n_neurons=125, model__optimizer=adam; total time=   2.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 1045.9968 - mae: 25.3828 - val_loss: 942.8285 - val_mae: 23.5942\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 930.9460 - mae: 23.9425 - val_loss: 827.8563 - val_mae: 22.0902\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 833.4420 - mae: 22.6328 - val_loss: 728.1489 - val_mae: 20.6976\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 748.9876 - mae: 21.4219 - val_loss: 643.4529 - val_mae: 19.4411\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 676.6882 - mae: 20.3344 - val_loss: 572.1168 - val_mae: 18.3346\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.0533 - mae: 19.3689 - val_loss: 513.2042 - val_mae: 17.3947\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.1829 - mae: 18.5467 - val_loss: 463.5890 - val_mae: 16.5637\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 522.1818 - mae: 17.8317 - val_loss: 421.9245 - val_mae: 15.8435\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 486.4755 - mae: 17.2267 - val_loss: 388.8465 - val_mae: 15.2667\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 457.8983 - mae: 16.7286 - val_loss: 360.8468 - val_mae: 14.7707\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 433.7879 - mae: 16.3194 - val_loss: 336.5594 - val_mae: 14.3361\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.8188 - mae: 15.9547 - val_loss: 314.9258 - val_mae: 13.9199\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 394.8780 - mae: 15.6171 - val_loss: 296.6725 - val_mae: 13.5482\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 379.9492 - mae: 15.3118 - val_loss: 280.9323 - val_mae: 13.2117\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.8242 - mae: 15.0361 - val_loss: 267.6434 - val_mae: 12.9168\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 355.6867 - mae: 14.8083 - val_loss: 256.8383 - val_mae: 12.6775\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 346.2288 - mae: 14.5959 - val_loss: 246.6499 - val_mae: 12.4249\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 337.8402 - mae: 14.3946 - val_loss: 238.1591 - val_mae: 12.2081\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 330.9000 - mae: 14.2210 - val_loss: 230.4222 - val_mae: 11.9958\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 324.6057 - mae: 14.0701 - val_loss: 224.2402 - val_mae: 11.8274\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 319.3237 - mae: 13.9522 - val_loss: 218.9020 - val_mae: 11.6832\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 314.4413 - mae: 13.8214 - val_loss: 212.7809 - val_mae: 11.4875\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.3339 - mae: 13.6707 - val_loss: 206.8182 - val_mae: 11.2944\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.1098 - mae: 13.5210 - val_loss: 201.8984 - val_mae: 11.1189\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 299.8753 - mae: 13.4096 - val_loss: 198.9576 - val_mae: 11.0236\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.0827 - mae: 13.3386 - val_loss: 196.1282 - val_mae: 10.9217\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.5544 - mae: 13.2616 - val_loss: 193.5290 - val_mae: 10.8208\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 292.3241 - mae: 13.1802 - val_loss: 190.5893 - val_mae: 10.7036\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.9042 - mae: 13.0973 - val_loss: 188.2348 - val_mae: 10.6111\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.7585 - mae: 13.0227 - val_loss: 186.3386 - val_mae: 10.5391\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 285.9182 - mae: 12.9712 - val_loss: 184.7323 - val_mae: 10.4825\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 284.2421 - mae: 12.9187 - val_loss: 182.6671 - val_mae: 10.3936\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 282.4996 - mae: 12.8663 - val_loss: 181.2232 - val_mae: 10.3574\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 280.4941 - mae: 12.8275 - val_loss: 178.9349 - val_mae: 10.2734\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.1921 - mae: 12.7561 - val_loss: 177.2852 - val_mae: 10.1975\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 276.5797 - mae: 12.7087 - val_loss: 176.3745 - val_mae: 10.1662\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.9997 - mae: 12.6547 - val_loss: 174.3533 - val_mae: 10.0751\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.3953 - mae: 12.5874 - val_loss: 172.4394 - val_mae: 9.9875\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 271.5140 - mae: 12.5245 - val_loss: 171.0097 - val_mae: 9.9307\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 270.0629 - mae: 12.4546 - val_loss: 169.4959 - val_mae: 9.8435\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.8433 - mae: 12.4262 - val_loss: 169.3485 - val_mae: 9.8654\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.5789 - mae: 12.4074 - val_loss: 168.1819 - val_mae: 9.8149\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 266.5683 - mae: 12.3464 - val_loss: 166.5849 - val_mae: 9.7189\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 265.7112 - mae: 12.3024 - val_loss: 165.8769 - val_mae: 9.6866\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 265.3874 - mae: 12.3215 - val_loss: 166.1301 - val_mae: 9.7181\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 264.3556 - mae: 12.2691 - val_loss: 164.4900 - val_mae: 9.6123\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.6564 - mae: 12.2123 - val_loss: 163.5646 - val_mae: 9.5563\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.0810 - mae: 12.1881 - val_loss: 163.3131 - val_mae: 9.5503\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.5305 - mae: 12.1762 - val_loss: 162.8565 - val_mae: 9.5315\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 261.8701 - mae: 12.1811 - val_loss: 163.5202 - val_mae: 9.5962\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.3307 - mae: 12.2005 - val_loss: 162.8663 - val_mae: 9.5580\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 260.6147 - mae: 12.1535 - val_loss: 161.7523 - val_mae: 9.4897\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.8082 - mae: 12.1114 - val_loss: 161.1623 - val_mae: 9.4573\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.0324 - mae: 12.0892 - val_loss: 160.8221 - val_mae: 9.4617\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 257.9672 - mae: 12.0530 - val_loss: 159.7683 - val_mae: 9.4016\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 257.2107 - mae: 12.0175 - val_loss: 159.4042 - val_mae: 9.3879\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 256.6377 - mae: 11.9949 - val_loss: 158.6878 - val_mae: 9.3489\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.9798 - mae: 11.9836 - val_loss: 158.4218 - val_mae: 9.3461\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.4770 - mae: 11.9605 - val_loss: 157.8089 - val_mae: 9.3140\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 254.9996 - mae: 11.9465 - val_loss: 157.6362 - val_mae: 9.3148\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 254.5067 - mae: 11.9479 - val_loss: 157.2319 - val_mae: 9.2963\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 253.7916 - mae: 11.9143 - val_loss: 156.6718 - val_mae: 9.2556\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 253.2180 - mae: 11.8846 - val_loss: 155.9417 - val_mae: 9.2069\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 252.5585 - mae: 11.8398 - val_loss: 155.0585 - val_mae: 9.1637\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 251.9588 - mae: 11.7892 - val_loss: 153.9472 - val_mae: 9.1109\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 250.6948 - mae: 11.7630 - val_loss: 153.6048 - val_mae: 9.1135\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 249.9473 - mae: 11.7741 - val_loss: 153.7643 - val_mae: 9.1488\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 249.3355 - mae: 11.7762 - val_loss: 152.8696 - val_mae: 9.0973\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 248.8865 - mae: 11.7358 - val_loss: 152.3957 - val_mae: 9.0630\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 248.4480 - mae: 11.7022 - val_loss: 151.7525 - val_mae: 9.0155\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 248.2293 - mae: 11.7060 - val_loss: 151.9907 - val_mae: 9.0401\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.8616 - mae: 11.6752 - val_loss: 150.9652 - val_mae: 8.9591\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.5962 - mae: 11.6430 - val_loss: 150.8641 - val_mae: 8.9547\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.3393 - mae: 11.6414 - val_loss: 150.8602 - val_mae: 8.9574\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.1266 - mae: 11.6586 - val_loss: 151.4119 - val_mae: 9.0114\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.1933 - mae: 11.6559 - val_loss: 150.6423 - val_mae: 8.9478\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.7484 - mae: 11.6481 - val_loss: 150.7789 - val_mae: 8.9632\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.8541 - mae: 11.6909 - val_loss: 151.5965 - val_mae: 9.0377\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.3151 - mae: 11.6501 - val_loss: 150.1765 - val_mae: 8.9176\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.1507 - mae: 11.5976 - val_loss: 149.7810 - val_mae: 8.8873\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.0340 - mae: 11.5967 - val_loss: 150.0555 - val_mae: 8.9159\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 245.8153 - mae: 11.5780 - val_loss: 149.3544 - val_mae: 8.8574\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 245.6385 - mae: 11.5645 - val_loss: 149.5139 - val_mae: 8.8742\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 245.4279 - mae: 11.5764 - val_loss: 149.9520 - val_mae: 8.9152\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 245.3186 - mae: 11.5892 - val_loss: 149.6179 - val_mae: 8.8886\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 245.0971 - mae: 11.5689 - val_loss: 149.6343 - val_mae: 8.8924\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.9209 - mae: 11.5667 - val_loss: 149.3792 - val_mae: 8.8732\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.7969 - mae: 11.5477 - val_loss: 149.1658 - val_mae: 8.8571\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 244.7405 - mae: 11.5750 - val_loss: 149.7457 - val_mae: 8.9109\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.5182 - mae: 11.5834 - val_loss: 149.4286 - val_mae: 8.8862\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.2651 - mae: 11.5319 - val_loss: 148.4088 - val_mae: 8.7986\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 244.0577 - mae: 11.4783 - val_loss: 147.7270 - val_mae: 8.7571\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 243.1807 - mae: 11.4451 - val_loss: 147.2309 - val_mae: 8.7457\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 241.9007 - mae: 11.4305 - val_loss: 147.1323 - val_mae: 8.7599\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 241.1143 - mae: 11.4646 - val_loss: 147.3664 - val_mae: 8.8088\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.2760 - mae: 11.4299 - val_loss: 145.4744 - val_mae: 8.6949\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 239.7536 - mae: 11.3541 - val_loss: 144.5858 - val_mae: 8.6298\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.5751 - mae: 11.3805 - val_loss: 145.4307 - val_mae: 8.7133\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.1075 - mae: 11.3801 - val_loss: 144.9452 - val_mae: 8.6709\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 239.0488 - mae: 11.3214 - val_loss: 143.9829 - val_mae: 8.5848\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=2, model__n_neurons=125, model__optimizer=adam; total time=   2.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 909.8541 - mae: 24.0227 - val_loss: 861.9138 - val_mae: 23.4540\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 836.5446 - mae: 23.0533 - val_loss: 792.3950 - val_mae: 22.5109\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 771.5500 - mae: 22.1333 - val_loss: 729.3247 - val_mae: 21.5973\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 712.9584 - mae: 21.2570 - val_loss: 673.0284 - val_mae: 20.7179\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 660.7746 - mae: 20.4186 - val_loss: 622.9326 - val_mae: 19.8860\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.4628 - mae: 19.6319 - val_loss: 578.9581 - val_mae: 19.1329\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.7992 - mae: 18.9069 - val_loss: 539.5657 - val_mae: 18.4337\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 534.5775 - mae: 18.2339 - val_loss: 503.8959 - val_mae: 17.7763\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 500.5507 - mae: 17.6027 - val_loss: 472.3499 - val_mae: 17.1659\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 471.2993 - mae: 17.0399 - val_loss: 444.6981 - val_mae: 16.6218\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 444.9998 - mae: 16.5268 - val_loss: 420.3707 - val_mae: 16.1255\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 422.0056 - mae: 16.0614 - val_loss: 399.0492 - val_mae: 15.6873\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 402.0095 - mae: 15.6438 - val_loss: 380.3673 - val_mae: 15.3057\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 384.2772 - mae: 15.2828 - val_loss: 364.4406 - val_mae: 14.9840\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.9097 - mae: 14.9726 - val_loss: 350.5003 - val_mae: 14.7004\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 355.1852 - mae: 14.6916 - val_loss: 337.5994 - val_mae: 14.4276\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.0479 - mae: 14.4035 - val_loss: 324.7451 - val_mae: 14.1370\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 329.0533 - mae: 14.0933 - val_loss: 312.6114 - val_mae: 13.8331\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 317.4553 - mae: 13.8078 - val_loss: 302.1352 - val_mae: 13.5770\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.4521 - mae: 13.5685 - val_loss: 292.7941 - val_mae: 13.3656\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.0881 - mae: 13.3454 - val_loss: 284.2082 - val_mae: 13.1574\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.8396 - mae: 13.1344 - val_loss: 275.6625 - val_mae: 12.9382\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.5772 - mae: 12.9145 - val_loss: 267.9207 - val_mae: 12.7252\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.3294 - mae: 12.7149 - val_loss: 261.3000 - val_mae: 12.5367\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.2844 - mae: 12.5493 - val_loss: 255.7165 - val_mae: 12.3746\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.9903 - mae: 12.3985 - val_loss: 250.3022 - val_mae: 12.2151\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 257.8791 - mae: 12.2609 - val_loss: 245.3059 - val_mae: 12.0740\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 253.3077 - mae: 12.1352 - val_loss: 241.0440 - val_mae: 11.9381\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 249.4206 - mae: 12.0153 - val_loss: 237.5296 - val_mae: 11.8210\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.1575 - mae: 11.9125 - val_loss: 234.3708 - val_mae: 11.7173\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 243.0180 - mae: 11.8155 - val_loss: 231.3865 - val_mae: 11.6153\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.2309 - mae: 11.7230 - val_loss: 228.5614 - val_mae: 11.5143\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.5187 - mae: 11.6369 - val_loss: 226.0434 - val_mae: 11.4334\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 235.0027 - mae: 11.5591 - val_loss: 223.3476 - val_mae: 11.3437\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 232.3306 - mae: 11.4661 - val_loss: 220.4445 - val_mae: 11.2438\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.3792 - mae: 11.3703 - val_loss: 217.0815 - val_mae: 11.1354\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 226.2093 - mae: 11.2741 - val_loss: 213.5214 - val_mae: 11.0275\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.5851 - mae: 11.1561 - val_loss: 210.2095 - val_mae: 10.9010\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.1651 - mae: 11.0576 - val_loss: 208.0005 - val_mae: 10.8096\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 218.4260 - mae: 10.9848 - val_loss: 206.1554 - val_mae: 10.7369\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.9512 - mae: 10.9292 - val_loss: 204.9475 - val_mae: 10.6915\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 215.8455 - mae: 10.8902 - val_loss: 203.9113 - val_mae: 10.6453\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.7882 - mae: 10.8598 - val_loss: 202.9247 - val_mae: 10.6140\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 213.4460 - mae: 10.8334 - val_loss: 200.6288 - val_mae: 10.5363\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 210.7808 - mae: 10.7319 - val_loss: 198.1267 - val_mae: 10.4343\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.9552 - mae: 10.6568 - val_loss: 196.8577 - val_mae: 10.3929\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.0745 - mae: 10.6328 - val_loss: 196.1492 - val_mae: 10.3665\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.1501 - mae: 10.5868 - val_loss: 195.1530 - val_mae: 10.3145\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 206.3611 - mae: 10.5471 - val_loss: 194.2186 - val_mae: 10.2688\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.5834 - mae: 10.5098 - val_loss: 193.4775 - val_mae: 10.2343\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.9608 - mae: 10.4855 - val_loss: 192.8635 - val_mae: 10.2083\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.2837 - mae: 10.4568 - val_loss: 191.9802 - val_mae: 10.1659\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 203.6319 - mae: 10.4222 - val_loss: 191.2651 - val_mae: 10.1293\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 203.0836 - mae: 10.4039 - val_loss: 190.7186 - val_mae: 10.1092\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.5400 - mae: 10.3844 - val_loss: 190.1990 - val_mae: 10.0881\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.0629 - mae: 10.3686 - val_loss: 189.7675 - val_mae: 10.0686\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 201.5689 - mae: 10.3434 - val_loss: 189.1681 - val_mae: 10.0373\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 201.1582 - mae: 10.3189 - val_loss: 188.6156 - val_mae: 10.0135\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.7682 - mae: 10.2895 - val_loss: 188.1769 - val_mae: 9.9922\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.3485 - mae: 10.2752 - val_loss: 187.7403 - val_mae: 9.9761\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.9672 - mae: 10.2652 - val_loss: 187.3507 - val_mae: 9.9571\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 199.6160 - mae: 10.2507 - val_loss: 186.9977 - val_mae: 9.9406\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.2375 - mae: 10.2331 - val_loss: 186.6095 - val_mae: 9.9224\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.8964 - mae: 10.2046 - val_loss: 186.1855 - val_mae: 9.8999\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.5803 - mae: 10.1843 - val_loss: 185.8420 - val_mae: 9.8870\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.2253 - mae: 10.1706 - val_loss: 185.4942 - val_mae: 9.8683\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.8877 - mae: 10.1498 - val_loss: 185.2021 - val_mae: 9.8516\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.6875 - mae: 10.1536 - val_loss: 185.0284 - val_mae: 9.8424\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.3989 - mae: 10.1284 - val_loss: 184.6317 - val_mae: 9.8190\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.0366 - mae: 10.1055 - val_loss: 184.2993 - val_mae: 9.8055\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.7705 - mae: 10.0908 - val_loss: 183.9789 - val_mae: 9.7892\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.4876 - mae: 10.0789 - val_loss: 183.8059 - val_mae: 9.7809\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.2532 - mae: 10.0659 - val_loss: 183.4242 - val_mae: 9.7629\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 195.8702 - mae: 10.0456 - val_loss: 183.0873 - val_mae: 9.7518\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 195.4612 - mae: 10.0412 - val_loss: 182.7739 - val_mae: 9.7401\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 194.9559 - mae: 10.0277 - val_loss: 182.0497 - val_mae: 9.7126\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 194.0060 - mae: 9.9933 - val_loss: 181.1366 - val_mae: 9.6788\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.0949 - mae: 9.9650 - val_loss: 180.4107 - val_mae: 9.6499\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 192.6011 - mae: 9.9569 - val_loss: 179.7776 - val_mae: 9.6290\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.8758 - mae: 9.9161 - val_loss: 179.0041 - val_mae: 9.6018\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 191.4851 - mae: 9.8718 - val_loss: 178.4191 - val_mae: 9.5802\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.1279 - mae: 9.8594 - val_loss: 177.9181 - val_mae: 9.5583\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.6410 - mae: 9.8520 - val_loss: 177.3237 - val_mae: 9.5375\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.0674 - mae: 9.8395 - val_loss: 176.4894 - val_mae: 9.5088\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 189.3696 - mae: 9.8411 - val_loss: 175.6007 - val_mae: 9.4816\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 188.3786 - mae: 9.7929 - val_loss: 174.7464 - val_mae: 9.4515\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 187.6587 - mae: 9.7408 - val_loss: 173.9999 - val_mae: 9.4217\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 187.0083 - mae: 9.7060 - val_loss: 173.0966 - val_mae: 9.3876\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 185.2624 - mae: 9.6622 - val_loss: 170.2451 - val_mae: 9.3095\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 181.7589 - mae: 9.5529 - val_loss: 167.3759 - val_mae: 9.1907\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.9035 - mae: 9.4856 - val_loss: 166.7936 - val_mae: 9.1759\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 179.3495 - mae: 9.4873 - val_loss: 166.2099 - val_mae: 9.1528\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 178.7560 - mae: 9.4716 - val_loss: 165.6686 - val_mae: 9.1297\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 178.2874 - mae: 9.4537 - val_loss: 165.2054 - val_mae: 9.1072\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 177.9544 - mae: 9.4152 - val_loss: 164.8270 - val_mae: 9.0878\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 177.7390 - mae: 9.3767 - val_loss: 164.4946 - val_mae: 9.0744\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 177.5803 - mae: 9.3753 - val_loss: 164.4140 - val_mae: 9.0634\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.2928 - mae: 9.3621 - val_loss: 164.2067 - val_mae: 9.0524\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 177.1167 - mae: 9.3453 - val_loss: 163.9768 - val_mae: 9.0416\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 177.0470 - mae: 9.3418 - val_loss: 163.8236 - val_mae: 9.0320\n",
      "5/5 [==============================] - 0s 750us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=2, model__n_neurons=125, model__optimizer=adam; total time=   2.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 23951.1855 - mae: 50.2120 - val_loss: 449.2127 - val_mae: 20.2756\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.4477 - mae: 22.6974 - val_loss: 448.8011 - val_mae: 20.2654\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.9008 - mae: 22.6852 - val_loss: 448.2257 - val_mae: 20.2511\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.2198 - mae: 22.6702 - val_loss: 447.5900 - val_mae: 20.2352\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.4922 - mae: 22.6539 - val_loss: 446.9266 - val_mae: 20.2185\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.7513 - mae: 22.6370 - val_loss: 446.2576 - val_mae: 20.2015\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.9990 - mae: 22.6201 - val_loss: 445.5988 - val_mae: 20.1847\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.2554 - mae: 22.6034 - val_loss: 444.9494 - val_mae: 20.1680\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.5289 - mae: 22.5866 - val_loss: 444.3015 - val_mae: 20.1512\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.8041 - mae: 22.5698 - val_loss: 443.6582 - val_mae: 20.1344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.0812 - mae: 22.5531 - val_loss: 443.0294 - val_mae: 20.1179\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.3755 - mae: 22.5366 - val_loss: 442.4070 - val_mae: 20.1014\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.6756 - mae: 22.5202 - val_loss: 441.7933 - val_mae: 20.0850\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.9875 - mae: 22.5038 - val_loss: 441.1841 - val_mae: 20.0686\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.3058 - mae: 22.4875 - val_loss: 440.5846 - val_mae: 20.0524\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.6349 - mae: 22.4713 - val_loss: 439.9931 - val_mae: 20.0363\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.9631 - mae: 22.4553 - val_loss: 439.4182 - val_mae: 20.0205\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.3132 - mae: 22.4395 - val_loss: 438.8475 - val_mae: 20.0047\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.6627 - mae: 22.4238 - val_loss: 438.2863 - val_mae: 19.9891\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.0314 - mae: 22.4081 - val_loss: 437.7272 - val_mae: 19.9734\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 585.4026 - mae: 22.3924 - val_loss: 437.1730 - val_mae: 19.9577\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.7760 - mae: 22.3768 - val_loss: 436.6279 - val_mae: 19.9421\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.1561 - mae: 22.3614 - val_loss: 436.0959 - val_mae: 19.9269\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 583.5544 - mae: 22.3461 - val_loss: 435.5669 - val_mae: 19.9116\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.9587 - mae: 22.3308 - val_loss: 435.0418 - val_mae: 19.8963\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.3605 - mae: 22.3156 - val_loss: 434.5272 - val_mae: 19.8812\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.7725 - mae: 22.3006 - val_loss: 434.0215 - val_mae: 19.8662\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.1997 - mae: 22.2856 - val_loss: 433.5207 - val_mae: 19.8513\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.6273 - mae: 22.2708 - val_loss: 433.0289 - val_mae: 19.8365\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.0726 - mae: 22.2559 - val_loss: 432.5382 - val_mae: 19.8217\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 579.5141 - mae: 22.2412 - val_loss: 432.0595 - val_mae: 19.8071\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.9650 - mae: 22.2267 - val_loss: 431.5912 - val_mae: 19.7928\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.4289 - mae: 22.2123 - val_loss: 431.1235 - val_mae: 19.7783\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.8909 - mae: 22.1979 - val_loss: 430.6636 - val_mae: 19.7640\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 577.3631 - mae: 22.1836 - val_loss: 430.2090 - val_mae: 19.7497\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 576.8506 - mae: 22.1693 - val_loss: 429.7557 - val_mae: 19.7354\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 576.3292 - mae: 22.1551 - val_loss: 429.3161 - val_mae: 19.7214\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.8223 - mae: 22.1412 - val_loss: 428.8846 - val_mae: 19.7075\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.3261 - mae: 22.1274 - val_loss: 428.4600 - val_mae: 19.6938\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.8308 - mae: 22.1137 - val_loss: 428.0404 - val_mae: 19.6802\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.3550 - mae: 22.1000 - val_loss: 427.6182 - val_mae: 19.6663\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 573.8679 - mae: 22.0864 - val_loss: 427.2063 - val_mae: 19.6527\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 573.3954 - mae: 22.0731 - val_loss: 426.7997 - val_mae: 19.6391\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.9232 - mae: 22.0598 - val_loss: 426.4028 - val_mae: 19.6258\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.4673 - mae: 22.0468 - val_loss: 426.0069 - val_mae: 19.6124\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 572.0090 - mae: 22.0336 - val_loss: 425.6176 - val_mae: 19.5992\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.5558 - mae: 22.0207 - val_loss: 425.2370 - val_mae: 19.5861\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.1145 - mae: 22.0078 - val_loss: 424.8607 - val_mae: 19.5731\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.6740 - mae: 21.9951 - val_loss: 424.4883 - val_mae: 19.5601\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.2404 - mae: 21.9824 - val_loss: 424.1208 - val_mae: 19.5472\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.8112 - mae: 21.9697 - val_loss: 423.7597 - val_mae: 19.5345\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 569.3931 - mae: 21.9572 - val_loss: 423.3996 - val_mae: 19.5216\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.9714 - mae: 21.9446 - val_loss: 423.0469 - val_mae: 19.5090\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.5661 - mae: 21.9322 - val_loss: 422.6945 - val_mae: 19.4962\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.1510 - mae: 21.9197 - val_loss: 422.3556 - val_mae: 19.4839\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.7535 - mae: 21.9076 - val_loss: 422.0187 - val_mae: 19.4715\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.3583 - mae: 21.8954 - val_loss: 421.6857 - val_mae: 19.4591\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.9653 - mae: 21.8834 - val_loss: 421.3601 - val_mae: 19.4470\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.5861 - mae: 21.8714 - val_loss: 421.0335 - val_mae: 19.4349\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 566.2028 - mae: 21.8593 - val_loss: 420.7137 - val_mae: 19.4237\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.8234 - mae: 21.8476 - val_loss: 420.4011 - val_mae: 19.4127\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.4606 - mae: 21.8358 - val_loss: 420.0891 - val_mae: 19.4016\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 565.0914 - mae: 21.8241 - val_loss: 419.7839 - val_mae: 19.3906\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.7281 - mae: 21.8127 - val_loss: 419.4844 - val_mae: 19.3798\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.3713 - mae: 21.8014 - val_loss: 419.1877 - val_mae: 19.3690\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 564.0215 - mae: 21.7902 - val_loss: 418.8964 - val_mae: 19.3583\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 563.6755 - mae: 21.7790 - val_loss: 418.6086 - val_mae: 19.3477\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.3330 - mae: 21.7679 - val_loss: 418.3238 - val_mae: 19.3370\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 563.0009 - mae: 21.7568 - val_loss: 418.0371 - val_mae: 19.3263\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 562.6549 - mae: 21.7457 - val_loss: 417.7609 - val_mae: 19.3158\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.3305 - mae: 21.7347 - val_loss: 417.4859 - val_mae: 19.3053\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 561.9966 - mae: 21.7239 - val_loss: 417.2223 - val_mae: 19.2952\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.6860 - mae: 21.7131 - val_loss: 416.9545 - val_mae: 19.2848\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 561.3621 - mae: 21.7026 - val_loss: 416.6959 - val_mae: 19.2747\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.0520 - mae: 21.6923 - val_loss: 416.4369 - val_mae: 19.2645\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.7380 - mae: 21.6822 - val_loss: 416.1850 - val_mae: 19.2545\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 560.4409 - mae: 21.6721 - val_loss: 415.9336 - val_mae: 19.2445\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.1394 - mae: 21.6622 - val_loss: 415.6843 - val_mae: 19.2344\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.8365 - mae: 21.6523 - val_loss: 415.4413 - val_mae: 19.2246\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.5446 - mae: 21.6424 - val_loss: 415.2004 - val_mae: 19.2147\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.2557 - mae: 21.6328 - val_loss: 414.9609 - val_mae: 19.2048\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.9624 - mae: 21.6231 - val_loss: 414.7317 - val_mae: 19.1953\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.6854 - mae: 21.6136 - val_loss: 414.5017 - val_mae: 19.1857\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.4054 - mae: 21.6041 - val_loss: 414.2747 - val_mae: 19.1761\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.1267 - mae: 21.5946 - val_loss: 414.0526 - val_mae: 19.1666\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.8571 - mae: 21.5853 - val_loss: 413.8324 - val_mae: 19.1572\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.5920 - mae: 21.5759 - val_loss: 413.6120 - val_mae: 19.1477\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.3200 - mae: 21.5665 - val_loss: 413.3992 - val_mae: 19.1384\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.0591 - mae: 21.5572 - val_loss: 413.1869 - val_mae: 19.1291\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.8051 - mae: 21.5481 - val_loss: 412.9765 - val_mae: 19.1198\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.5438 - mae: 21.5390 - val_loss: 412.7729 - val_mae: 19.1107\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.2960 - mae: 21.5298 - val_loss: 412.5695 - val_mae: 19.1015\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 556.0437 - mae: 21.5210 - val_loss: 412.3723 - val_mae: 19.0926\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.7999 - mae: 21.5121 - val_loss: 412.1773 - val_mae: 19.0837\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.5624 - mae: 21.5033 - val_loss: 411.9818 - val_mae: 19.0747\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.3192 - mae: 21.4944 - val_loss: 411.7911 - val_mae: 19.0658\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 555.0814 - mae: 21.4858 - val_loss: 411.6047 - val_mae: 19.0573\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.8559 - mae: 21.4772 - val_loss: 411.4144 - val_mae: 19.0490\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.6172 - mae: 21.4685 - val_loss: 411.2318 - val_mae: 19.0411\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.3848 - mae: 21.4602 - val_loss: 411.0531 - val_mae: 19.0332\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   3.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 946.3998 - mae: 25.2679 - val_loss: 449.1347 - val_mae: 20.2737\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.9531 - mae: 23.1146 - val_loss: 448.6592 - val_mae: 20.2619\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.3340 - mae: 23.1012 - val_loss: 448.0562 - val_mae: 20.2469\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.6171 - mae: 23.0855 - val_loss: 447.3950 - val_mae: 20.2303\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.8490 - mae: 23.0687 - val_loss: 446.7187 - val_mae: 20.2132\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.0825 - mae: 23.0514 - val_loss: 446.0366 - val_mae: 20.1959\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.3011 - mae: 23.0342 - val_loss: 445.3673 - val_mae: 20.1788\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.5264 - mae: 23.0172 - val_loss: 444.7123 - val_mae: 20.1619\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.7830 - mae: 23.0002 - val_loss: 444.0543 - val_mae: 20.1448\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 631.0321 - mae: 22.9831 - val_loss: 443.4016 - val_mae: 20.1277\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 630.2866 - mae: 22.9660 - val_loss: 442.7586 - val_mae: 20.1107\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 629.5471 - mae: 22.9492 - val_loss: 442.1312 - val_mae: 20.0940\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.8279 - mae: 22.9325 - val_loss: 441.5082 - val_mae: 20.0774\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.1139 - mae: 22.9159 - val_loss: 440.8934 - val_mae: 20.0608\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 627.4061 - mae: 22.8994 - val_loss: 440.2906 - val_mae: 20.0444\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 626.7202 - mae: 22.8830 - val_loss: 439.6884 - val_mae: 20.0279\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.0211 - mae: 22.8666 - val_loss: 439.1021 - val_mae: 20.0118\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.3476 - mae: 22.8504 - val_loss: 438.5182 - val_mae: 19.9955\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.6694 - mae: 22.8344 - val_loss: 437.9486 - val_mae: 19.9796\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.0164 - mae: 22.8183 - val_loss: 437.3802 - val_mae: 19.9635\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.3672 - mae: 22.8023 - val_loss: 436.8180 - val_mae: 19.9476\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.7134 - mae: 22.7865 - val_loss: 436.2703 - val_mae: 19.9319\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 622.0800 - mae: 22.7708 - val_loss: 435.7303 - val_mae: 19.9163\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 621.4559 - mae: 22.7552 - val_loss: 435.1945 - val_mae: 19.9007\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.8363 - mae: 22.7396 - val_loss: 434.6624 - val_mae: 19.8851\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 620.2188 - mae: 22.7242 - val_loss: 434.1422 - val_mae: 19.8698\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 619.6152 - mae: 22.7089 - val_loss: 433.6292 - val_mae: 19.8545\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 619.0176 - mae: 22.6938 - val_loss: 433.1297 - val_mae: 19.8396\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 618.4374 - mae: 22.6788 - val_loss: 432.6342 - val_mae: 19.8246\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 617.8593 - mae: 22.6639 - val_loss: 432.1455 - val_mae: 19.8098\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 617.2900 - mae: 22.6490 - val_loss: 431.6621 - val_mae: 19.7949\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.7235 - mae: 22.6343 - val_loss: 431.1895 - val_mae: 19.7803\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 616.1710 - mae: 22.6196 - val_loss: 430.7160 - val_mae: 19.7656\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.6149 - mae: 22.6050 - val_loss: 430.2518 - val_mae: 19.7511\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.0676 - mae: 22.5905 - val_loss: 429.7957 - val_mae: 19.7367\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 614.5392 - mae: 22.5760 - val_loss: 429.3382 - val_mae: 19.7221\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.9999 - mae: 22.5616 - val_loss: 428.8924 - val_mae: 19.7078\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.4772 - mae: 22.5473 - val_loss: 428.4554 - val_mae: 19.6937\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.9653 - mae: 22.5332 - val_loss: 428.0237 - val_mae: 19.6796\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 612.4499 - mae: 22.5193 - val_loss: 427.6012 - val_mae: 19.6657\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.9568 - mae: 22.5053 - val_loss: 427.1777 - val_mae: 19.6517\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 611.4569 - mae: 22.4914 - val_loss: 426.7621 - val_mae: 19.6379\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 610.9614 - mae: 22.4776 - val_loss: 426.3560 - val_mae: 19.6242\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.4786 - mae: 22.4640 - val_loss: 425.9543 - val_mae: 19.6107\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 610.0133 - mae: 22.4503 - val_loss: 425.5500 - val_mae: 19.5969\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 609.5263 - mae: 22.4367 - val_loss: 425.1615 - val_mae: 19.5835\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 609.0657 - mae: 22.4234 - val_loss: 424.7776 - val_mae: 19.5702\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 608.6061 - mae: 22.4102 - val_loss: 424.4014 - val_mae: 19.5571\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 608.1519 - mae: 22.3970 - val_loss: 424.0286 - val_mae: 19.5440\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.7070 - mae: 22.3839 - val_loss: 423.6563 - val_mae: 19.5308\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 607.2656 - mae: 22.3708 - val_loss: 423.2910 - val_mae: 19.5177\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 606.8296 - mae: 22.3579 - val_loss: 422.9300 - val_mae: 19.5047\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.3953 - mae: 22.3450 - val_loss: 422.5758 - val_mae: 19.4919\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 605.9735 - mae: 22.3322 - val_loss: 422.2245 - val_mae: 19.4790\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 605.5499 - mae: 22.3196 - val_loss: 421.8824 - val_mae: 19.4664\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 605.1362 - mae: 22.3071 - val_loss: 421.5424 - val_mae: 19.4538\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 604.7250 - mae: 22.2946 - val_loss: 421.2071 - val_mae: 19.4413\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 604.3223 - mae: 22.2822 - val_loss: 420.8763 - val_mae: 19.4295\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 603.9178 - mae: 22.2699 - val_loss: 420.5536 - val_mae: 19.4181\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.5312 - mae: 22.2576 - val_loss: 420.2282 - val_mae: 19.4065\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 603.1392 - mae: 22.2454 - val_loss: 419.9081 - val_mae: 19.3951\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.7524 - mae: 22.2333 - val_loss: 419.5959 - val_mae: 19.3838\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.3735 - mae: 22.2215 - val_loss: 419.2894 - val_mae: 19.3727\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 602.0004 - mae: 22.2098 - val_loss: 418.9873 - val_mae: 19.3616\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.6279 - mae: 22.1982 - val_loss: 418.6919 - val_mae: 19.3507\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 601.2668 - mae: 22.1868 - val_loss: 418.4003 - val_mae: 19.3399\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.9154 - mae: 22.1752 - val_loss: 418.1071 - val_mae: 19.3289\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 600.5544 - mae: 22.1638 - val_loss: 417.8235 - val_mae: 19.3182\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 600.2108 - mae: 22.1525 - val_loss: 417.5380 - val_mae: 19.3073\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 599.8551 - mae: 22.1412 - val_loss: 417.2622 - val_mae: 19.2967\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 599.5226 - mae: 22.1299 - val_loss: 416.9852 - val_mae: 19.2860\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 599.1753 - mae: 22.1189 - val_loss: 416.7202 - val_mae: 19.2757\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 598.8490 - mae: 22.1084 - val_loss: 416.4541 - val_mae: 19.2652\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.5186 - mae: 22.0977 - val_loss: 416.1917 - val_mae: 19.2548\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.1951 - mae: 22.0871 - val_loss: 415.9306 - val_mae: 19.2444\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.8649 - mae: 22.0768 - val_loss: 415.6785 - val_mae: 19.2342\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.5566 - mae: 22.0664 - val_loss: 415.4264 - val_mae: 19.2240\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.2506 - mae: 22.0562 - val_loss: 415.1719 - val_mae: 19.2135\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.9322 - mae: 22.0459 - val_loss: 414.9293 - val_mae: 19.2035\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.6309 - mae: 22.0358 - val_loss: 414.6882 - val_mae: 19.1935\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.3275 - mae: 22.0260 - val_loss: 414.4518 - val_mae: 19.1836\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.0287 - mae: 22.0160 - val_loss: 414.2222 - val_mae: 19.1739\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 595.7394 - mae: 22.0064 - val_loss: 413.9937 - val_mae: 19.1641\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.4558 - mae: 21.9966 - val_loss: 413.7639 - val_mae: 19.1542\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.1649 - mae: 21.9868 - val_loss: 413.5417 - val_mae: 19.1446\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 594.8859 - mae: 21.9772 - val_loss: 413.3213 - val_mae: 19.1350\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.6061 - mae: 21.9677 - val_loss: 413.1057 - val_mae: 19.1255\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.3319 - mae: 21.9583 - val_loss: 412.8914 - val_mae: 19.1160\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.0626 - mae: 21.9487 - val_loss: 412.6772 - val_mae: 19.1064\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.7936 - mae: 21.9394 - val_loss: 412.4666 - val_mae: 19.0969\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.5253 - mae: 21.9301 - val_loss: 412.2629 - val_mae: 19.0876\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.2661 - mae: 21.9209 - val_loss: 412.0609 - val_mae: 19.0783\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 593.0032 - mae: 21.9117 - val_loss: 411.8650 - val_mae: 19.0692\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.7537 - mae: 21.9027 - val_loss: 411.6672 - val_mae: 19.0600\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.5074 - mae: 21.8938 - val_loss: 411.4706 - val_mae: 19.0515\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 592.2509 - mae: 21.8846 - val_loss: 411.2826 - val_mae: 19.0433\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.0099 - mae: 21.8759 - val_loss: 411.0955 - val_mae: 19.0350\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.7717 - mae: 21.8673 - val_loss: 410.9077 - val_mae: 19.0267\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.5292 - mae: 21.8586 - val_loss: 410.7255 - val_mae: 19.0186\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.2914 - mae: 21.8500 - val_loss: 410.5473 - val_mae: 19.0105\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   3.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 7246.7168 - mae: 38.6823 - val_loss: 548.6348 - val_mae: 21.8367\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2112 - mae: 21.8942 - val_loss: 548.5134 - val_mae: 21.8339\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.0557 - mae: 21.8906 - val_loss: 548.3226 - val_mae: 21.8295\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.8493 - mae: 21.8859 - val_loss: 548.1054 - val_mae: 21.8245\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.6277 - mae: 21.8807 - val_loss: 547.8765 - val_mae: 21.8192\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.3974 - mae: 21.8754 - val_loss: 547.6454 - val_mae: 21.8138\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.1649 - mae: 21.8700 - val_loss: 547.4161 - val_mae: 21.8083\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.9375 - mae: 21.8645 - val_loss: 547.1857 - val_mae: 21.8029\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.7060 - mae: 21.8591 - val_loss: 546.9604 - val_mae: 21.7975\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.4808 - mae: 21.8537 - val_loss: 546.7382 - val_mae: 21.7921\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.2589 - mae: 21.8484 - val_loss: 546.5180 - val_mae: 21.7868\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.0393 - mae: 21.8430 - val_loss: 546.3005 - val_mae: 21.7815\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.8226 - mae: 21.8378 - val_loss: 546.0866 - val_mae: 21.7763\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.6089 - mae: 21.8325 - val_loss: 545.8751 - val_mae: 21.7710\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.3998 - mae: 21.8273 - val_loss: 545.6644 - val_mae: 21.7658\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.1892 - mae: 21.8221 - val_loss: 545.4579 - val_mae: 21.7606\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.9847 - mae: 21.8169 - val_loss: 545.2522 - val_mae: 21.7555\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.7789 - mae: 21.8118 - val_loss: 545.0510 - val_mae: 21.7504\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.5772 - mae: 21.8067 - val_loss: 544.8535 - val_mae: 21.7453\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.3798 - mae: 21.8017 - val_loss: 544.6585 - val_mae: 21.7403\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.1859 - mae: 21.7967 - val_loss: 544.4648 - val_mae: 21.7353\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.9913 - mae: 21.7917 - val_loss: 544.2750 - val_mae: 21.7304\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.8004 - mae: 21.7868 - val_loss: 544.0876 - val_mae: 21.7255\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.6143 - mae: 21.7819 - val_loss: 543.9006 - val_mae: 21.7205\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 552.4281 - mae: 21.7769 - val_loss: 543.7150 - val_mae: 21.7156\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.2424 - mae: 21.7720 - val_loss: 543.5327 - val_mae: 21.7108\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.0613 - mae: 21.7672 - val_loss: 543.3522 - val_mae: 21.7059\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.8818 - mae: 21.7624 - val_loss: 543.1744 - val_mae: 21.7011\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.7038 - mae: 21.7576 - val_loss: 542.9992 - val_mae: 21.6963\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.5298 - mae: 21.7528 - val_loss: 542.8260 - val_mae: 21.6916\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.3576 - mae: 21.7481 - val_loss: 542.6546 - val_mae: 21.6869\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.1846 - mae: 21.7434 - val_loss: 542.4872 - val_mae: 21.6822\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.0190 - mae: 21.7387 - val_loss: 542.3198 - val_mae: 21.6776\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.8524 - mae: 21.7341 - val_loss: 542.1559 - val_mae: 21.6730\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.6877 - mae: 21.7295 - val_loss: 541.9952 - val_mae: 21.6684\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.5280 - mae: 21.7250 - val_loss: 541.8350 - val_mae: 21.6639\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 550.3710 - mae: 21.7204 - val_loss: 541.6766 - val_mae: 21.6593\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.2125 - mae: 21.7159 - val_loss: 541.5222 - val_mae: 21.6549\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.0577 - mae: 21.7115 - val_loss: 541.3703 - val_mae: 21.6505\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.9045 - mae: 21.7071 - val_loss: 541.2203 - val_mae: 21.6461\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.7547 - mae: 21.7027 - val_loss: 541.0712 - val_mae: 21.6417\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.6042 - mae: 21.6983 - val_loss: 540.9249 - val_mae: 21.6374\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.4580 - mae: 21.6940 - val_loss: 540.7777 - val_mae: 21.6333\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.3122 - mae: 21.6897 - val_loss: 540.6327 - val_mae: 21.6293\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.1671 - mae: 21.6854 - val_loss: 540.4910 - val_mae: 21.6253\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.0259 - mae: 21.6811 - val_loss: 540.3499 - val_mae: 21.6213\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.8871 - mae: 21.6769 - val_loss: 540.2101 - val_mae: 21.6174\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.7462 - mae: 21.6727 - val_loss: 540.0749 - val_mae: 21.6135\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.6115 - mae: 21.6686 - val_loss: 539.9403 - val_mae: 21.6097\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.4774 - mae: 21.6644 - val_loss: 539.8069 - val_mae: 21.6058\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.3448 - mae: 21.6603 - val_loss: 539.6750 - val_mae: 21.6020\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 548.2128 - mae: 21.6562 - val_loss: 539.5460 - val_mae: 21.5982\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.0826 - mae: 21.6522 - val_loss: 539.4187 - val_mae: 21.5945\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.9560 - mae: 21.6482 - val_loss: 539.2915 - val_mae: 21.5907\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.8281 - mae: 21.6442 - val_loss: 539.1667 - val_mae: 21.5870\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 547.7043 - mae: 21.6403 - val_loss: 539.0432 - val_mae: 21.5833\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.5803 - mae: 21.6363 - val_loss: 538.9221 - val_mae: 21.5796\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.4598 - mae: 21.6324 - val_loss: 538.8013 - val_mae: 21.5760\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.3380 - mae: 21.6286 - val_loss: 538.6830 - val_mae: 21.5723\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.2206 - mae: 21.6247 - val_loss: 538.5647 - val_mae: 21.5687\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.1023 - mae: 21.6209 - val_loss: 538.4495 - val_mae: 21.5651\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.9883 - mae: 21.6171 - val_loss: 538.3339 - val_mae: 21.5615\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.8734 - mae: 21.6133 - val_loss: 538.2206 - val_mae: 21.5580\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.7587 - mae: 21.6095 - val_loss: 538.1108 - val_mae: 21.5545\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.6508 - mae: 21.6058 - val_loss: 538.0004 - val_mae: 21.5510\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.5397 - mae: 21.6021 - val_loss: 537.8928 - val_mae: 21.5475\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.4318 - mae: 21.5985 - val_loss: 537.7855 - val_mae: 21.5441\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.3254 - mae: 21.5948 - val_loss: 537.6792 - val_mae: 21.5406\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.2180 - mae: 21.5912 - val_loss: 537.5762 - val_mae: 21.5373\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 546.1151 - mae: 21.5876 - val_loss: 537.4725 - val_mae: 21.5339\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.0117 - mae: 21.5840 - val_loss: 537.3713 - val_mae: 21.5305\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.9108 - mae: 21.5805 - val_loss: 537.2708 - val_mae: 21.5272\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.8093 - mae: 21.5769 - val_loss: 537.1727 - val_mae: 21.5239\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.7124 - mae: 21.5734 - val_loss: 537.0748 - val_mae: 21.5206\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.6143 - mae: 21.5699 - val_loss: 536.9785 - val_mae: 21.5173\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.5184 - mae: 21.5664 - val_loss: 536.8831 - val_mae: 21.5141\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 545.4238 - mae: 21.5630 - val_loss: 536.7883 - val_mae: 21.5108\n",
      "Epoch 77: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   2.1s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=0, model__n_neurons=125, model__optimizer=momentum; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 754us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=0, model__n_neurons=125, model__optimizer=momentum; total time=   0.4s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21635.4844 - mae: 71.4221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 761us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=0, model__n_neurons=125, model__optimizer=momentum; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 689us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=adam; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 12ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=adam; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=5, model__optimizer=adam; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=0, model__n_neurons=25, model__optimizer=sgd; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=0, model__n_neurons=25, model__optimizer=sgd; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1000us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=0, model__n_neurons=25, model__optimizer=sgd; total time=   0.4s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24492.2461 - mae: 74.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=0, model__n_neurons=125, model__optimizer=nesterov; total time=   0.4s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 23560.8262 - mae: 73.5918"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=0, model__n_neurons=125, model__optimizer=nesterov; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=0, model__n_neurons=125, model__optimizer=nesterov; total time=   0.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 1320.2953 - mae: 27.8396 - val_loss: 712.7047 - val_mae: 21.7644\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.3848 - mae: 20.2778 - val_loss: 411.7111 - val_mae: 17.1473\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 440.1546 - mae: 17.6313 - val_loss: 348.8471 - val_mae: 15.7222\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 410.3608 - mae: 16.8743 - val_loss: 325.8379 - val_mae: 15.2070\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 399.4248 - mae: 16.5917 - val_loss: 314.2277 - val_mae: 14.9460\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 392.0196 - mae: 16.3976 - val_loss: 304.9590 - val_mae: 14.7180\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 385.8781 - mae: 16.2190 - val_loss: 298.1650 - val_mae: 14.5464\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 381.7498 - mae: 16.1027 - val_loss: 293.0048 - val_mae: 14.4150\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 377.9183 - mae: 15.9995 - val_loss: 289.1023 - val_mae: 14.3107\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 374.7114 - mae: 15.9146 - val_loss: 285.4816 - val_mae: 14.2081\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 371.8665 - mae: 15.8303 - val_loss: 281.9819 - val_mae: 14.1009\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.3398 - mae: 15.7492 - val_loss: 279.2444 - val_mae: 14.0067\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.1936 - mae: 15.6775 - val_loss: 276.8588 - val_mae: 13.9238\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.4476 - mae: 15.6337 - val_loss: 274.8789 - val_mae: 13.8554\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 363.7094 - mae: 15.5668 - val_loss: 272.8792 - val_mae: 13.7825\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 362.1989 - mae: 15.5116 - val_loss: 270.8976 - val_mae: 13.7111\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 360.6316 - mae: 15.4602 - val_loss: 268.8469 - val_mae: 13.6420\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 359.0315 - mae: 15.4052 - val_loss: 267.2017 - val_mae: 13.5852\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 357.2733 - mae: 15.3451 - val_loss: 264.8823 - val_mae: 13.5115\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.6090 - mae: 15.2779 - val_loss: 262.2459 - val_mae: 13.4084\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 352.1993 - mae: 15.1981 - val_loss: 260.5066 - val_mae: 13.3245\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 350.3398 - mae: 15.1226 - val_loss: 258.8401 - val_mae: 13.2564\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 348.9684 - mae: 15.0664 - val_loss: 257.4414 - val_mae: 13.2067\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 347.6444 - mae: 15.0411 - val_loss: 256.1617 - val_mae: 13.1603\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 346.4001 - mae: 15.0049 - val_loss: 254.9264 - val_mae: 13.1071\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 345.0831 - mae: 14.9476 - val_loss: 253.7829 - val_mae: 13.0606\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 343.8986 - mae: 14.9129 - val_loss: 252.7016 - val_mae: 13.0224\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.6736 - mae: 14.8806 - val_loss: 251.4507 - val_mae: 12.9724\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 341.6317 - mae: 14.8316 - val_loss: 250.4043 - val_mae: 12.9324\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.5634 - mae: 14.8153 - val_loss: 249.2695 - val_mae: 12.8924\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.6676 - mae: 14.7786 - val_loss: 248.0637 - val_mae: 12.8460\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.8665 - mae: 14.7361 - val_loss: 247.1084 - val_mae: 12.8045\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.1209 - mae: 14.7228 - val_loss: 246.5327 - val_mae: 12.7889\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 337.3594 - mae: 14.7038 - val_loss: 245.7823 - val_mae: 12.7612\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 336.8314 - mae: 14.6864 - val_loss: 244.9727 - val_mae: 12.7311\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 336.1377 - mae: 14.6653 - val_loss: 244.2903 - val_mae: 12.7001\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 335.5919 - mae: 14.6401 - val_loss: 243.5437 - val_mae: 12.6667\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 334.9922 - mae: 14.6180 - val_loss: 242.7856 - val_mae: 12.6371\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 334.4659 - mae: 14.5889 - val_loss: 242.2823 - val_mae: 12.6112\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 334.0893 - mae: 14.5764 - val_loss: 241.8379 - val_mae: 12.6004\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 333.4826 - mae: 14.5862 - val_loss: 241.4818 - val_mae: 12.5860\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 332.9997 - mae: 14.5556 - val_loss: 240.8602 - val_mae: 12.5546\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 332.5913 - mae: 14.5420 - val_loss: 240.3174 - val_mae: 12.5323\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 332.1864 - mae: 14.5267 - val_loss: 239.8005 - val_mae: 12.5103\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 331.9345 - mae: 14.5250 - val_loss: 239.3944 - val_mae: 12.4958\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 331.3826 - mae: 14.4956 - val_loss: 238.9477 - val_mae: 12.4736\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 331.2573 - mae: 14.4812 - val_loss: 238.4501 - val_mae: 12.4489\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 330.7142 - mae: 14.4704 - val_loss: 238.2092 - val_mae: 12.4466\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 330.1888 - mae: 14.4556 - val_loss: 238.0752 - val_mae: 12.4455\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 329.7050 - mae: 14.4545 - val_loss: 237.8462 - val_mae: 12.4395\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 329.1445 - mae: 14.4341 - val_loss: 237.1889 - val_mae: 12.4147\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 328.5664 - mae: 14.4248 - val_loss: 236.6892 - val_mae: 12.4018\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 327.9458 - mae: 14.3983 - val_loss: 235.8865 - val_mae: 12.3733\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 327.4193 - mae: 14.4076 - val_loss: 235.1221 - val_mae: 12.3489\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 326.6626 - mae: 14.3442 - val_loss: 234.1514 - val_mae: 12.3089\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 325.8071 - mae: 14.3384 - val_loss: 233.5544 - val_mae: 12.2947\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 325.1139 - mae: 14.3129 - val_loss: 232.8669 - val_mae: 12.2670\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 324.5319 - mae: 14.2990 - val_loss: 232.1884 - val_mae: 12.2471\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 323.8889 - mae: 14.2983 - val_loss: 231.7295 - val_mae: 12.2297\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 323.2805 - mae: 14.2521 - val_loss: 230.9487 - val_mae: 12.1952\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 322.6464 - mae: 14.2346 - val_loss: 230.2368 - val_mae: 12.1727\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 322.0295 - mae: 14.2364 - val_loss: 229.5455 - val_mae: 12.1478\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 321.2755 - mae: 14.1955 - val_loss: 228.7194 - val_mae: 12.1183\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 320.5176 - mae: 14.1777 - val_loss: 228.0178 - val_mae: 12.1034\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 319.5262 - mae: 14.1531 - val_loss: 227.0727 - val_mae: 12.0826\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 318.0658 - mae: 14.1222 - val_loss: 225.6442 - val_mae: 12.0297\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 316.6926 - mae: 14.0711 - val_loss: 224.5462 - val_mae: 11.9891\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 315.3674 - mae: 14.0391 - val_loss: 223.4623 - val_mae: 11.9491\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 314.1649 - mae: 14.0107 - val_loss: 222.7340 - val_mae: 11.9229\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 312.6662 - mae: 13.9522 - val_loss: 221.6806 - val_mae: 11.8862\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.5679 - mae: 13.9289 - val_loss: 220.6581 - val_mae: 11.8469\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.4886 - mae: 13.8650 - val_loss: 219.6605 - val_mae: 11.8113\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.3382 - mae: 13.8547 - val_loss: 218.9784 - val_mae: 11.7975\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 308.2654 - mae: 13.8125 - val_loss: 217.9487 - val_mae: 11.7703\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.2323 - mae: 13.8003 - val_loss: 217.1974 - val_mae: 11.7559\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.3586 - mae: 13.7718 - val_loss: 216.0880 - val_mae: 11.7179\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.1195 - mae: 13.7499 - val_loss: 214.8455 - val_mae: 11.6733\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.9930 - mae: 13.7151 - val_loss: 213.9841 - val_mae: 11.6428\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.8985 - mae: 13.6778 - val_loss: 213.0566 - val_mae: 11.6144\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.0447 - mae: 13.6551 - val_loss: 212.1376 - val_mae: 11.5853\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.1400 - mae: 13.6474 - val_loss: 211.3098 - val_mae: 11.5621\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 299.9706 - mae: 13.5842 - val_loss: 210.1165 - val_mae: 11.5176\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.7971 - mae: 13.5650 - val_loss: 209.2424 - val_mae: 11.4893\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.5876 - mae: 13.5188 - val_loss: 208.3239 - val_mae: 11.4624\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.6630 - mae: 13.4842 - val_loss: 207.4019 - val_mae: 11.4360\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 295.5480 - mae: 13.4588 - val_loss: 206.5810 - val_mae: 11.4184\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.6953 - mae: 13.4687 - val_loss: 205.5678 - val_mae: 11.3833\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.8529 - mae: 13.4088 - val_loss: 204.4502 - val_mae: 11.3404\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 293.0859 - mae: 13.3886 - val_loss: 203.6724 - val_mae: 11.3147\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 292.3160 - mae: 13.3860 - val_loss: 202.7238 - val_mae: 11.2749\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 291.5167 - mae: 13.3292 - val_loss: 201.8160 - val_mae: 11.2356\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 290.9041 - mae: 13.3197 - val_loss: 201.2014 - val_mae: 11.2139\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 290.1902 - mae: 13.2747 - val_loss: 200.4155 - val_mae: 11.1812\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.5809 - mae: 13.2433 - val_loss: 199.9393 - val_mae: 11.1648\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.9680 - mae: 13.2478 - val_loss: 199.4986 - val_mae: 11.1504\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.4973 - mae: 13.2271 - val_loss: 199.0007 - val_mae: 11.1293\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.1389 - mae: 13.2019 - val_loss: 198.5800 - val_mae: 11.1126\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.7404 - mae: 13.2203 - val_loss: 198.2213 - val_mae: 11.0967\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.3452 - mae: 13.1975 - val_loss: 197.6672 - val_mae: 11.0659\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.1316 - mae: 13.1529 - val_loss: 197.4071 - val_mae: 11.0554\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=1, model__n_neurons=125, model__optimizer=momentum; total time=   2.5s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 1s - loss: 1723.8948 - mae: 31.7745"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 1264.2920 - mae: 27.9017 - val_loss: 737.1267 - val_mae: 22.2246\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 655.0403 - mae: 21.3123 - val_loss: 456.7644 - val_mae: 18.0544\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 517.3356 - mae: 18.9927 - val_loss: 379.6395 - val_mae: 16.4984\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 476.7038 - mae: 18.1493 - val_loss: 346.8991 - val_mae: 15.7899\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 455.4260 - mae: 17.6748 - val_loss: 328.0465 - val_mae: 15.3351\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 441.2221 - mae: 17.3508 - val_loss: 314.1541 - val_mae: 15.0170\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 430.8512 - mae: 17.1074 - val_loss: 303.6669 - val_mae: 14.7673\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 422.7269 - mae: 16.9250 - val_loss: 295.6521 - val_mae: 14.5786\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.4508 - mae: 16.7494 - val_loss: 289.2950 - val_mae: 14.4146\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 409.4214 - mae: 16.6056 - val_loss: 283.7294 - val_mae: 14.2639\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 404.2077 - mae: 16.4798 - val_loss: 278.5845 - val_mae: 14.1244\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 399.6879 - mae: 16.3572 - val_loss: 274.2709 - val_mae: 14.0032\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 395.7760 - mae: 16.2596 - val_loss: 270.7162 - val_mae: 13.8976\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 392.2691 - mae: 16.1743 - val_loss: 267.2776 - val_mae: 13.7831\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 388.8375 - mae: 16.0666 - val_loss: 264.3195 - val_mae: 13.6739\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 385.6379 - mae: 15.9847 - val_loss: 261.7437 - val_mae: 13.5698\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 382.5794 - mae: 15.8828 - val_loss: 259.1783 - val_mae: 13.4739\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 379.5125 - mae: 15.7943 - val_loss: 256.8760 - val_mae: 13.3884\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 376.7372 - mae: 15.7068 - val_loss: 254.5977 - val_mae: 13.3039\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 374.1186 - mae: 15.6399 - val_loss: 252.4365 - val_mae: 13.2187\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 371.9133 - mae: 15.5816 - val_loss: 250.2128 - val_mae: 13.1271\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.7919 - mae: 15.4877 - val_loss: 248.2136 - val_mae: 13.0450\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.7909 - mae: 15.4221 - val_loss: 246.6246 - val_mae: 12.9841\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.0191 - mae: 15.3832 - val_loss: 245.0708 - val_mae: 12.9213\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 364.3145 - mae: 15.3316 - val_loss: 243.5698 - val_mae: 12.8531\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 362.6435 - mae: 15.2660 - val_loss: 242.1365 - val_mae: 12.7909\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.0407 - mae: 15.2187 - val_loss: 240.6988 - val_mae: 12.7286\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 359.1512 - mae: 15.1603 - val_loss: 238.5332 - val_mae: 12.6479\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 356.4684 - mae: 15.0809 - val_loss: 236.7528 - val_mae: 12.5775\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 354.4533 - mae: 15.0187 - val_loss: 235.5566 - val_mae: 12.5302\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 353.0037 - mae: 14.9852 - val_loss: 234.3245 - val_mae: 12.4764\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 351.8157 - mae: 14.9312 - val_loss: 233.0513 - val_mae: 12.4190\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 350.5685 - mae: 14.9122 - val_loss: 232.4114 - val_mae: 12.3971\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 349.6141 - mae: 14.8822 - val_loss: 231.3583 - val_mae: 12.3511\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 348.6397 - mae: 14.8515 - val_loss: 230.5404 - val_mae: 12.3160\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 347.7997 - mae: 14.8428 - val_loss: 229.6552 - val_mae: 12.2679\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 346.9422 - mae: 14.7951 - val_loss: 228.7134 - val_mae: 12.2176\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 346.1440 - mae: 14.7634 - val_loss: 227.8932 - val_mae: 12.1757\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 345.3752 - mae: 14.7470 - val_loss: 227.1626 - val_mae: 12.1374\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 344.6067 - mae: 14.7025 - val_loss: 226.5546 - val_mae: 12.1114\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 343.6664 - mae: 14.7226 - val_loss: 225.9241 - val_mae: 12.0882\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.2893 - mae: 14.6729 - val_loss: 224.5988 - val_mae: 12.0306\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.5855 - mae: 14.6098 - val_loss: 223.3249 - val_mae: 11.9853\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.1388 - mae: 14.5612 - val_loss: 221.9354 - val_mae: 11.9422\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 336.0126 - mae: 14.5466 - val_loss: 220.0397 - val_mae: 11.8857\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 333.0944 - mae: 14.4100 - val_loss: 218.0375 - val_mae: 11.8164\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 330.6992 - mae: 14.3508 - val_loss: 216.3766 - val_mae: 11.7572\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 328.5742 - mae: 14.3032 - val_loss: 214.9379 - val_mae: 11.7132\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 326.6669 - mae: 14.2404 - val_loss: 213.8864 - val_mae: 11.6894\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 324.7229 - mae: 14.2295 - val_loss: 212.8077 - val_mae: 11.6717\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 323.0197 - mae: 14.1757 - val_loss: 210.6394 - val_mae: 11.5886\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 321.5331 - mae: 14.1205 - val_loss: 209.1221 - val_mae: 11.5431\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 319.8197 - mae: 14.0773 - val_loss: 207.6553 - val_mae: 11.4929\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 318.5233 - mae: 14.0452 - val_loss: 206.4055 - val_mae: 11.4463\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 316.8583 - mae: 13.9705 - val_loss: 205.0809 - val_mae: 11.3906\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 315.6582 - mae: 13.9486 - val_loss: 204.3532 - val_mae: 11.3649\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 314.5451 - mae: 13.9034 - val_loss: 203.4560 - val_mae: 11.3262\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 313.4641 - mae: 13.8830 - val_loss: 202.5279 - val_mae: 11.2861\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 312.6503 - mae: 13.8421 - val_loss: 201.7927 - val_mae: 11.2571\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.8479 - mae: 13.8277 - val_loss: 201.1918 - val_mae: 11.2339\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.1717 - mae: 13.8156 - val_loss: 200.2523 - val_mae: 11.1893\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.4168 - mae: 13.7820 - val_loss: 199.4709 - val_mae: 11.1500\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.7861 - mae: 13.7513 - val_loss: 198.6149 - val_mae: 11.1076\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.2321 - mae: 13.7246 - val_loss: 198.0978 - val_mae: 11.0831\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.0252 - mae: 13.6868 - val_loss: 197.8976 - val_mae: 11.0777\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 308.1671 - mae: 13.6874 - val_loss: 197.4960 - val_mae: 11.0570\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 307.5436 - mae: 13.6892 - val_loss: 197.1894 - val_mae: 11.0446\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.9252 - mae: 13.6592 - val_loss: 196.2614 - val_mae: 11.0014\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.2985 - mae: 13.6418 - val_loss: 195.7302 - val_mae: 10.9864\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.4371 - mae: 13.6019 - val_loss: 194.9618 - val_mae: 10.9511\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.6668 - mae: 13.6056 - val_loss: 194.2215 - val_mae: 10.9130\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 304.0769 - mae: 13.5418 - val_loss: 193.5390 - val_mae: 10.8773\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.4374 - mae: 13.5297 - val_loss: 193.4288 - val_mae: 10.8745\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.9659 - mae: 13.5174 - val_loss: 193.3042 - val_mae: 10.8706\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.7280 - mae: 13.5258 - val_loss: 193.3907 - val_mae: 10.8805\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.8345 - mae: 13.5029 - val_loss: 193.2384 - val_mae: 10.8701\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.3834 - mae: 13.5247 - val_loss: 193.0219 - val_mae: 10.8567\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.4127 - mae: 13.5566 - val_loss: 192.8766 - val_mae: 10.8497\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.9850 - mae: 13.4924 - val_loss: 192.3651 - val_mae: 10.8158\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.9719 - mae: 13.4954 - val_loss: 192.3859 - val_mae: 10.8181\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.8458 - mae: 13.5032 - val_loss: 192.3438 - val_mae: 10.8176\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.6457 - mae: 13.4680 - val_loss: 192.0775 - val_mae: 10.7995\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.5609 - mae: 13.4812 - val_loss: 192.2569 - val_mae: 10.8136\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.3788 - mae: 13.4946 - val_loss: 192.4695 - val_mae: 10.8330\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.3651 - mae: 13.4834 - val_loss: 192.2319 - val_mae: 10.8174\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.1964 - mae: 13.4858 - val_loss: 192.3576 - val_mae: 10.8270\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.0284 - mae: 13.4834 - val_loss: 192.0535 - val_mae: 10.8082\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 300.9943 - mae: 13.4736 - val_loss: 192.0683 - val_mae: 10.8129\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 300.9834 - mae: 13.5109 - val_loss: 191.9459 - val_mae: 10.8068\n",
      "Epoch 89: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=1, model__n_neurons=125, model__optimizer=momentum; total time=   2.3s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 1s - loss: 1779.9918 - mae: 31.0511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 1351.5847 - mae: 27.6500 - val_loss: 734.5964 - val_mae: 22.5340\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 599.4860 - mae: 20.6796 - val_loss: 436.5193 - val_mae: 18.2178\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 440.4869 - mae: 17.8241 - val_loss: 373.9126 - val_mae: 16.6028\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 400.4236 - mae: 16.7648 - val_loss: 356.2141 - val_mae: 15.9951\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 383.9029 - mae: 16.3008 - val_loss: 347.2350 - val_mae: 15.6814\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 372.9384 - mae: 16.0103 - val_loss: 341.4677 - val_mae: 15.4802\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.3929 - mae: 15.8172 - val_loss: 337.6465 - val_mae: 15.3501\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 359.6503 - mae: 15.6846 - val_loss: 334.7851 - val_mae: 15.2593\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.8079 - mae: 15.5538 - val_loss: 332.3548 - val_mae: 15.1761\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 350.5981 - mae: 15.4505 - val_loss: 330.2253 - val_mae: 15.1063\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 346.8640 - mae: 15.3539 - val_loss: 328.3524 - val_mae: 15.0407\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 343.6168 - mae: 15.2697 - val_loss: 326.6295 - val_mae: 14.9829\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 340.8033 - mae: 15.1924 - val_loss: 325.0742 - val_mae: 14.9298\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.2363 - mae: 15.1120 - val_loss: 323.7045 - val_mae: 14.8868\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 335.9473 - mae: 15.0523 - val_loss: 322.2301 - val_mae: 14.8363\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 333.9125 - mae: 14.9878 - val_loss: 320.9375 - val_mae: 14.7879\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 332.1363 - mae: 14.9334 - val_loss: 319.6505 - val_mae: 14.7397\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 330.2853 - mae: 14.8673 - val_loss: 318.3369 - val_mae: 14.6904\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 328.6357 - mae: 14.8097 - val_loss: 317.0822 - val_mae: 14.6559\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 326.7451 - mae: 14.7536 - val_loss: 315.6557 - val_mae: 14.6112\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 324.7920 - mae: 14.6927 - val_loss: 313.8270 - val_mae: 14.5548\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 322.7659 - mae: 14.6254 - val_loss: 312.2297 - val_mae: 14.5001\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 321.2118 - mae: 14.5692 - val_loss: 311.0313 - val_mae: 14.4584\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 319.6588 - mae: 14.5224 - val_loss: 309.6222 - val_mae: 14.4110\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 318.2262 - mae: 14.4787 - val_loss: 308.4045 - val_mae: 14.3763\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 317.1171 - mae: 14.4405 - val_loss: 307.3244 - val_mae: 14.3400\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 316.1303 - mae: 14.4168 - val_loss: 306.2916 - val_mae: 14.3097\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 315.0208 - mae: 14.3794 - val_loss: 305.2018 - val_mae: 14.2679\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 313.9755 - mae: 14.3384 - val_loss: 304.4795 - val_mae: 14.2387\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 313.2458 - mae: 14.3156 - val_loss: 303.7151 - val_mae: 14.2060\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 312.5587 - mae: 14.2899 - val_loss: 303.0369 - val_mae: 14.1785\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.8850 - mae: 14.2565 - val_loss: 302.4993 - val_mae: 14.1601\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.2770 - mae: 14.2465 - val_loss: 301.8825 - val_mae: 14.1382\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.6970 - mae: 14.2210 - val_loss: 301.2497 - val_mae: 14.1062\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.1834 - mae: 14.1931 - val_loss: 300.6611 - val_mae: 14.0854\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.6910 - mae: 14.1791 - val_loss: 299.9212 - val_mae: 14.0621\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.2212 - mae: 14.1728 - val_loss: 299.2169 - val_mae: 14.0339\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 308.5738 - mae: 14.1409 - val_loss: 298.4079 - val_mae: 14.0053\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.9799 - mae: 14.1229 - val_loss: 297.5333 - val_mae: 13.9766\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.8593 - mae: 14.0896 - val_loss: 296.7267 - val_mae: 13.9619\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.9511 - mae: 14.0647 - val_loss: 295.8415 - val_mae: 13.9427\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.0013 - mae: 14.0304 - val_loss: 295.0207 - val_mae: 13.9148\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.1018 - mae: 14.0180 - val_loss: 294.4391 - val_mae: 13.9037\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.5052 - mae: 13.9965 - val_loss: 293.7262 - val_mae: 13.8704\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.8683 - mae: 13.9654 - val_loss: 293.2225 - val_mae: 13.8492\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.3434 - mae: 13.9505 - val_loss: 292.7221 - val_mae: 13.8323\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.0317 - mae: 13.9544 - val_loss: 292.2757 - val_mae: 13.8120\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.5848 - mae: 13.9132 - val_loss: 291.8631 - val_mae: 13.7927\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.2046 - mae: 13.9084 - val_loss: 291.4837 - val_mae: 13.7785\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 300.8348 - mae: 13.8921 - val_loss: 291.1877 - val_mae: 13.7707\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 300.5374 - mae: 13.8871 - val_loss: 290.8928 - val_mae: 13.7569\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 300.2213 - mae: 13.8673 - val_loss: 290.5336 - val_mae: 13.7404\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 299.9493 - mae: 13.8529 - val_loss: 290.2711 - val_mae: 13.7335\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 299.7249 - mae: 13.8589 - val_loss: 290.0711 - val_mae: 13.7293\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 299.4302 - mae: 13.8440 - val_loss: 289.7715 - val_mae: 13.7184\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 299.2350 - mae: 13.8404 - val_loss: 289.4301 - val_mae: 13.7023\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.9729 - mae: 13.8197 - val_loss: 289.0890 - val_mae: 13.6836\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.7950 - mae: 13.8180 - val_loss: 288.8380 - val_mae: 13.6726\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.6033 - mae: 13.8016 - val_loss: 288.6857 - val_mae: 13.6706\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.4106 - mae: 13.8082 - val_loss: 288.4197 - val_mae: 13.6625\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.2463 - mae: 13.7930 - val_loss: 288.2109 - val_mae: 13.6455\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.0887 - mae: 13.7942 - val_loss: 288.0590 - val_mae: 13.6428\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.9502 - mae: 13.7849 - val_loss: 287.8536 - val_mae: 13.6333\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.7768 - mae: 13.7664 - val_loss: 287.6273 - val_mae: 13.6194\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.6587 - mae: 13.7769 - val_loss: 287.4458 - val_mae: 13.6140\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.4580 - mae: 13.7581 - val_loss: 287.2633 - val_mae: 13.6031\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.2952 - mae: 13.7521 - val_loss: 287.1499 - val_mae: 13.6038\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.2000 - mae: 13.7610 - val_loss: 286.9330 - val_mae: 13.5971\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 297.1600 - mae: 13.7395 - val_loss: 286.6939 - val_mae: 13.5840\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.8120 - mae: 13.7454 - val_loss: 286.4651 - val_mae: 13.5782\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.6418 - mae: 13.7280 - val_loss: 286.2960 - val_mae: 13.5680\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.5074 - mae: 13.7311 - val_loss: 286.1568 - val_mae: 13.5654\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.4688 - mae: 13.7148 - val_loss: 285.9655 - val_mae: 13.5562\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.2667 - mae: 13.7202 - val_loss: 285.8558 - val_mae: 13.5579\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.1228 - mae: 13.7154 - val_loss: 285.6817 - val_mae: 13.5483\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.0501 - mae: 13.7019 - val_loss: 285.5205 - val_mae: 13.5389\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 295.8549 - mae: 13.7081 - val_loss: 285.3620 - val_mae: 13.5388\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 295.7643 - mae: 13.7031 - val_loss: 285.1502 - val_mae: 13.5278\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 295.7398 - mae: 13.7163 - val_loss: 284.9877 - val_mae: 13.5183\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 295.5258 - mae: 13.6822 - val_loss: 284.7969 - val_mae: 13.5046\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 295.4050 - mae: 13.6706 - val_loss: 284.6525 - val_mae: 13.4989\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 295.3118 - mae: 13.6809 - val_loss: 284.5339 - val_mae: 13.4989\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 295.1751 - mae: 13.6709 - val_loss: 284.4194 - val_mae: 13.4969\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.9706 - mae: 13.6729 - val_loss: 284.2690 - val_mae: 13.4942\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.9124 - mae: 13.6818 - val_loss: 284.0225 - val_mae: 13.4779\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.8094 - mae: 13.6599 - val_loss: 283.8512 - val_mae: 13.4667\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.6606 - mae: 13.6415 - val_loss: 283.6628 - val_mae: 13.4585\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.4723 - mae: 13.6376 - val_loss: 283.6092 - val_mae: 13.4594\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.3503 - mae: 13.6342 - val_loss: 283.4293 - val_mae: 13.4538\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.3397 - mae: 13.6363 - val_loss: 283.2689 - val_mae: 13.4499\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.1153 - mae: 13.6312 - val_loss: 283.2417 - val_mae: 13.4541\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.0334 - mae: 13.6321 - val_loss: 283.1316 - val_mae: 13.4500\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.9342 - mae: 13.6413 - val_loss: 282.9862 - val_mae: 13.4458\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.8136 - mae: 13.6353 - val_loss: 282.7639 - val_mae: 13.4284\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.7210 - mae: 13.6144 - val_loss: 282.5948 - val_mae: 13.4159\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.5750 - mae: 13.6061 - val_loss: 282.5037 - val_mae: 13.4163\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.5272 - mae: 13.6117 - val_loss: 282.4326 - val_mae: 13.4109\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.3703 - mae: 13.5989 - val_loss: 282.2948 - val_mae: 13.4033\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.2271 - mae: 13.5867 - val_loss: 282.1656 - val_mae: 13.3980\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.2175 - mae: 13.5966 - val_loss: 282.0765 - val_mae: 13.3949\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=1, model__n_neurons=125, model__optimizer=momentum; total time=   2.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=25, model__optimizer=adam; total time=   0.5s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 706us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=25, model__optimizer=adam; total time=   0.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 20776.2676 - mae: 67.5026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=0, model__n_neurons=25, model__optimizer=adam; total time=   0.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 465.5634 - mae: 18.2180 - val_loss: 361.3523 - val_mae: 16.3968\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 457.2914 - mae: 18.5920 - val_loss: 408.1030 - val_mae: 19.1182\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 465.1956 - mae: 18.8007 - val_loss: 261.2585 - val_mae: 14.1365\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 453.4786 - mae: 18.4825 - val_loss: 380.8039 - val_mae: 18.1055\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 408.9981 - mae: 17.2346 - val_loss: 278.1801 - val_mae: 14.4643\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 509.5027 - mae: 20.0256 - val_loss: 260.5358 - val_mae: 13.8385\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 490.8238 - mae: 19.6128 - val_loss: 293.5523 - val_mae: 14.7855\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 489.1307 - mae: 19.5938 - val_loss: 339.5274 - val_mae: 16.2086\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 426.4922 - mae: 17.7520 - val_loss: 521.0706 - val_mae: 21.0818\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.2162 - mae: 20.9034 - val_loss: 439.4140 - val_mae: 19.9456\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 470.1630 - mae: 18.9399 - val_loss: 281.6848 - val_mae: 14.3172\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 505.2863 - mae: 20.0841 - val_loss: 427.7146 - val_mae: 19.7365\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 448.4218 - mae: 18.6649 - val_loss: 305.4945 - val_mae: 15.8045\n",
      "Epoch 13: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=125, model__optimizer=momentum; total time=   0.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 526.2020 - mae: 19.5130 - val_loss: 280.2726 - val_mae: 14.6994\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 475.7160 - mae: 18.7113 - val_loss: 322.7076 - val_mae: 15.9270\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 486.6980 - mae: 18.8640 - val_loss: 357.3246 - val_mae: 17.5281\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 433.9598 - mae: 17.4495 - val_loss: 342.3487 - val_mae: 16.8068\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 483.4257 - mae: 19.0177 - val_loss: 292.3896 - val_mae: 14.7381\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 489.8700 - mae: 19.0186 - val_loss: 286.1378 - val_mae: 14.7814\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 479.9536 - mae: 18.7408 - val_loss: 297.7863 - val_mae: 14.9166\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.3447 - mae: 20.7190 - val_loss: 416.4804 - val_mae: 19.2780\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 498.2538 - mae: 19.3077 - val_loss: 462.9869 - val_mae: 19.9107\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 511.7369 - mae: 19.4619 - val_loss: 290.1660 - val_mae: 14.6158\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 466.8198 - mae: 18.5248 - val_loss: 311.7580 - val_mae: 16.0853\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=125, model__optimizer=momentum; total time=   0.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 506.5697 - mae: 19.0185 - val_loss: 571.2803 - val_mae: 19.9501\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 383.7697 - mae: 16.6925 - val_loss: 621.4375 - val_mae: 22.2608\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 475.2865 - mae: 19.3974 - val_loss: 373.3035 - val_mae: 16.5252\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 405.5351 - mae: 17.4848 - val_loss: 479.4182 - val_mae: 19.8367\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 387.7704 - mae: 16.6535 - val_loss: 329.3849 - val_mae: 14.9044\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 389.1792 - mae: 16.8286 - val_loss: 346.0105 - val_mae: 15.5187\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 416.4274 - mae: 17.8040 - val_loss: 459.6108 - val_mae: 18.9263\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 440.3235 - mae: 18.4874 - val_loss: 347.1401 - val_mae: 15.8341\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.5142 - mae: 16.6498 - val_loss: 532.3698 - val_mae: 21.2797\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 408.6792 - mae: 17.5323 - val_loss: 326.2332 - val_mae: 15.0779\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 331.0630 - mae: 15.0815 - val_loss: 279.8839 - val_mae: 13.4498\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 349.9595 - mae: 15.9892 - val_loss: 532.8471 - val_mae: 21.3112\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 405.0496 - mae: 17.3821 - val_loss: 326.0906 - val_mae: 14.8578\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 443.3317 - mae: 18.1888 - val_loss: 508.8416 - val_mae: 20.5469\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 471.2201 - mae: 19.5041 - val_loss: 547.0114 - val_mae: 21.7853\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 470.9901 - mae: 19.2530 - val_loss: 406.9274 - val_mae: 17.5817\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 504.8354 - mae: 20.4302 - val_loss: 547.7905 - val_mae: 21.8139\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 513.3566 - mae: 20.4684 - val_loss: 445.0039 - val_mae: 18.7964\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 437.1143 - mae: 18.5055 - val_loss: 419.2848 - val_mae: 18.1514\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 382.9854 - mae: 16.6604 - val_loss: 423.3751 - val_mae: 18.6058\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 381.3284 - mae: 16.7569 - val_loss: 525.4779 - val_mae: 21.3704\n",
      "Epoch 21: early stopping\n",
      "5/5 [==============================] - 0s 782us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=125, model__optimizer=momentum; total time=   0.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 1475.1467 - mae: 30.2846 - val_loss: 1420.8390 - val_mae: 28.7895\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1471.8301 - mae: 30.2613 - val_loss: 1417.4073 - val_mae: 28.7652\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1468.5186 - mae: 30.2382 - val_loss: 1413.9865 - val_mae: 28.7409\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1465.2208 - mae: 30.2152 - val_loss: 1410.5791 - val_mae: 28.7167\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1461.9612 - mae: 30.1920 - val_loss: 1407.1913 - val_mae: 28.6926\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1458.6680 - mae: 30.1694 - val_loss: 1403.8193 - val_mae: 28.6685\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1455.4380 - mae: 30.1470 - val_loss: 1400.4406 - val_mae: 28.6444\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1452.1544 - mae: 30.1235 - val_loss: 1397.0969 - val_mae: 28.6205\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1448.9458 - mae: 30.1010 - val_loss: 1393.7404 - val_mae: 28.5964\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1445.7103 - mae: 30.0786 - val_loss: 1390.4242 - val_mae: 28.5725\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1442.5355 - mae: 30.0558 - val_loss: 1387.1046 - val_mae: 28.5487\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1439.3289 - mae: 30.0337 - val_loss: 1383.8323 - val_mae: 28.5251\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1436.1505 - mae: 30.0113 - val_loss: 1380.5596 - val_mae: 28.5016\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1433.0245 - mae: 29.9894 - val_loss: 1377.2682 - val_mae: 28.4778\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1429.8152 - mae: 29.9672 - val_loss: 1374.0167 - val_mae: 28.4542\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1426.6567 - mae: 29.9450 - val_loss: 1370.7522 - val_mae: 28.4313\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1423.5353 - mae: 29.9224 - val_loss: 1367.4827 - val_mae: 28.4094\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1420.4086 - mae: 29.9004 - val_loss: 1364.2272 - val_mae: 28.3879\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1417.2671 - mae: 29.8784 - val_loss: 1361.0253 - val_mae: 28.3666\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1414.1528 - mae: 29.8568 - val_loss: 1357.8286 - val_mae: 28.3454\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1411.0275 - mae: 29.8342 - val_loss: 1354.6401 - val_mae: 28.3242\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1407.9658 - mae: 29.8126 - val_loss: 1351.4196 - val_mae: 28.3029\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1404.8933 - mae: 29.7906 - val_loss: 1348.2006 - val_mae: 28.2814\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1401.7571 - mae: 29.7688 - val_loss: 1345.0507 - val_mae: 28.2603\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1398.7179 - mae: 29.7475 - val_loss: 1341.8838 - val_mae: 28.2391\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1395.6630 - mae: 29.7259 - val_loss: 1338.7158 - val_mae: 28.2175\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1392.6133 - mae: 29.7042 - val_loss: 1335.5597 - val_mae: 28.1959\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1389.5743 - mae: 29.6824 - val_loss: 1332.4290 - val_mae: 28.1744\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1386.6128 - mae: 29.6614 - val_loss: 1329.2623 - val_mae: 28.1526\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1383.5244 - mae: 29.6394 - val_loss: 1326.1608 - val_mae: 28.1313\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1380.5457 - mae: 29.6181 - val_loss: 1323.0431 - val_mae: 28.1097\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1377.5354 - mae: 29.5962 - val_loss: 1319.9337 - val_mae: 28.0882\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1374.5887 - mae: 29.5753 - val_loss: 1316.8083 - val_mae: 28.0665\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1371.5629 - mae: 29.5537 - val_loss: 1313.7612 - val_mae: 28.0460\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1368.6141 - mae: 29.5328 - val_loss: 1310.7257 - val_mae: 28.0257\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1365.6451 - mae: 29.5117 - val_loss: 1307.6964 - val_mae: 28.0055\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1362.7429 - mae: 29.4904 - val_loss: 1304.5994 - val_mae: 27.9847\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1359.7509 - mae: 29.4687 - val_loss: 1301.5497 - val_mae: 27.9642\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1356.8254 - mae: 29.4476 - val_loss: 1298.5031 - val_mae: 27.9437\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1353.8947 - mae: 29.4259 - val_loss: 1295.4850 - val_mae: 27.9231\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1350.9575 - mae: 29.4047 - val_loss: 1292.4907 - val_mae: 27.9028\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1348.0497 - mae: 29.3835 - val_loss: 1289.5095 - val_mae: 27.8826\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1345.1479 - mae: 29.3621 - val_loss: 1286.5363 - val_mae: 27.8624\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1342.2991 - mae: 29.3408 - val_loss: 1283.5317 - val_mae: 27.8419\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1339.3674 - mae: 29.3193 - val_loss: 1280.5862 - val_mae: 27.8218\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1336.5325 - mae: 29.2981 - val_loss: 1277.6216 - val_mae: 27.8015\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1333.6825 - mae: 29.2769 - val_loss: 1274.6597 - val_mae: 27.7811\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1330.8066 - mae: 29.2557 - val_loss: 1271.7382 - val_mae: 27.7610\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1327.9941 - mae: 29.2347 - val_loss: 1268.8201 - val_mae: 27.7409\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1325.1656 - mae: 29.2140 - val_loss: 1265.9045 - val_mae: 27.7207\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1322.3456 - mae: 29.1929 - val_loss: 1263.0079 - val_mae: 27.7006\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1319.5286 - mae: 29.1721 - val_loss: 1260.1101 - val_mae: 27.6805\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1316.7301 - mae: 29.1506 - val_loss: 1257.2134 - val_mae: 27.6603\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1313.9194 - mae: 29.1300 - val_loss: 1254.3309 - val_mae: 27.6403\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1311.1630 - mae: 29.1087 - val_loss: 1251.4358 - val_mae: 27.6199\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1308.3523 - mae: 29.0878 - val_loss: 1248.5775 - val_mae: 27.5999\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1305.5851 - mae: 29.0669 - val_loss: 1245.7188 - val_mae: 27.5799\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1302.8212 - mae: 29.0458 - val_loss: 1242.8655 - val_mae: 27.5598\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1300.0321 - mae: 29.0247 - val_loss: 1240.0638 - val_mae: 27.5400\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1297.3640 - mae: 29.0040 - val_loss: 1237.2050 - val_mae: 27.5197\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1294.5724 - mae: 28.9831 - val_loss: 1234.3995 - val_mae: 27.4998\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1291.8457 - mae: 28.9622 - val_loss: 1231.5992 - val_mae: 27.4799\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1289.1234 - mae: 28.9416 - val_loss: 1228.8016 - val_mae: 27.4601\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1286.4076 - mae: 28.9202 - val_loss: 1226.0077 - val_mae: 27.4401\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1283.7158 - mae: 28.8998 - val_loss: 1223.2089 - val_mae: 27.4202\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1281.0076 - mae: 28.8789 - val_loss: 1220.4149 - val_mae: 27.4002\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1278.3074 - mae: 28.8580 - val_loss: 1217.6250 - val_mae: 27.3802\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1275.6154 - mae: 28.8374 - val_loss: 1214.8492 - val_mae: 27.3608\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1272.9387 - mae: 28.8164 - val_loss: 1212.0931 - val_mae: 27.3418\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1270.2496 - mae: 28.7954 - val_loss: 1209.3676 - val_mae: 27.3229\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1267.5914 - mae: 28.7749 - val_loss: 1206.6423 - val_mae: 27.3040\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1264.9624 - mae: 28.7541 - val_loss: 1203.8655 - val_mae: 27.2845\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1262.2993 - mae: 28.7336 - val_loss: 1201.1376 - val_mae: 27.2654\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1259.6613 - mae: 28.7129 - val_loss: 1198.4105 - val_mae: 27.2461\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1257.0729 - mae: 28.6923 - val_loss: 1195.6727 - val_mae: 27.2268\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1254.4293 - mae: 28.6714 - val_loss: 1192.9722 - val_mae: 27.2076\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1251.8053 - mae: 28.6512 - val_loss: 1190.2761 - val_mae: 27.1885\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1249.2208 - mae: 28.6309 - val_loss: 1187.5869 - val_mae: 27.1694\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1246.6404 - mae: 28.6104 - val_loss: 1184.8994 - val_mae: 27.1503\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1244.0342 - mae: 28.5898 - val_loss: 1182.2415 - val_mae: 27.1311\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1241.4857 - mae: 28.5694 - val_loss: 1179.5764 - val_mae: 27.1121\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1238.9177 - mae: 28.5490 - val_loss: 1176.9149 - val_mae: 27.0933\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1236.3834 - mae: 28.5288 - val_loss: 1174.2529 - val_mae: 27.0746\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1233.8199 - mae: 28.5087 - val_loss: 1171.6288 - val_mae: 27.0562\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1231.3008 - mae: 28.4888 - val_loss: 1169.0189 - val_mae: 27.0376\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1228.7738 - mae: 28.4686 - val_loss: 1166.4164 - val_mae: 27.0192\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1226.2335 - mae: 28.4487 - val_loss: 1163.8439 - val_mae: 27.0009\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1223.7878 - mae: 28.4290 - val_loss: 1161.2180 - val_mae: 26.9825\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1221.2544 - mae: 28.4088 - val_loss: 1158.6224 - val_mae: 26.9641\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1218.7378 - mae: 28.3890 - val_loss: 1156.0557 - val_mae: 26.9460\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1216.2750 - mae: 28.3691 - val_loss: 1153.4716 - val_mae: 26.9274\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1213.7500 - mae: 28.3492 - val_loss: 1150.9313 - val_mae: 26.9093\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1211.2806 - mae: 28.3294 - val_loss: 1148.3690 - val_mae: 26.8909\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1208.8286 - mae: 28.3100 - val_loss: 1145.7935 - val_mae: 26.8726\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1206.3492 - mae: 28.2901 - val_loss: 1143.2366 - val_mae: 26.8543\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1203.8878 - mae: 28.2703 - val_loss: 1140.6978 - val_mae: 26.8360\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1201.4648 - mae: 28.2504 - val_loss: 1138.1350 - val_mae: 26.8170\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1198.9913 - mae: 28.2306 - val_loss: 1135.6084 - val_mae: 26.7984\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1196.5536 - mae: 28.2110 - val_loss: 1133.0839 - val_mae: 26.7795\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1194.1647 - mae: 28.1915 - val_loss: 1130.5474 - val_mae: 26.7606\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=adam; total time=   2.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 1627.2705 - mae: 31.7903 - val_loss: 1503.5753 - val_mae: 29.7201\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1622.4821 - mae: 31.7567 - val_loss: 1498.6180 - val_mae: 29.6853\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1617.7784 - mae: 31.7228 - val_loss: 1493.6661 - val_mae: 29.6504\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1613.0496 - mae: 31.6889 - val_loss: 1488.7495 - val_mae: 29.6157\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1608.3358 - mae: 31.6554 - val_loss: 1483.8694 - val_mae: 29.5812\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1603.6200 - mae: 31.6217 - val_loss: 1479.0237 - val_mae: 29.5469\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1598.9703 - mae: 31.5881 - val_loss: 1474.1604 - val_mae: 29.5124\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1594.3353 - mae: 31.5546 - val_loss: 1469.3022 - val_mae: 29.4780\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1589.6627 - mae: 31.5211 - val_loss: 1464.5016 - val_mae: 29.4438\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1585.1151 - mae: 31.4882 - val_loss: 1459.6903 - val_mae: 29.4095\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1580.4866 - mae: 31.4549 - val_loss: 1454.9374 - val_mae: 29.3754\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1575.9432 - mae: 31.4220 - val_loss: 1450.2064 - val_mae: 29.3415\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1571.3915 - mae: 31.3893 - val_loss: 1445.4772 - val_mae: 29.3074\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1566.8992 - mae: 31.3568 - val_loss: 1440.7196 - val_mae: 29.2732\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1562.3275 - mae: 31.3238 - val_loss: 1436.0253 - val_mae: 29.2393\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1557.7606 - mae: 31.2910 - val_loss: 1431.3750 - val_mae: 29.2056\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1553.3251 - mae: 31.2587 - val_loss: 1426.6960 - val_mae: 29.1717\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1548.8641 - mae: 31.2264 - val_loss: 1422.0328 - val_mae: 29.1380\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1544.3593 - mae: 31.1935 - val_loss: 1417.4471 - val_mae: 29.1059\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1539.8810 - mae: 31.1612 - val_loss: 1412.8929 - val_mae: 29.0739\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1535.4912 - mae: 31.1294 - val_loss: 1408.2927 - val_mae: 29.0415\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1531.0935 - mae: 31.0973 - val_loss: 1403.6930 - val_mae: 29.0091\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1526.6583 - mae: 31.0645 - val_loss: 1399.1400 - val_mae: 28.9770\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1522.2665 - mae: 31.0327 - val_loss: 1394.6218 - val_mae: 28.9449\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1517.9197 - mae: 31.0007 - val_loss: 1390.1409 - val_mae: 28.9131\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1513.5902 - mae: 30.9688 - val_loss: 1385.6548 - val_mae: 28.8811\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1509.2518 - mae: 30.9365 - val_loss: 1381.2029 - val_mae: 28.8494\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1504.9796 - mae: 30.9049 - val_loss: 1376.7268 - val_mae: 28.8174\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1500.6813 - mae: 30.8730 - val_loss: 1372.2803 - val_mae: 28.7855\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1496.4149 - mae: 30.8413 - val_loss: 1367.8501 - val_mae: 28.7537\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1492.1121 - mae: 30.8094 - val_loss: 1363.4901 - val_mae: 28.7223\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1487.9126 - mae: 30.7778 - val_loss: 1359.1117 - val_mae: 28.6907\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1483.6787 - mae: 30.7463 - val_loss: 1354.7788 - val_mae: 28.6593\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1479.4600 - mae: 30.7146 - val_loss: 1350.4799 - val_mae: 28.6282\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1475.3220 - mae: 30.6831 - val_loss: 1346.1361 - val_mae: 28.5966\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1471.0983 - mae: 30.6515 - val_loss: 1341.8677 - val_mae: 28.5654\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1466.9902 - mae: 30.6205 - val_loss: 1337.5503 - val_mae: 28.5339\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1462.8102 - mae: 30.5891 - val_loss: 1333.2872 - val_mae: 28.5028\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1458.7233 - mae: 30.5580 - val_loss: 1329.0177 - val_mae: 28.4715\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1454.5630 - mae: 30.5266 - val_loss: 1324.8042 - val_mae: 28.4406\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1450.4248 - mae: 30.4956 - val_loss: 1320.6294 - val_mae: 28.4098\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1446.3840 - mae: 30.4648 - val_loss: 1316.4258 - val_mae: 28.3787\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1442.3152 - mae: 30.4340 - val_loss: 1312.2286 - val_mae: 28.3477\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1438.2710 - mae: 30.4034 - val_loss: 1308.0381 - val_mae: 28.3167\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1434.1414 - mae: 30.3728 - val_loss: 1303.9445 - val_mae: 28.2862\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1430.2410 - mae: 30.3427 - val_loss: 1299.7664 - val_mae: 28.2551\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1426.1855 - mae: 30.3121 - val_loss: 1295.6440 - val_mae: 28.2244\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1422.1985 - mae: 30.2817 - val_loss: 1291.5322 - val_mae: 28.1937\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1418.2384 - mae: 30.2516 - val_loss: 1287.4413 - val_mae: 28.1630\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1414.2543 - mae: 30.2213 - val_loss: 1283.3905 - val_mae: 28.1326\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 1410.2911 - mae: 30.1916 - val_loss: 1279.3376 - val_mae: 28.1020\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1406.3879 - mae: 30.1615 - val_loss: 1275.2639 - val_mae: 28.0713\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1402.4290 - mae: 30.1317 - val_loss: 1271.2542 - val_mae: 28.0410\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1398.5332 - mae: 30.1020 - val_loss: 1267.2478 - val_mae: 28.0106\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1394.6584 - mae: 30.0726 - val_loss: 1263.2362 - val_mae: 27.9802\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1390.8110 - mae: 30.0431 - val_loss: 1259.2424 - val_mae: 27.9498\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1386.9641 - mae: 30.0133 - val_loss: 1255.2914 - val_mae: 27.9197\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1383.1290 - mae: 29.9841 - val_loss: 1251.3521 - val_mae: 27.8896\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1379.2814 - mae: 29.9545 - val_loss: 1247.4226 - val_mae: 27.8595\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1375.4706 - mae: 29.9255 - val_loss: 1243.5076 - val_mae: 27.8294\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1371.6375 - mae: 29.8958 - val_loss: 1239.6334 - val_mae: 27.7995\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1367.8660 - mae: 29.8670 - val_loss: 1235.7717 - val_mae: 27.7697\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1364.0787 - mae: 29.8376 - val_loss: 1231.9158 - val_mae: 27.7399\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1360.3104 - mae: 29.8085 - val_loss: 1228.0696 - val_mae: 27.7101\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1356.6022 - mae: 29.7790 - val_loss: 1224.1849 - val_mae: 27.6800\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1352.8477 - mae: 29.7499 - val_loss: 1220.3522 - val_mae: 27.6503\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1349.0577 - mae: 29.7209 - val_loss: 1216.5857 - val_mae: 27.6217\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1345.4087 - mae: 29.6920 - val_loss: 1212.7556 - val_mae: 27.5928\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1341.6492 - mae: 29.6628 - val_loss: 1208.9723 - val_mae: 27.5642\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1337.9526 - mae: 29.6337 - val_loss: 1205.1932 - val_mae: 27.5355\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1334.2394 - mae: 29.6048 - val_loss: 1201.4546 - val_mae: 27.5071\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1330.5616 - mae: 29.5757 - val_loss: 1197.7104 - val_mae: 27.4786\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1326.8821 - mae: 29.5471 - val_loss: 1193.9983 - val_mae: 27.4503\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1323.1898 - mae: 29.5182 - val_loss: 1190.3070 - val_mae: 27.4220\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1319.5752 - mae: 29.4899 - val_loss: 1186.5840 - val_mae: 27.3934\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1315.9316 - mae: 29.4612 - val_loss: 1182.8785 - val_mae: 27.3649\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1312.2931 - mae: 29.4328 - val_loss: 1179.1978 - val_mae: 27.3366\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1308.6129 - mae: 29.4046 - val_loss: 1175.5739 - val_mae: 27.3085\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1305.0549 - mae: 29.3765 - val_loss: 1171.8857 - val_mae: 27.2800\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1301.4355 - mae: 29.3480 - val_loss: 1168.2253 - val_mae: 27.2516\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1297.8131 - mae: 29.3201 - val_loss: 1164.6005 - val_mae: 27.2233\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1294.2322 - mae: 29.2919 - val_loss: 1160.9795 - val_mae: 27.1948\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1290.6733 - mae: 29.2643 - val_loss: 1157.3683 - val_mae: 27.1669\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1287.0846 - mae: 29.2362 - val_loss: 1153.7991 - val_mae: 27.1395\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1283.5786 - mae: 29.2086 - val_loss: 1150.1952 - val_mae: 27.1119\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1280.0333 - mae: 29.1809 - val_loss: 1146.6361 - val_mae: 27.0845\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1276.4906 - mae: 29.1529 - val_loss: 1143.0815 - val_mae: 27.0571\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1272.9395 - mae: 29.1253 - val_loss: 1139.5682 - val_mae: 27.0299\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1269.4569 - mae: 29.0976 - val_loss: 1136.0361 - val_mae: 27.0026\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1265.9595 - mae: 29.0700 - val_loss: 1132.5178 - val_mae: 26.9752\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1262.5205 - mae: 29.0426 - val_loss: 1128.9614 - val_mae: 26.9476\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1258.9597 - mae: 29.0144 - val_loss: 1125.5165 - val_mae: 26.9207\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1255.5366 - mae: 28.9871 - val_loss: 1122.0574 - val_mae: 26.8936\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1252.1504 - mae: 28.9599 - val_loss: 1118.5806 - val_mae: 26.8660\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1248.6836 - mae: 28.9327 - val_loss: 1115.1716 - val_mae: 26.8389\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1245.3032 - mae: 28.9056 - val_loss: 1111.7673 - val_mae: 26.8117\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1241.9043 - mae: 28.8782 - val_loss: 1108.3622 - val_mae: 26.7845\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1238.5796 - mae: 28.8511 - val_loss: 1104.9240 - val_mae: 26.7569\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1235.1602 - mae: 28.8235 - val_loss: 1101.5381 - val_mae: 26.7297\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 1231.8123 - mae: 28.7962 - val_loss: 1098.1659 - val_mae: 26.7025\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=adam; total time=   2.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 4746.9170 - mae: 52.9956 - val_loss: 3719.3997 - val_mae: 48.1325\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4736.7124 - mae: 52.9359 - val_loss: 3710.3792 - val_mae: 48.0754\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4726.3936 - mae: 52.8749 - val_loss: 3701.4324 - val_mae: 48.0188\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4716.2808 - mae: 52.8141 - val_loss: 3692.4797 - val_mae: 47.9621\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4705.9863 - mae: 52.7530 - val_loss: 3683.5854 - val_mae: 47.9057\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4695.9414 - mae: 52.6932 - val_loss: 3674.6606 - val_mae: 47.8488\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4685.7119 - mae: 52.6326 - val_loss: 3665.8174 - val_mae: 47.7923\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4675.6406 - mae: 52.5720 - val_loss: 3656.9668 - val_mae: 47.7359\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4665.5801 - mae: 52.5124 - val_loss: 3648.1311 - val_mae: 47.6792\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4655.6021 - mae: 52.4515 - val_loss: 3639.2859 - val_mae: 47.6227\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4645.4302 - mae: 52.3915 - val_loss: 3630.5859 - val_mae: 47.5667\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4635.4990 - mae: 52.3317 - val_loss: 3621.8625 - val_mae: 47.5107\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4625.5791 - mae: 52.2715 - val_loss: 3613.1189 - val_mae: 47.4545\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4615.6499 - mae: 52.2116 - val_loss: 3604.4065 - val_mae: 47.3983\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4605.7178 - mae: 52.1521 - val_loss: 3595.7566 - val_mae: 47.3423\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4595.7217 - mae: 52.0928 - val_loss: 3587.1970 - val_mae: 47.2868\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4586.0361 - mae: 52.0328 - val_loss: 3578.5271 - val_mae: 47.2304\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4576.0894 - mae: 51.9729 - val_loss: 3569.9417 - val_mae: 47.1747\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4566.2812 - mae: 51.9141 - val_loss: 3561.3550 - val_mae: 47.1189\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4556.5957 - mae: 51.8548 - val_loss: 3552.7217 - val_mae: 47.0628\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4546.6577 - mae: 51.7955 - val_loss: 3544.2246 - val_mae: 47.0078\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4537.0708 - mae: 51.7367 - val_loss: 3535.6907 - val_mae: 46.9532\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4527.3052 - mae: 51.6777 - val_loss: 3527.2488 - val_mae: 46.8989\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4517.6899 - mae: 51.6187 - val_loss: 3518.7839 - val_mae: 46.8443\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4508.0947 - mae: 51.5604 - val_loss: 3510.3962 - val_mae: 46.7902\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4498.4297 - mae: 51.5017 - val_loss: 3502.0891 - val_mae: 46.7364\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4488.9702 - mae: 51.4427 - val_loss: 3493.7144 - val_mae: 46.6823\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4479.3589 - mae: 51.3849 - val_loss: 3485.3948 - val_mae: 46.6285\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4469.8472 - mae: 51.3275 - val_loss: 3477.1421 - val_mae: 46.5747\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4460.4282 - mae: 51.2686 - val_loss: 3468.9153 - val_mae: 46.5212\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4450.9937 - mae: 51.2113 - val_loss: 3460.6599 - val_mae: 46.4674\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4441.5864 - mae: 51.1527 - val_loss: 3452.4375 - val_mae: 46.4139\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4432.2627 - mae: 51.0957 - val_loss: 3444.2339 - val_mae: 46.3603\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4422.9199 - mae: 51.0379 - val_loss: 3436.0552 - val_mae: 46.3068\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4413.5776 - mae: 50.9805 - val_loss: 3427.9780 - val_mae: 46.2539\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4404.3115 - mae: 50.9236 - val_loss: 3419.9131 - val_mae: 46.2009\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4395.0991 - mae: 50.8669 - val_loss: 3411.8801 - val_mae: 46.1481\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4385.8916 - mae: 50.8102 - val_loss: 3403.8525 - val_mae: 46.0955\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4376.7358 - mae: 50.7542 - val_loss: 3395.8062 - val_mae: 46.0428\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4367.5410 - mae: 50.6968 - val_loss: 3387.8271 - val_mae: 45.9904\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4358.5366 - mae: 50.6411 - val_loss: 3379.8079 - val_mae: 45.9372\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4349.3472 - mae: 50.5844 - val_loss: 3371.8513 - val_mae: 45.8845\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4340.2607 - mae: 50.5280 - val_loss: 3363.9146 - val_mae: 45.8321\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4331.1577 - mae: 50.4718 - val_loss: 3356.0256 - val_mae: 45.7797\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4322.2056 - mae: 50.4156 - val_loss: 3348.1106 - val_mae: 45.7271\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4313.1582 - mae: 50.3598 - val_loss: 3340.2698 - val_mae: 45.6748\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4304.2417 - mae: 50.3044 - val_loss: 3332.4331 - val_mae: 45.6227\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4295.2896 - mae: 50.2484 - val_loss: 3324.6187 - val_mae: 45.5706\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4286.2407 - mae: 50.1930 - val_loss: 3316.8894 - val_mae: 45.5190\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4277.5171 - mae: 50.1388 - val_loss: 3309.1047 - val_mae: 45.4667\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4268.6338 - mae: 50.0838 - val_loss: 3301.3516 - val_mae: 45.4147\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4259.8203 - mae: 50.0279 - val_loss: 3293.6169 - val_mae: 45.3628\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4250.9023 - mae: 49.9727 - val_loss: 3285.9534 - val_mae: 45.3113\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4242.2119 - mae: 49.9174 - val_loss: 3278.2432 - val_mae: 45.2592\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4233.4092 - mae: 49.8625 - val_loss: 3270.5996 - val_mae: 45.2075\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4224.6953 - mae: 49.8076 - val_loss: 3262.9612 - val_mae: 45.1559\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4215.9321 - mae: 49.7530 - val_loss: 3255.3687 - val_mae: 45.1043\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4207.2515 - mae: 49.6980 - val_loss: 3247.7876 - val_mae: 45.0526\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4198.6680 - mae: 49.6431 - val_loss: 3240.2058 - val_mae: 45.0008\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4189.8843 - mae: 49.5885 - val_loss: 3232.7354 - val_mae: 44.9498\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4181.4468 - mae: 49.5341 - val_loss: 3225.1514 - val_mae: 44.8981\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4172.6470 - mae: 49.4795 - val_loss: 3217.7422 - val_mae: 44.8470\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4164.1602 - mae: 49.4250 - val_loss: 3210.2803 - val_mae: 44.7957\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4155.6265 - mae: 49.3711 - val_loss: 3202.8162 - val_mae: 44.7447\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4147.0879 - mae: 49.3163 - val_loss: 3195.3953 - val_mae: 44.6936\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4138.5669 - mae: 49.2623 - val_loss: 3187.9749 - val_mae: 44.6426\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4130.0752 - mae: 49.2081 - val_loss: 3180.5615 - val_mae: 44.5913\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4121.5625 - mae: 49.1536 - val_loss: 3173.2109 - val_mae: 44.5406\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4113.2129 - mae: 49.0994 - val_loss: 3165.8225 - val_mae: 44.4894\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4104.7158 - mae: 49.0455 - val_loss: 3158.5374 - val_mae: 44.4389\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4096.4233 - mae: 48.9922 - val_loss: 3151.2034 - val_mae: 44.3879\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4088.0173 - mae: 48.9383 - val_loss: 3143.9436 - val_mae: 44.3373\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4079.6672 - mae: 48.8848 - val_loss: 3136.7087 - val_mae: 44.2868\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4071.4211 - mae: 48.8319 - val_loss: 3129.4719 - val_mae: 44.2364\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4063.1055 - mae: 48.7783 - val_loss: 3122.2690 - val_mae: 44.1863\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4054.8757 - mae: 48.7258 - val_loss: 3115.0662 - val_mae: 44.1358\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4046.6028 - mae: 48.6726 - val_loss: 3107.9390 - val_mae: 44.0858\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4038.4077 - mae: 48.6199 - val_loss: 3100.8232 - val_mae: 44.0359\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4030.2278 - mae: 48.5672 - val_loss: 3093.7256 - val_mae: 43.9860\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4022.1067 - mae: 48.5148 - val_loss: 3086.6018 - val_mae: 43.9361\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4013.9580 - mae: 48.4618 - val_loss: 3079.5115 - val_mae: 43.8864\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 4005.7954 - mae: 48.4100 - val_loss: 3072.4734 - val_mae: 43.8364\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3997.7178 - mae: 48.3575 - val_loss: 3065.4207 - val_mae: 43.7863\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3989.6479 - mae: 48.3047 - val_loss: 3058.4231 - val_mae: 43.7364\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3981.5388 - mae: 48.2528 - val_loss: 3051.4709 - val_mae: 43.6867\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3973.5874 - mae: 48.2006 - val_loss: 3044.4746 - val_mae: 43.6367\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3965.5393 - mae: 48.1485 - val_loss: 3037.4949 - val_mae: 43.5870\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3957.5447 - mae: 48.0965 - val_loss: 3030.5537 - val_mae: 43.5373\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3949.6531 - mae: 48.0444 - val_loss: 3023.5906 - val_mae: 43.4875\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3941.6401 - mae: 47.9923 - val_loss: 3016.6973 - val_mae: 43.4381\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3933.7561 - mae: 47.9410 - val_loss: 3009.8147 - val_mae: 43.3890\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3925.8777 - mae: 47.8897 - val_loss: 3002.9653 - val_mae: 43.3399\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3918.0186 - mae: 47.8382 - val_loss: 2996.1558 - val_mae: 43.2908\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3910.1809 - mae: 47.7874 - val_loss: 2989.3975 - val_mae: 43.2417\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3902.3555 - mae: 47.7361 - val_loss: 2982.6277 - val_mae: 43.1930\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3894.5967 - mae: 47.6857 - val_loss: 2975.8660 - val_mae: 43.1439\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3886.8455 - mae: 47.6340 - val_loss: 2969.1062 - val_mae: 43.0954\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3879.0413 - mae: 47.5832 - val_loss: 2962.3708 - val_mae: 43.0463\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3871.3325 - mae: 47.5321 - val_loss: 2955.6348 - val_mae: 42.9977\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 3863.5469 - mae: 47.4818 - val_loss: 2948.9888 - val_mae: 42.9510\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=adam; total time=   2.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 727.9274 - mae: 20.7276 - val_loss: 313.3366 - val_mae: 15.5422\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 425.0894 - mae: 17.3580 - val_loss: 304.2885 - val_mae: 15.0344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 408.4826 - mae: 16.8780 - val_loss: 287.0294 - val_mae: 14.3635\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 392.3724 - mae: 16.4781 - val_loss: 293.1767 - val_mae: 14.9387\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 389.4978 - mae: 16.3209 - val_loss: 269.2209 - val_mae: 13.6084\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 380.7594 - mae: 16.0225 - val_loss: 274.4070 - val_mae: 13.8953\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 383.5621 - mae: 16.0558 - val_loss: 269.1890 - val_mae: 13.5321\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 385.8740 - mae: 16.2537 - val_loss: 275.2427 - val_mae: 14.0457\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 374.1852 - mae: 15.6741 - val_loss: 282.6181 - val_mae: 14.4394\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 377.5555 - mae: 15.8775 - val_loss: 268.7258 - val_mae: 13.6135\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 375.7751 - mae: 15.7936 - val_loss: 265.5775 - val_mae: 13.3280\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 375.4167 - mae: 15.7008 - val_loss: 267.0740 - val_mae: 13.4887\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 372.8860 - mae: 15.6440 - val_loss: 288.8727 - val_mae: 14.7847\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 382.5294 - mae: 16.1699 - val_loss: 264.6783 - val_mae: 13.2663\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.8593 - mae: 15.5516 - val_loss: 267.7741 - val_mae: 13.5639\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 374.8382 - mae: 15.7522 - val_loss: 265.7957 - val_mae: 13.3136\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 372.6736 - mae: 15.5891 - val_loss: 265.7773 - val_mae: 13.4249\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.9245 - mae: 15.5363 - val_loss: 264.1688 - val_mae: 13.2756\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.7026 - mae: 15.4542 - val_loss: 265.8213 - val_mae: 13.4363\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.8461 - mae: 15.5170 - val_loss: 272.4136 - val_mae: 13.8917\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.9431 - mae: 15.5706 - val_loss: 264.4893 - val_mae: 13.3423\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 371.7008 - mae: 15.5672 - val_loss: 267.3811 - val_mae: 13.4441\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.1506 - mae: 15.4412 - val_loss: 267.4724 - val_mae: 13.5822\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.4299 - mae: 15.4252 - val_loss: 262.3090 - val_mae: 13.1655\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.4418 - mae: 15.4208 - val_loss: 269.5233 - val_mae: 13.7021\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.6728 - mae: 15.4357 - val_loss: 268.6446 - val_mae: 13.6774\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.5935 - mae: 15.5070 - val_loss: 261.7460 - val_mae: 13.0738\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 376.7642 - mae: 15.8137 - val_loss: 262.4328 - val_mae: 13.2065\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.1562 - mae: 15.4194 - val_loss: 267.5340 - val_mae: 13.5926\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.0649 - mae: 15.3963 - val_loss: 248.2646 - val_mae: 12.6273\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 350.0991 - mae: 14.8953 - val_loss: 246.3192 - val_mae: 12.5046\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 348.8723 - mae: 14.7338 - val_loss: 253.5656 - val_mae: 13.1739\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 350.9996 - mae: 14.9160 - val_loss: 247.2972 - val_mae: 12.7210\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 345.5736 - mae: 14.6963 - val_loss: 247.6525 - val_mae: 12.7572\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 346.8065 - mae: 14.7850 - val_loss: 244.8105 - val_mae: 12.4610\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 347.0101 - mae: 14.7765 - val_loss: 244.0344 - val_mae: 12.4052\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 345.7638 - mae: 14.7312 - val_loss: 242.3202 - val_mae: 12.2735\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 332.9733 - mae: 14.3834 - val_loss: 233.9790 - val_mae: 12.1238\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 329.6222 - mae: 14.2456 - val_loss: 229.9931 - val_mae: 12.0490\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 325.5923 - mae: 14.2100 - val_loss: 227.7238 - val_mae: 11.8561\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 323.9323 - mae: 14.0546 - val_loss: 226.6443 - val_mae: 11.8112\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 315.3724 - mae: 13.7902 - val_loss: 211.9220 - val_mae: 11.2335\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.3399 - mae: 13.4361 - val_loss: 209.6699 - val_mae: 11.0583\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.8879 - mae: 13.3155 - val_loss: 209.3424 - val_mae: 11.0745\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.7137 - mae: 13.3509 - val_loss: 210.5253 - val_mae: 11.1891\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.0585 - mae: 13.3560 - val_loss: 208.7336 - val_mae: 10.9113\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.7122 - mae: 13.3572 - val_loss: 209.1596 - val_mae: 10.9322\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.7415 - mae: 13.2386 - val_loss: 216.0789 - val_mae: 11.6470\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.1924 - mae: 13.3645 - val_loss: 245.0963 - val_mae: 13.1061\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.3466 - mae: 13.6535 - val_loss: 207.9169 - val_mae: 10.8734\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.3317 - mae: 13.2906 - val_loss: 212.6292 - val_mae: 11.3552\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.1872 - mae: 13.6053 - val_loss: 209.7393 - val_mae: 11.1452\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.0946 - mae: 13.4081 - val_loss: 212.8212 - val_mae: 11.3747\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.0057 - mae: 13.3858 - val_loss: 210.0667 - val_mae: 10.9480\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.3081 - mae: 13.4528 - val_loss: 218.4584 - val_mae: 11.7983\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.5402 - mae: 13.4003 - val_loss: 207.3540 - val_mae: 10.8762\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 301.5182 - mae: 13.2286 - val_loss: 210.2804 - val_mae: 11.1692\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.9613 - mae: 13.3794 - val_loss: 218.3752 - val_mae: 11.8526\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.8441 - mae: 13.4789 - val_loss: 214.6111 - val_mae: 11.3156\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 302.0126 - mae: 13.2833 - val_loss: 209.0115 - val_mae: 11.0500\n",
      "Epoch 60: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=nesterov; total time=   1.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 783.5969 - mae: 21.7374 - val_loss: 308.0153 - val_mae: 15.4588\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 436.7941 - mae: 17.5251 - val_loss: 276.3332 - val_mae: 14.2885\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 418.9136 - mae: 17.0520 - val_loss: 276.1899 - val_mae: 14.2970\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 394.7440 - mae: 16.4173 - val_loss: 263.2179 - val_mae: 13.6849\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 403.8884 - mae: 16.7184 - val_loss: 261.6662 - val_mae: 13.7279\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 376.6028 - mae: 15.7330 - val_loss: 227.2279 - val_mae: 12.2280\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 355.5518 - mae: 15.0705 - val_loss: 232.1208 - val_mae: 12.3689\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 359.4231 - mae: 15.1447 - val_loss: 236.8698 - val_mae: 12.6007\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 350.3960 - mae: 14.8389 - val_loss: 241.6511 - val_mae: 12.8228\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 348.3698 - mae: 14.8400 - val_loss: 250.3230 - val_mae: 13.2248\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 347.1050 - mae: 14.8213 - val_loss: 221.0178 - val_mae: 11.7557\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 342.3026 - mae: 14.5656 - val_loss: 240.9784 - val_mae: 12.8325\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 343.9562 - mae: 14.6781 - val_loss: 234.1937 - val_mae: 12.5320\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 343.2427 - mae: 14.6506 - val_loss: 220.0977 - val_mae: 11.7441\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 338.1002 - mae: 14.4139 - val_loss: 219.2443 - val_mae: 11.7573\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 325.5865 - mae: 14.0702 - val_loss: 199.8938 - val_mae: 10.9264\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 316.1790 - mae: 13.6947 - val_loss: 208.4549 - val_mae: 11.5118\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 320.3274 - mae: 13.9349 - val_loss: 204.1479 - val_mae: 11.2132\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 315.9039 - mae: 13.7333 - val_loss: 210.2460 - val_mae: 11.5906\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 315.1199 - mae: 13.6990 - val_loss: 204.1090 - val_mae: 11.2456\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 312.2344 - mae: 13.6642 - val_loss: 197.3642 - val_mae: 10.8099\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 313.2445 - mae: 13.5581 - val_loss: 201.5527 - val_mae: 11.0524\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 312.3233 - mae: 13.5440 - val_loss: 203.9314 - val_mae: 11.3024\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.4904 - mae: 13.5385 - val_loss: 199.7746 - val_mae: 10.9974\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 311.2249 - mae: 13.5458 - val_loss: 200.6476 - val_mae: 11.0765\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 313.6399 - mae: 13.6054 - val_loss: 204.2564 - val_mae: 11.3273\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.8597 - mae: 13.5646 - val_loss: 195.7306 - val_mae: 10.6286\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 316.0560 - mae: 13.6632 - val_loss: 196.8909 - val_mae: 10.7659\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 313.7185 - mae: 13.6029 - val_loss: 195.9327 - val_mae: 10.7211\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.6561 - mae: 13.4604 - val_loss: 196.2280 - val_mae: 10.7534\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.7261 - mae: 13.5423 - val_loss: 196.5081 - val_mae: 10.6495\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 314.9426 - mae: 13.4195 - val_loss: 215.1066 - val_mae: 12.0500\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 311.5135 - mae: 13.5772 - val_loss: 200.1487 - val_mae: 11.0837\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.6606 - mae: 13.3766 - val_loss: 203.0122 - val_mae: 11.2898\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.6461 - mae: 13.3966 - val_loss: 199.5834 - val_mae: 11.0181\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.9468 - mae: 13.4156 - val_loss: 196.5137 - val_mae: 10.7759\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.2215 - mae: 13.4498 - val_loss: 192.6955 - val_mae: 10.4317\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 309.6738 - mae: 13.4062 - val_loss: 192.4299 - val_mae: 10.3561\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.7629 - mae: 13.3650 - val_loss: 193.9057 - val_mae: 10.5451\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.7438 - mae: 13.2867 - val_loss: 200.6736 - val_mae: 11.1016\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 308.9458 - mae: 13.4172 - val_loss: 192.8087 - val_mae: 10.4121\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.3538 - mae: 13.3544 - val_loss: 192.0934 - val_mae: 10.3526\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.3897 - mae: 13.3010 - val_loss: 193.1195 - val_mae: 10.4440\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.7761 - mae: 13.2555 - val_loss: 195.0879 - val_mae: 10.6327\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.4655 - mae: 13.3679 - val_loss: 191.7436 - val_mae: 10.3001\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.4250 - mae: 13.2949 - val_loss: 191.2308 - val_mae: 10.2305\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.1262 - mae: 13.2504 - val_loss: 193.5166 - val_mae: 10.4538\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.1047 - mae: 13.2570 - val_loss: 196.5604 - val_mae: 10.7558\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.8234 - mae: 13.1466 - val_loss: 221.3057 - val_mae: 12.4428\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.7154 - mae: 13.5652 - val_loss: 191.4824 - val_mae: 10.2905\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.9880 - mae: 13.2898 - val_loss: 195.9542 - val_mae: 10.7158\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.7967 - mae: 13.4723 - val_loss: 194.1710 - val_mae: 10.5531\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.5569 - mae: 13.1826 - val_loss: 195.2101 - val_mae: 10.6614\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.2162 - mae: 13.2652 - val_loss: 192.0628 - val_mae: 10.3438\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.5412 - mae: 13.1318 - val_loss: 203.9125 - val_mae: 11.3455\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 308.6447 - mae: 13.3677 - val_loss: 195.0863 - val_mae: 10.6535\n",
      "Epoch 56: early stopping\n",
      "5/5 [==============================] - 0s 758us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=nesterov; total time=   1.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 806.5750 - mae: 21.8753 - val_loss: 444.6669 - val_mae: 18.7880\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.3222 - mae: 16.0967 - val_loss: 333.3586 - val_mae: 15.1064\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 339.9378 - mae: 15.1381 - val_loss: 353.6697 - val_mae: 15.9293\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 355.0543 - mae: 15.7762 - val_loss: 326.8773 - val_mae: 14.9041\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 327.1796 - mae: 14.5569 - val_loss: 310.5671 - val_mae: 14.1449\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 324.2418 - mae: 14.6112 - val_loss: 300.0792 - val_mae: 13.8457\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.4791 - mae: 13.8900 - val_loss: 312.8606 - val_mae: 14.4989\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.1333 - mae: 13.8498 - val_loss: 292.8705 - val_mae: 13.5212\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 299.6078 - mae: 13.5600 - val_loss: 283.6130 - val_mae: 13.2880\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.6639 - mae: 13.2653 - val_loss: 279.3011 - val_mae: 13.1250\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.1025 - mae: 13.2504 - val_loss: 276.8481 - val_mae: 13.0168\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 288.6380 - mae: 13.1823 - val_loss: 303.8430 - val_mae: 14.3245\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 293.4109 - mae: 13.4506 - val_loss: 273.8604 - val_mae: 12.9144\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 285.5500 - mae: 13.0720 - val_loss: 274.4985 - val_mae: 12.9674\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 285.8155 - mae: 13.1480 - val_loss: 273.5336 - val_mae: 12.8725\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 282.7564 - mae: 12.9075 - val_loss: 273.1065 - val_mae: 12.9271\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 283.2332 - mae: 13.0299 - val_loss: 271.4879 - val_mae: 12.7376\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.5078 - mae: 12.8911 - val_loss: 270.1303 - val_mae: 12.7032\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 280.9119 - mae: 12.8943 - val_loss: 270.3443 - val_mae: 12.7030\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 280.4756 - mae: 12.8230 - val_loss: 269.4726 - val_mae: 12.6762\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 280.8362 - mae: 12.8646 - val_loss: 269.3248 - val_mae: 12.6727\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.4479 - mae: 12.7533 - val_loss: 269.1552 - val_mae: 12.6714\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.7592 - mae: 12.8232 - val_loss: 273.6028 - val_mae: 12.9192\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 280.6520 - mae: 12.7669 - val_loss: 276.9232 - val_mae: 13.1269\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.6269 - mae: 12.9212 - val_loss: 268.4422 - val_mae: 12.6238\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.1754 - mae: 12.6979 - val_loss: 274.6479 - val_mae: 13.0238\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.4428 - mae: 12.8585 - val_loss: 268.3359 - val_mae: 12.6015\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.0488 - mae: 12.7605 - val_loss: 268.4636 - val_mae: 12.6535\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.1918 - mae: 12.6479 - val_loss: 268.2661 - val_mae: 12.5920\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 277.5078 - mae: 12.6391 - val_loss: 272.4648 - val_mae: 12.8972\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.7751 - mae: 12.6967 - val_loss: 267.8666 - val_mae: 12.5638\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.1718 - mae: 12.6241 - val_loss: 270.8360 - val_mae: 12.8062\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.1032 - mae: 12.7946 - val_loss: 271.7079 - val_mae: 12.8060\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.4026 - mae: 12.6873 - val_loss: 268.6319 - val_mae: 12.6496\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.2902 - mae: 12.5814 - val_loss: 267.3562 - val_mae: 12.5570\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.6876 - mae: 12.6245 - val_loss: 274.0454 - val_mae: 12.9479\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.6120 - mae: 12.7573 - val_loss: 273.4140 - val_mae: 12.9111\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.0061 - mae: 12.7367 - val_loss: 268.0269 - val_mae: 12.5644\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.3404 - mae: 12.5850 - val_loss: 267.6796 - val_mae: 12.6236\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.4870 - mae: 12.5782 - val_loss: 267.0025 - val_mae: 12.5185\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.4158 - mae: 12.6085 - val_loss: 267.0219 - val_mae: 12.5183\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.9142 - mae: 12.4260 - val_loss: 301.5413 - val_mae: 14.4078\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 284.0751 - mae: 13.0078 - val_loss: 267.8091 - val_mae: 12.5543\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.5085 - mae: 12.5779 - val_loss: 268.0473 - val_mae: 12.5569\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.0989 - mae: 12.5620 - val_loss: 268.5047 - val_mae: 12.6373\n",
      "Epoch 45: early stopping\n",
      "5/5 [==============================] - 0s 746us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=nesterov; total time=   1.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 497.8363 - mae: 19.3998 - val_loss: 435.9034 - val_mae: 19.8278\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 489.5630 - mae: 19.6491 - val_loss: 305.0118 - val_mae: 15.0955\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 492.0432 - mae: 19.4358 - val_loss: 393.9043 - val_mae: 18.4125\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.6038 - mae: 21.0821 - val_loss: 461.0023 - val_mae: 19.2683\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 516.9570 - mae: 20.1263 - val_loss: 373.8252 - val_mae: 18.1218\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 455.5799 - mae: 18.6778 - val_loss: 269.2516 - val_mae: 13.6470\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 449.1726 - mae: 18.2183 - val_loss: 448.1719 - val_mae: 20.2200\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.8066 - mae: 22.1260 - val_loss: 448.7821 - val_mae: 20.2625\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.9902 - mae: 22.6834 - val_loss: 448.0760 - val_mae: 20.2287\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 585.6612 - mae: 22.2950 - val_loss: 377.6496 - val_mae: 17.8895\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 479.0501 - mae: 19.2593 - val_loss: 349.2558 - val_mae: 17.5045\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 511.1614 - mae: 20.0615 - val_loss: 448.5517 - val_mae: 20.2592\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.7595 - mae: 22.6820 - val_loss: 448.3122 - val_mae: 20.2532\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.4684 - mae: 22.6749 - val_loss: 448.0231 - val_mae: 20.2438\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.1633 - mae: 22.6668 - val_loss: 447.6698 - val_mae: 20.2293\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.7356 - mae: 22.6530 - val_loss: 446.0647 - val_mae: 20.1573\n",
      "Epoch 16: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.5, model__n_hidden=3, model__n_neurons=125, model__optimizer=momentum; total time=   0.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 490.3911 - mae: 18.6259 - val_loss: 270.4165 - val_mae: 14.2580\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 472.3135 - mae: 18.6052 - val_loss: 354.5110 - val_mae: 16.1457\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 513.1252 - mae: 19.3970 - val_loss: 437.1565 - val_mae: 17.6837\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 499.5584 - mae: 19.3734 - val_loss: 329.2101 - val_mae: 15.9093\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.7406 - mae: 20.1441 - val_loss: 444.7582 - val_mae: 20.0519\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.1704 - mae: 22.0476 - val_loss: 308.5001 - val_mae: 15.5951\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 585.7000 - mae: 21.7579 - val_loss: 364.3414 - val_mae: 17.2363\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.5178 - mae: 20.9836 - val_loss: 448.8677 - val_mae: 20.2671\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.5561 - mae: 22.8332 - val_loss: 491.1830 - val_mae: 20.0972\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.2264 - mae: 21.9111 - val_loss: 355.2495 - val_mae: 17.1369\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 491.8512 - mae: 19.2050 - val_loss: 331.5473 - val_mae: 16.8343\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 755us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.5, model__n_hidden=3, model__n_neurons=125, model__optimizer=momentum; total time=   0.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 418.7078 - mae: 17.1958 - val_loss: 431.6854 - val_mae: 18.9805\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 383.2781 - mae: 16.8932 - val_loss: 568.4418 - val_mae: 20.4109\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 514.9840 - mae: 19.7040 - val_loss: 372.4324 - val_mae: 16.5248\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 465.4317 - mae: 18.5936 - val_loss: 503.4276 - val_mae: 20.5923\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 435.2454 - mae: 18.2213 - val_loss: 360.0941 - val_mae: 15.8951\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 429.7738 - mae: 18.1471 - val_loss: 541.7452 - val_mae: 21.6089\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 456.8711 - mae: 18.9610 - val_loss: 438.5885 - val_mae: 18.3319\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 470.0866 - mae: 19.3620 - val_loss: 547.9296 - val_mae: 21.8217\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 498.5853 - mae: 20.1255 - val_loss: 421.7367 - val_mae: 17.7664\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 441.7365 - mae: 18.4450 - val_loss: 447.1348 - val_mae: 19.0782\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 407.2443 - mae: 17.2674 - val_loss: 369.2480 - val_mae: 16.0314\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 359.9722 - mae: 15.6927 - val_loss: 542.8911 - val_mae: 21.7302\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.6075 - mae: 21.7381 - val_loss: 544.9308 - val_mae: 21.7117\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 496.5986 - mae: 20.1221 - val_loss: 433.3906 - val_mae: 18.2783\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.3371 - mae: 17.3995 - val_loss: 392.1330 - val_mae: 16.7627\n",
      "Epoch 15: early stopping\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.5, model__n_hidden=3, model__n_neurons=125, model__optimizer=momentum; total time=   0.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 6373.6309 - mae: 42.6110 - val_loss: 329.2420 - val_mae: 16.3609\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 445.4454 - mae: 18.2191 - val_loss: 328.7633 - val_mae: 16.4971\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 442.6440 - mae: 18.1816 - val_loss: 325.6115 - val_mae: 16.3963\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 441.7409 - mae: 18.1513 - val_loss: 331.3040 - val_mae: 16.5100\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 439.8769 - mae: 18.1264 - val_loss: 327.6602 - val_mae: 16.4275\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 439.5580 - mae: 18.1189 - val_loss: 326.0516 - val_mae: 16.3696\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 438.4673 - mae: 18.0807 - val_loss: 326.2308 - val_mae: 16.4094\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 438.7803 - mae: 18.0885 - val_loss: 326.1715 - val_mae: 16.3527\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 436.5001 - mae: 18.0141 - val_loss: 328.4991 - val_mae: 16.3972\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 435.3987 - mae: 17.9712 - val_loss: 323.7637 - val_mae: 16.2633\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 435.4532 - mae: 17.9704 - val_loss: 328.4396 - val_mae: 16.3913\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 434.9001 - mae: 17.9599 - val_loss: 322.8037 - val_mae: 16.2615\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 434.2074 - mae: 17.9212 - val_loss: 325.4421 - val_mae: 16.2781\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 434.9719 - mae: 17.9286 - val_loss: 323.9180 - val_mae: 16.2588\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 432.5287 - mae: 17.8727 - val_loss: 319.4348 - val_mae: 16.1628\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 432.4155 - mae: 17.8627 - val_loss: 319.8832 - val_mae: 16.1524\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 432.3342 - mae: 17.8690 - val_loss: 321.0954 - val_mae: 16.1863\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 430.8557 - mae: 17.7921 - val_loss: 325.1298 - val_mae: 16.2338\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 431.2677 - mae: 17.8096 - val_loss: 322.1585 - val_mae: 16.1693\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 430.1268 - mae: 17.7627 - val_loss: 322.4148 - val_mae: 16.1575\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 429.6391 - mae: 17.7622 - val_loss: 318.7420 - val_mae: 16.0703\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 429.7408 - mae: 17.7404 - val_loss: 318.4236 - val_mae: 16.0384\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 427.7638 - mae: 17.6955 - val_loss: 323.4063 - val_mae: 16.1112\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 427.9797 - mae: 17.6763 - val_loss: 321.9812 - val_mae: 16.1232\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 428.1918 - mae: 17.7025 - val_loss: 318.5288 - val_mae: 16.0111\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 426.4058 - mae: 17.6380 - val_loss: 317.6609 - val_mae: 15.9814\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 426.3490 - mae: 17.6273 - val_loss: 319.9590 - val_mae: 16.0371\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 427.1361 - mae: 17.6487 - val_loss: 317.0907 - val_mae: 15.9607\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 425.8671 - mae: 17.6280 - val_loss: 319.7355 - val_mae: 16.0184\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 425.6390 - mae: 17.6009 - val_loss: 314.2849 - val_mae: 15.8754\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 424.8029 - mae: 17.5434 - val_loss: 314.0125 - val_mae: 15.8693\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 424.8794 - mae: 17.5763 - val_loss: 318.0154 - val_mae: 15.9463\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 424.4301 - mae: 17.5404 - val_loss: 320.3037 - val_mae: 15.9900\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 423.6109 - mae: 17.5104 - val_loss: 322.0320 - val_mae: 15.9648\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 424.0124 - mae: 17.5119 - val_loss: 317.6741 - val_mae: 15.8933\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 422.2719 - mae: 17.4576 - val_loss: 309.2853 - val_mae: 15.7347\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 422.0364 - mae: 17.4378 - val_loss: 311.4189 - val_mae: 15.7678\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 421.6820 - mae: 17.4543 - val_loss: 310.8298 - val_mae: 15.7691\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 421.7802 - mae: 17.4159 - val_loss: 316.7094 - val_mae: 15.8367\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 421.3951 - mae: 17.4084 - val_loss: 317.6920 - val_mae: 15.8560\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 420.8038 - mae: 17.4161 - val_loss: 310.5993 - val_mae: 15.7124\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 420.0361 - mae: 17.3840 - val_loss: 309.2442 - val_mae: 15.6753\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 419.6461 - mae: 17.3635 - val_loss: 308.5992 - val_mae: 15.6678\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 419.7816 - mae: 17.3785 - val_loss: 311.5130 - val_mae: 15.6948\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 419.4162 - mae: 17.3581 - val_loss: 308.5893 - val_mae: 15.6499\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 419.0356 - mae: 17.3534 - val_loss: 308.0871 - val_mae: 15.6047\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 419.5945 - mae: 17.3625 - val_loss: 309.6423 - val_mae: 15.6246\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 418.2536 - mae: 17.3165 - val_loss: 311.2451 - val_mae: 15.6516\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 418.0731 - mae: 17.2914 - val_loss: 310.6759 - val_mae: 15.6354\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 417.6024 - mae: 17.2876 - val_loss: 309.5846 - val_mae: 15.6031\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 417.0504 - mae: 17.2447 - val_loss: 308.9489 - val_mae: 15.5736\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 417.3593 - mae: 17.2528 - val_loss: 308.7109 - val_mae: 15.5603\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 417.0058 - mae: 17.2454 - val_loss: 307.8178 - val_mae: 15.5391\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.9488 - mae: 17.2146 - val_loss: 305.0576 - val_mae: 15.5134\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 416.0604 - mae: 17.2197 - val_loss: 306.4814 - val_mae: 15.4956\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.7582 - mae: 17.2115 - val_loss: 305.2902 - val_mae: 15.4672\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.9457 - mae: 17.2073 - val_loss: 304.9059 - val_mae: 15.4516\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.2050 - mae: 17.1747 - val_loss: 309.4105 - val_mae: 15.5208\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.5728 - mae: 17.2085 - val_loss: 303.5373 - val_mae: 15.4183\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 414.6947 - mae: 17.1639 - val_loss: 305.4306 - val_mae: 15.4298\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 415.7995 - mae: 17.1899 - val_loss: 304.7020 - val_mae: 15.4077\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.5668 - mae: 17.1174 - val_loss: 305.0044 - val_mae: 15.4291\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 414.4515 - mae: 17.1282 - val_loss: 302.2839 - val_mae: 15.3475\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.5983 - mae: 17.0961 - val_loss: 304.3845 - val_mae: 15.3732\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.7306 - mae: 17.1014 - val_loss: 301.7732 - val_mae: 15.3352\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.6767 - mae: 17.1001 - val_loss: 301.6925 - val_mae: 15.3122\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.4751 - mae: 17.1008 - val_loss: 302.5869 - val_mae: 15.3118\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.5733 - mae: 17.0727 - val_loss: 305.5133 - val_mae: 15.3538\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.3639 - mae: 17.0495 - val_loss: 301.5795 - val_mae: 15.2745\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 411.7573 - mae: 17.0282 - val_loss: 301.8474 - val_mae: 15.2672\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 411.5776 - mae: 17.0214 - val_loss: 300.0800 - val_mae: 15.2848\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 413.4702 - mae: 17.0747 - val_loss: 305.7484 - val_mae: 15.3129\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 411.5392 - mae: 17.0339 - val_loss: 302.8387 - val_mae: 15.3121\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 412.3230 - mae: 17.0668 - val_loss: 302.7623 - val_mae: 15.2345\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 411.9655 - mae: 17.0300 - val_loss: 300.6653 - val_mae: 15.2029\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 411.8332 - mae: 17.0211 - val_loss: 299.6461 - val_mae: 15.1919\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 410.8336 - mae: 16.9956 - val_loss: 300.4828 - val_mae: 15.1650\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 410.2415 - mae: 16.9658 - val_loss: 298.7760 - val_mae: 15.1426\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 409.5040 - mae: 16.9331 - val_loss: 299.3933 - val_mae: 15.1491\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 410.3538 - mae: 16.9612 - val_loss: 300.0359 - val_mae: 15.1354\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 409.9340 - mae: 16.9408 - val_loss: 297.2821 - val_mae: 15.1199\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 409.7194 - mae: 16.9011 - val_loss: 299.6977 - val_mae: 15.1213\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 408.8451 - mae: 16.9107 - val_loss: 300.1302 - val_mae: 15.1260\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 408.6516 - mae: 16.9028 - val_loss: 299.8434 - val_mae: 15.1116\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 409.3577 - mae: 16.9175 - val_loss: 300.9213 - val_mae: 15.1188\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 408.5949 - mae: 16.8925 - val_loss: 299.9943 - val_mae: 15.0764\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 407.7611 - mae: 16.8673 - val_loss: 297.0297 - val_mae: 15.0479\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 407.9546 - mae: 16.8626 - val_loss: 300.7173 - val_mae: 15.0783\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 408.8117 - mae: 16.9064 - val_loss: 299.1202 - val_mae: 15.0428\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 407.1056 - mae: 16.8459 - val_loss: 296.5540 - val_mae: 15.0036\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 407.3076 - mae: 16.8121 - val_loss: 298.8529 - val_mae: 15.0129\n",
      "Epoch 91: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=sgd; total time=   2.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 5738.4897 - mae: 40.7883 - val_loss: 458.7435 - val_mae: 20.3670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 638.6160 - mae: 23.0477 - val_loss: 454.1078 - val_mae: 20.3787\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3035 - mae: 23.0451 - val_loss: 453.0946 - val_mae: 20.2753\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.7882 - mae: 22.9668 - val_loss: 451.2947 - val_mae: 20.2274\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.5255 - mae: 22.9333 - val_loss: 449.1109 - val_mae: 20.2453\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.2410 - mae: 22.9095 - val_loss: 446.7184 - val_mae: 20.1139\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.9819 - mae: 22.7966 - val_loss: 442.7808 - val_mae: 19.9423\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.3396 - mae: 22.4762 - val_loss: 422.2193 - val_mae: 19.2853\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.3774 - mae: 21.6563 - val_loss: 409.3305 - val_mae: 18.5864\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.2073 - mae: 21.1508 - val_loss: 385.9709 - val_mae: 18.1255\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.6390 - mae: 20.7157 - val_loss: 381.7531 - val_mae: 17.8080\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.7605 - mae: 20.4472 - val_loss: 375.4249 - val_mae: 17.5578\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.0335 - mae: 20.2661 - val_loss: 375.3869 - val_mae: 17.5193\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.9396 - mae: 20.2136 - val_loss: 367.6653 - val_mae: 17.2177\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.8140 - mae: 20.0387 - val_loss: 368.9633 - val_mae: 17.2509\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.4572 - mae: 20.0025 - val_loss: 366.0072 - val_mae: 17.1109\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.3974 - mae: 20.0084 - val_loss: 369.4239 - val_mae: 17.3430\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.6735 - mae: 20.0190 - val_loss: 370.5017 - val_mae: 17.4203\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.9553 - mae: 20.0158 - val_loss: 367.3268 - val_mae: 17.2177\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.7925 - mae: 20.0236 - val_loss: 366.4323 - val_mae: 17.1461\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.5090 - mae: 19.9943 - val_loss: 366.4438 - val_mae: 17.1534\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.1690 - mae: 19.9976 - val_loss: 364.6324 - val_mae: 16.9923\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.5846 - mae: 19.9678 - val_loss: 367.1396 - val_mae: 17.2032\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.3398 - mae: 19.9679 - val_loss: 365.0241 - val_mae: 17.0518\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.4539 - mae: 19.9580 - val_loss: 366.0471 - val_mae: 17.1131\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.9465 - mae: 19.9971 - val_loss: 368.5597 - val_mae: 17.3171\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.6458 - mae: 19.9729 - val_loss: 365.2488 - val_mae: 17.0482\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.1343 - mae: 20.0457 - val_loss: 364.5789 - val_mae: 17.0270\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.4284 - mae: 19.9455 - val_loss: 364.6938 - val_mae: 17.0197\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.0930 - mae: 19.9177 - val_loss: 366.7463 - val_mae: 17.1858\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.1811 - mae: 19.9923 - val_loss: 365.4688 - val_mae: 17.0643\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.5253 - mae: 19.9692 - val_loss: 369.7459 - val_mae: 17.3935\n",
      "Epoch 32: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=sgd; total time=   0.9s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 1882.7096 - mae: 27.3445 - val_loss: 443.3583 - val_mae: 18.9103\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 441.4131 - mae: 18.7491 - val_loss: 368.6096 - val_mae: 16.2988\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 380.4117 - mae: 16.4834 - val_loss: 364.2814 - val_mae: 15.9524\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 375.0317 - mae: 16.1873 - val_loss: 361.8725 - val_mae: 15.8687\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 372.8387 - mae: 16.0864 - val_loss: 359.4452 - val_mae: 15.8032\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 371.7007 - mae: 16.0289 - val_loss: 358.2808 - val_mae: 15.7651\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.9937 - mae: 16.0091 - val_loss: 357.4064 - val_mae: 15.7384\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.2864 - mae: 15.9961 - val_loss: 356.2389 - val_mae: 15.6926\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 369.4610 - mae: 15.9487 - val_loss: 355.8145 - val_mae: 15.6720\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.8811 - mae: 15.9447 - val_loss: 355.0217 - val_mae: 15.6386\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 368.4075 - mae: 15.9302 - val_loss: 354.1617 - val_mae: 15.5933\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.8874 - mae: 15.9106 - val_loss: 353.4859 - val_mae: 15.5603\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 367.4603 - mae: 15.8783 - val_loss: 352.9008 - val_mae: 15.5350\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.9581 - mae: 15.8564 - val_loss: 352.3596 - val_mae: 15.5101\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.5995 - mae: 15.8622 - val_loss: 351.9043 - val_mae: 15.4860\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 366.2380 - mae: 15.8328 - val_loss: 351.4953 - val_mae: 15.4740\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.7486 - mae: 15.8426 - val_loss: 350.8982 - val_mae: 15.4171\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 365.4019 - mae: 15.8076 - val_loss: 350.3310 - val_mae: 15.3848\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 364.9489 - mae: 15.7655 - val_loss: 349.7919 - val_mae: 15.3512\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 364.3793 - mae: 15.7594 - val_loss: 349.3252 - val_mae: 15.3154\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 364.0345 - mae: 15.7466 - val_loss: 348.8472 - val_mae: 15.2686\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 363.5829 - mae: 15.7058 - val_loss: 348.4092 - val_mae: 15.2606\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 363.3076 - mae: 15.6884 - val_loss: 348.0511 - val_mae: 15.2470\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 362.8262 - mae: 15.6669 - val_loss: 347.8088 - val_mae: 15.2329\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 362.5371 - mae: 15.6545 - val_loss: 347.5199 - val_mae: 15.2035\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 362.3294 - mae: 15.6156 - val_loss: 347.3393 - val_mae: 15.1924\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 362.1928 - mae: 15.6432 - val_loss: 347.0918 - val_mae: 15.1723\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.9414 - mae: 15.5983 - val_loss: 346.9420 - val_mae: 15.1641\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.6693 - mae: 15.5750 - val_loss: 346.8233 - val_mae: 15.1562\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.5486 - mae: 15.5704 - val_loss: 346.7000 - val_mae: 15.1466\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.3965 - mae: 15.5684 - val_loss: 346.6527 - val_mae: 15.1443\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.3586 - mae: 15.5353 - val_loss: 346.5681 - val_mae: 15.1369\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.2594 - mae: 15.5611 - val_loss: 346.5337 - val_mae: 15.1349\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.1823 - mae: 15.5381 - val_loss: 346.4667 - val_mae: 15.1291\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.0957 - mae: 15.5181 - val_loss: 346.4254 - val_mae: 15.1248\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 361.1140 - mae: 15.5326 - val_loss: 346.4133 - val_mae: 15.1253\n",
      "Epoch 36: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=2, model__n_neurons=5, model__optimizer=sgd; total time=   1.0s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=0, model__n_neurons=125, model__optimizer=nesterov; total time=   0.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 778us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=0, model__n_neurons=125, model__optimizer=nesterov; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.1, model__n_hidden=0, model__n_neurons=125, model__optimizer=nesterov; total time=   0.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 431.9498 - mae: 17.3151 - val_loss: 242.4628 - val_mae: 12.7998\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.5380 - mae: 13.8955 - val_loss: 182.5316 - val_mae: 10.8504\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 246.7039 - mae: 12.0321 - val_loss: 150.7372 - val_mae: 9.3325\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.9074 - mae: 11.1689 - val_loss: 152.6513 - val_mae: 9.5180\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.9750 - mae: 10.9610 - val_loss: 137.0541 - val_mae: 8.5689\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.4481 - mae: 10.9183 - val_loss: 137.5930 - val_mae: 8.6432\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 217.3300 - mae: 10.8243 - val_loss: 132.0083 - val_mae: 8.2836\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 217.1503 - mae: 10.9303 - val_loss: 131.8097 - val_mae: 8.7636\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 188.0264 - mae: 9.8688 - val_loss: 140.6497 - val_mae: 9.3188\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 194.3246 - mae: 10.2535 - val_loss: 119.6576 - val_mae: 7.9261\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 187.1031 - mae: 9.8968 - val_loss: 111.6061 - val_mae: 7.3232\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 186.3121 - mae: 9.7085 - val_loss: 112.5110 - val_mae: 7.4494\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 182.8878 - mae: 9.6379 - val_loss: 140.1507 - val_mae: 9.3576\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.9573 - mae: 10.4316 - val_loss: 109.4130 - val_mae: 7.1961\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 180.2787 - mae: 9.5632 - val_loss: 111.5819 - val_mae: 7.4680\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 184.6461 - mae: 9.7641 - val_loss: 112.3380 - val_mae: 7.3539\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 184.2416 - mae: 9.6303 - val_loss: 114.6357 - val_mae: 7.6822\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 181.7361 - mae: 9.5841 - val_loss: 108.8698 - val_mae: 7.2082\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 178.5025 - mae: 9.4235 - val_loss: 113.8967 - val_mae: 7.6719\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 180.8529 - mae: 9.5285 - val_loss: 124.4141 - val_mae: 8.4734\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 178.9963 - mae: 9.5608 - val_loss: 111.7940 - val_mae: 7.5181\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 182.7917 - mae: 9.6405 - val_loss: 117.2351 - val_mae: 7.7028\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 179.9878 - mae: 9.4285 - val_loss: 118.0805 - val_mae: 8.0090\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 178.3357 - mae: 9.4151 - val_loss: 111.1564 - val_mae: 7.4265\n",
      "Epoch 24: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=25, model__optimizer=sgd; total time=   0.8s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 494.2861 - mae: 18.5891 - val_loss: 263.1613 - val_mae: 13.9622\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 356.5914 - mae: 15.2208 - val_loss: 291.1579 - val_mae: 14.7229\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 323.3575 - mae: 14.1117 - val_loss: 187.7262 - val_mae: 11.0810\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 307.8228 - mae: 13.9402 - val_loss: 195.1059 - val_mae: 11.3857\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 294.4647 - mae: 13.4191 - val_loss: 172.8380 - val_mae: 9.8293\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.3580 - mae: 13.6998 - val_loss: 177.9374 - val_mae: 10.3681\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.3063 - mae: 13.0643 - val_loss: 162.7519 - val_mae: 9.4810\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.4744 - mae: 13.6190 - val_loss: 165.5402 - val_mae: 9.6078\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 265.1762 - mae: 12.2157 - val_loss: 192.4593 - val_mae: 11.2638\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.4485 - mae: 12.3603 - val_loss: 187.2353 - val_mae: 10.9787\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 270.5209 - mae: 12.5135 - val_loss: 159.4431 - val_mae: 9.2445\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 253.0716 - mae: 11.8106 - val_loss: 154.4268 - val_mae: 9.3260\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 242.4240 - mae: 11.5754 - val_loss: 156.7744 - val_mae: 9.4544\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.4056 - mae: 12.2796 - val_loss: 141.0991 - val_mae: 8.4863\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.4661 - mae: 11.3560 - val_loss: 147.7727 - val_mae: 8.8914\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.9489 - mae: 11.3358 - val_loss: 140.4546 - val_mae: 8.4599\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 239.9047 - mae: 11.3497 - val_loss: 161.2991 - val_mae: 9.8482\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 251.6096 - mae: 12.0176 - val_loss: 130.9476 - val_mae: 8.1926\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.4770 - mae: 10.8353 - val_loss: 135.5109 - val_mae: 8.5187\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 227.0011 - mae: 11.1892 - val_loss: 132.4512 - val_mae: 8.3075\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 215.1869 - mae: 10.7337 - val_loss: 127.5116 - val_mae: 8.0451\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.4158 - mae: 10.8271 - val_loss: 137.8061 - val_mae: 8.8216\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.5135 - mae: 10.6558 - val_loss: 131.1890 - val_mae: 8.3119\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 218.8072 - mae: 10.7193 - val_loss: 136.9308 - val_mae: 8.6816\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.3000 - mae: 10.7521 - val_loss: 126.1813 - val_mae: 7.9427\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.4101 - mae: 10.9354 - val_loss: 139.2973 - val_mae: 8.8269\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.6501 - mae: 10.6237 - val_loss: 128.6005 - val_mae: 8.0938\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 227.9168 - mae: 11.2114 - val_loss: 122.3531 - val_mae: 7.6368\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 215.4013 - mae: 10.6276 - val_loss: 121.3899 - val_mae: 7.5713\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 213.6754 - mae: 10.5488 - val_loss: 121.2295 - val_mae: 7.5020\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.5975 - mae: 10.7486 - val_loss: 133.2114 - val_mae: 8.4843\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 226.5092 - mae: 10.9001 - val_loss: 152.1087 - val_mae: 9.7968\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.0271 - mae: 10.5910 - val_loss: 130.6497 - val_mae: 8.3240\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.3922 - mae: 10.4118 - val_loss: 128.4869 - val_mae: 8.1499\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.6458 - mae: 10.4142 - val_loss: 120.8370 - val_mae: 7.4594\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 213.8786 - mae: 10.4823 - val_loss: 124.3434 - val_mae: 7.8179\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 213.8640 - mae: 10.5326 - val_loss: 119.3990 - val_mae: 7.2839\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 218.4041 - mae: 10.6401 - val_loss: 120.0804 - val_mae: 7.3239\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 210.5156 - mae: 10.4185 - val_loss: 121.4187 - val_mae: 7.4749\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.7575 - mae: 10.3345 - val_loss: 123.9602 - val_mae: 7.7253\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.1755 - mae: 10.5022 - val_loss: 119.9305 - val_mae: 7.3610\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.0969 - mae: 10.3446 - val_loss: 118.5980 - val_mae: 7.2429\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.9394 - mae: 10.3418 - val_loss: 120.2220 - val_mae: 7.4313\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.9077 - mae: 10.3026 - val_loss: 119.9546 - val_mae: 7.3924\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.3557 - mae: 10.4195 - val_loss: 121.6544 - val_mae: 7.5594\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 206.9810 - mae: 10.2100 - val_loss: 119.5892 - val_mae: 7.3218\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.2433 - mae: 10.3194 - val_loss: 129.8901 - val_mae: 8.2429\n",
      "Epoch 47: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=25, model__optimizer=sgd; total time=   1.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 731.1008 - mae: 21.3470 - val_loss: 372.0818 - val_mae: 16.2805\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 370.7259 - mae: 15.9488 - val_loss: 355.3678 - val_mae: 15.4670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 362.2433 - mae: 15.5233 - val_loss: 350.1335 - val_mae: 15.2277\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 357.0843 - mae: 15.2357 - val_loss: 347.9279 - val_mae: 15.1461\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 356.1516 - mae: 15.1621 - val_loss: 347.8816 - val_mae: 15.1273\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 356.7890 - mae: 15.2257 - val_loss: 347.0209 - val_mae: 15.1128\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 356.8914 - mae: 15.2552 - val_loss: 349.5725 - val_mae: 15.2979\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 357.4466 - mae: 15.2926 - val_loss: 347.1598 - val_mae: 15.1158\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.8664 - mae: 15.1386 - val_loss: 346.3528 - val_mae: 15.1011\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.7034 - mae: 15.1343 - val_loss: 346.4777 - val_mae: 15.1102\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.4812 - mae: 15.1247 - val_loss: 347.4083 - val_mae: 15.1424\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 355.3918 - mae: 15.1745 - val_loss: 356.3141 - val_mae: 15.7489\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 358.7828 - mae: 15.3346 - val_loss: 346.4586 - val_mae: 15.1091\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 355.2216 - mae: 15.1091 - val_loss: 346.2544 - val_mae: 15.0912\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.2944 - mae: 15.1043 - val_loss: 346.0790 - val_mae: 15.0808\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.1624 - mae: 15.0555 - val_loss: 348.7154 - val_mae: 15.2597\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.4036 - mae: 15.1646 - val_loss: 347.0412 - val_mae: 15.1355\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 354.3953 - mae: 15.1231 - val_loss: 345.6451 - val_mae: 15.0444\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 353.7754 - mae: 15.1236 - val_loss: 346.3184 - val_mae: 15.0821\n",
      "Epoch 19: early stopping\n",
      "5/5 [==============================] - 0s 755us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=25, model__optimizer=sgd; total time=   0.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 468.9185 - mae: 18.1590 - val_loss: 235.3420 - val_mae: 12.7792\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.7497 - mae: 14.1365 - val_loss: 190.1198 - val_mae: 10.7615\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.8991 - mae: 12.5454 - val_loss: 167.5343 - val_mae: 9.7255\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 241.9725 - mae: 11.4491 - val_loss: 159.6498 - val_mae: 9.5620\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 233.0988 - mae: 11.1222 - val_loss: 161.8307 - val_mae: 9.8138\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 226.8713 - mae: 10.9195 - val_loss: 146.3513 - val_mae: 8.5633\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.1540 - mae: 10.8439 - val_loss: 142.6474 - val_mae: 8.3291\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.0102 - mae: 10.7067 - val_loss: 144.5543 - val_mae: 8.7879\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.9511 - mae: 10.5316 - val_loss: 183.5670 - val_mae: 11.5813\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.2698 - mae: 10.9849 - val_loss: 158.9511 - val_mae: 10.0824\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.2569 - mae: 11.0663 - val_loss: 132.5274 - val_mae: 7.9944\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.4346 - mae: 10.7361 - val_loss: 129.7555 - val_mae: 7.7273\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 218.1336 - mae: 11.0646 - val_loss: 126.6731 - val_mae: 7.5446\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.1860 - mae: 10.0901 - val_loss: 127.9156 - val_mae: 7.6450\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 202.4677 - mae: 10.1161 - val_loss: 129.0426 - val_mae: 7.6339\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.5307 - mae: 10.4369 - val_loss: 139.3422 - val_mae: 8.5757\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.5473 - mae: 10.5621 - val_loss: 127.1373 - val_mae: 7.7017\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.8793 - mae: 10.0979 - val_loss: 125.1448 - val_mae: 7.5060\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.0698 - mae: 10.5133 - val_loss: 123.8110 - val_mae: 7.5073\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.2298 - mae: 9.8116 - val_loss: 132.7887 - val_mae: 8.6431\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 194.8906 - mae: 9.8357 - val_loss: 135.2088 - val_mae: 8.7908\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.3786 - mae: 10.1019 - val_loss: 130.0893 - val_mae: 8.3202\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.7190 - mae: 10.0458 - val_loss: 134.3962 - val_mae: 8.8450\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.6885 - mae: 9.7364 - val_loss: 125.7261 - val_mae: 8.0027\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.5557 - mae: 9.6331 - val_loss: 118.7001 - val_mae: 7.1953\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.5437 - mae: 9.6338 - val_loss: 119.6701 - val_mae: 7.3599\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.7167 - mae: 9.6659 - val_loss: 120.6031 - val_mae: 7.4981\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.2899 - mae: 9.5259 - val_loss: 122.2534 - val_mae: 7.7136\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 192.9640 - mae: 9.8331 - val_loss: 118.3006 - val_mae: 7.1410\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.9235 - mae: 9.5892 - val_loss: 118.2708 - val_mae: 7.1299\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.4537 - mae: 9.5897 - val_loss: 118.9679 - val_mae: 7.1105\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.7477 - mae: 9.5853 - val_loss: 129.8537 - val_mae: 8.4292\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 194.1127 - mae: 10.0474 - val_loss: 127.0211 - val_mae: 8.0838\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.3408 - mae: 9.8407 - val_loss: 151.0250 - val_mae: 10.0134\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.6730 - mae: 10.1175 - val_loss: 157.6207 - val_mae: 10.4053\n",
      "Epoch 35: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=125, model__optimizer=momentum; total time=   1.2s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 454.8996 - mae: 17.8323 - val_loss: 230.9673 - val_mae: 12.4998\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 325.5542 - mae: 14.3005 - val_loss: 193.4315 - val_mae: 10.9072\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 299.4922 - mae: 13.4626 - val_loss: 189.6399 - val_mae: 11.1473\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.4741 - mae: 12.5237 - val_loss: 185.7551 - val_mae: 11.2087\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.8230 - mae: 11.8299 - val_loss: 142.6105 - val_mae: 8.7850\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 232.8205 - mae: 10.9915 - val_loss: 132.8821 - val_mae: 8.0518\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.7805 - mae: 10.9183 - val_loss: 130.9427 - val_mae: 8.0964\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 227.9847 - mae: 10.8790 - val_loss: 125.6812 - val_mae: 7.8642\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.4420 - mae: 10.3436 - val_loss: 159.7886 - val_mae: 10.3903\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.9326 - mae: 10.1869 - val_loss: 135.2724 - val_mae: 9.1887\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.6914 - mae: 9.9776 - val_loss: 98.6018 - val_mae: 6.7951\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 179.8623 - mae: 9.5367 - val_loss: 89.0326 - val_mae: 6.2520\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 166.7986 - mae: 9.0224 - val_loss: 80.5576 - val_mae: 5.9225\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 158.9566 - mae: 8.7431 - val_loss: 94.6985 - val_mae: 7.1915\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 166.3539 - mae: 9.2695 - val_loss: 88.1188 - val_mae: 6.6685\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 165.3141 - mae: 9.0238 - val_loss: 73.5167 - val_mae: 5.5223\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 154.1918 - mae: 8.8171 - val_loss: 99.6122 - val_mae: 7.7362\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 150.2334 - mae: 8.6834 - val_loss: 89.6139 - val_mae: 7.0748\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 158.7766 - mae: 9.1853 - val_loss: 67.8026 - val_mae: 5.2440\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 147.4254 - mae: 8.4417 - val_loss: 66.5426 - val_mae: 5.1653\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 143.6643 - mae: 8.1859 - val_loss: 68.6968 - val_mae: 5.4434\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 148.0926 - mae: 8.3862 - val_loss: 93.0910 - val_mae: 7.5178\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 150.6128 - mae: 8.6925 - val_loss: 66.4308 - val_mae: 5.2035\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 154.3217 - mae: 8.6880 - val_loss: 68.1451 - val_mae: 5.2383\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 159.4727 - mae: 8.8766 - val_loss: 66.5773 - val_mae: 5.2327\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 149.2392 - mae: 8.4368 - val_loss: 86.2160 - val_mae: 6.9235\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 156.1371 - mae: 8.8357 - val_loss: 98.0606 - val_mae: 7.8229\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 153.5529 - mae: 8.6336 - val_loss: 68.1232 - val_mae: 5.3935\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 150.8981 - mae: 8.6160 - val_loss: 66.6935 - val_mae: 5.1799\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 151.8148 - mae: 8.6941 - val_loss: 66.6861 - val_mae: 5.1240\n",
      "Epoch 30: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=125, model__optimizer=momentum; total time=   1.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 379.6678 - mae: 16.3933 - val_loss: 301.1773 - val_mae: 14.1938\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.7711 - mae: 12.8515 - val_loss: 204.9610 - val_mae: 11.0091\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 205.9520 - mae: 10.9058 - val_loss: 173.6235 - val_mae: 9.7661\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 184.5396 - mae: 9.8871 - val_loss: 165.1326 - val_mae: 9.2882\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 173.1832 - mae: 9.3736 - val_loss: 152.5508 - val_mae: 8.8618\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 161.0645 - mae: 8.9162 - val_loss: 136.0009 - val_mae: 8.2226\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 164.0859 - mae: 9.2207 - val_loss: 146.3582 - val_mae: 8.8349\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 147.8098 - mae: 8.4374 - val_loss: 134.3944 - val_mae: 8.4607\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 139.0695 - mae: 8.1201 - val_loss: 121.9992 - val_mae: 7.7998\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 136.9178 - mae: 8.3237 - val_loss: 112.6031 - val_mae: 7.3443\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.0586 - mae: 7.7052 - val_loss: 122.3439 - val_mae: 8.2694\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.6062 - mae: 7.5381 - val_loss: 97.3146 - val_mae: 6.7706\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.3432 - mae: 7.0103 - val_loss: 99.2205 - val_mae: 7.1166\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.1542 - mae: 7.0035 - val_loss: 103.6176 - val_mae: 7.4750\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.0169 - mae: 7.1776 - val_loss: 128.0657 - val_mae: 8.8521\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.4381 - mae: 7.8889 - val_loss: 94.8483 - val_mae: 6.7222\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.5421 - mae: 7.8178 - val_loss: 96.2775 - val_mae: 6.7083\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.9090 - mae: 7.6323 - val_loss: 96.2239 - val_mae: 7.0532\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.2947 - mae: 7.0393 - val_loss: 102.4679 - val_mae: 7.2326\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.0521 - mae: 6.9739 - val_loss: 87.8557 - val_mae: 6.4315\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 106.4212 - mae: 7.0158 - val_loss: 88.7893 - val_mae: 6.5320\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.7666 - mae: 6.6859 - val_loss: 100.6828 - val_mae: 7.0901\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 122.7033 - mae: 7.8824 - val_loss: 88.6220 - val_mae: 6.3119\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.9167 - mae: 7.8986 - val_loss: 95.9551 - val_mae: 6.8329\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 110.7234 - mae: 7.1698 - val_loss: 88.3431 - val_mae: 6.5363\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 109.8787 - mae: 7.1658 - val_loss: 91.8631 - val_mae: 6.5184\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.3053 - mae: 7.3704 - val_loss: 92.8669 - val_mae: 6.4989\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 111.5373 - mae: 7.3081 - val_loss: 93.4753 - val_mae: 6.7804\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.3541 - mae: 6.7871 - val_loss: 92.3526 - val_mae: 6.5922\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.8530 - mae: 6.8478 - val_loss: 94.8771 - val_mae: 6.8658\n",
      "Epoch 30: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=125, model__optimizer=momentum; total time=   1.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 476.6396 - mae: 17.7177 - val_loss: 269.5671 - val_mae: 13.6821\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 350.9739 - mae: 15.1339 - val_loss: 246.6925 - val_mae: 12.8176\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 334.4999 - mae: 14.5677 - val_loss: 233.8459 - val_mae: 12.3237\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 321.9253 - mae: 14.1270 - val_loss: 226.7331 - val_mae: 12.1276\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.6828 - mae: 13.8000 - val_loss: 215.5172 - val_mae: 11.6259\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 303.9984 - mae: 13.5814 - val_loss: 209.4387 - val_mae: 11.3270\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 298.5814 - mae: 13.3660 - val_loss: 204.2186 - val_mae: 11.1263\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 295.1696 - mae: 13.2577 - val_loss: 207.0167 - val_mae: 11.3845\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 291.3628 - mae: 13.1165 - val_loss: 209.2716 - val_mae: 11.5698\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 289.8837 - mae: 13.1385 - val_loss: 201.6070 - val_mae: 11.1025\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 287.5788 - mae: 13.0339 - val_loss: 198.0655 - val_mae: 10.8657\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 286.7415 - mae: 12.9857 - val_loss: 196.6782 - val_mae: 10.7967\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 285.0728 - mae: 12.8802 - val_loss: 206.4238 - val_mae: 11.5264\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 286.6389 - mae: 13.0795 - val_loss: 194.1689 - val_mae: 10.6163\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 282.5548 - mae: 12.8356 - val_loss: 193.7338 - val_mae: 10.6262\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 282.3963 - mae: 12.8324 - val_loss: 191.8598 - val_mae: 10.5006\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.3852 - mae: 12.6830 - val_loss: 190.7619 - val_mae: 10.6224\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.1843 - mae: 12.6288 - val_loss: 188.5353 - val_mae: 10.4546\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.7596 - mae: 12.5101 - val_loss: 191.5414 - val_mae: 10.7550\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.2903 - mae: 12.5253 - val_loss: 192.7037 - val_mae: 10.9224\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.8029 - mae: 12.4890 - val_loss: 183.4030 - val_mae: 10.3547\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.3961 - mae: 12.3436 - val_loss: 179.9600 - val_mae: 10.0989\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 264.5097 - mae: 12.2102 - val_loss: 185.0613 - val_mae: 10.5869\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 264.3441 - mae: 12.2562 - val_loss: 180.2450 - val_mae: 10.2174\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.2732 - mae: 12.2196 - val_loss: 179.3854 - val_mae: 10.1362\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.5986 - mae: 12.1496 - val_loss: 182.9770 - val_mae: 10.4711\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.1853 - mae: 12.2334 - val_loss: 176.9796 - val_mae: 9.9241\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 264.3773 - mae: 12.2295 - val_loss: 176.6172 - val_mae: 9.9056\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.7004 - mae: 12.0900 - val_loss: 181.0276 - val_mae: 10.3352\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.1495 - mae: 12.1485 - val_loss: 175.7839 - val_mae: 9.8120\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 260.9700 - mae: 12.1068 - val_loss: 176.0989 - val_mae: 9.7680\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.3118 - mae: 11.9729 - val_loss: 181.6665 - val_mae: 10.4323\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.8973 - mae: 12.1135 - val_loss: 175.7388 - val_mae: 10.0776\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 253.8056 - mae: 11.8705 - val_loss: 174.9417 - val_mae: 10.0814\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 252.9804 - mae: 11.8460 - val_loss: 172.6101 - val_mae: 9.9345\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 252.7256 - mae: 11.8530 - val_loss: 169.7808 - val_mae: 9.6787\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 251.5533 - mae: 11.7963 - val_loss: 168.2900 - val_mae: 9.5380\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 252.3355 - mae: 11.7959 - val_loss: 168.9263 - val_mae: 9.5000\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 250.9798 - mae: 11.7086 - val_loss: 169.1443 - val_mae: 9.8199\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 247.5495 - mae: 11.6985 - val_loss: 167.8194 - val_mae: 9.8143\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 244.1965 - mae: 11.6355 - val_loss: 161.9363 - val_mae: 9.3155\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 242.1567 - mae: 11.4717 - val_loss: 161.2246 - val_mae: 9.3286\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 241.6119 - mae: 11.4624 - val_loss: 159.8970 - val_mae: 9.2362\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.2876 - mae: 11.4130 - val_loss: 159.9841 - val_mae: 9.2896\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 239.3777 - mae: 11.4716 - val_loss: 159.0741 - val_mae: 9.2131\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 239.2278 - mae: 11.4064 - val_loss: 158.0606 - val_mae: 9.0682\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.8819 - mae: 11.3918 - val_loss: 158.9901 - val_mae: 9.2417\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.7308 - mae: 11.3471 - val_loss: 163.2826 - val_mae: 9.6694\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.6767 - mae: 11.3719 - val_loss: 167.8116 - val_mae: 10.0138\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 239.3416 - mae: 11.4235 - val_loss: 157.6857 - val_mae: 9.1271\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.9363 - mae: 11.2710 - val_loss: 161.6767 - val_mae: 9.5478\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 239.9171 - mae: 11.4865 - val_loss: 157.6500 - val_mae: 9.1475\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.0189 - mae: 11.3316 - val_loss: 161.1153 - val_mae: 9.5192\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.9161 - mae: 11.4190 - val_loss: 157.6245 - val_mae: 9.0070\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.8228 - mae: 11.2815 - val_loss: 162.1217 - val_mae: 9.6053\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.3703 - mae: 11.3430 - val_loss: 156.9982 - val_mae: 9.1032\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.5591 - mae: 11.2332 - val_loss: 157.0655 - val_mae: 9.1180\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.9005 - mae: 11.2635 - val_loss: 163.7817 - val_mae: 9.7426\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.8023 - mae: 11.3846 - val_loss: 156.7050 - val_mae: 8.9859\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.8149 - mae: 11.2685 - val_loss: 156.9207 - val_mae: 9.1132\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.0478 - mae: 11.3519 - val_loss: 155.7309 - val_mae: 8.9577\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.0011 - mae: 11.2526 - val_loss: 155.5074 - val_mae: 8.9105\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.6272 - mae: 11.2249 - val_loss: 156.1597 - val_mae: 9.0528\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.0316 - mae: 11.2149 - val_loss: 162.5693 - val_mae: 9.6790\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 236.8169 - mae: 11.3819 - val_loss: 152.6376 - val_mae: 8.8543\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 232.8942 - mae: 11.0789 - val_loss: 151.8891 - val_mae: 8.8783\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 231.7504 - mae: 11.0682 - val_loss: 152.3118 - val_mae: 8.9766\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.9702 - mae: 11.0608 - val_loss: 153.4894 - val_mae: 9.1222\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 230.8821 - mae: 11.1659 - val_loss: 151.4224 - val_mae: 8.9192\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.1279 - mae: 11.0381 - val_loss: 150.1487 - val_mae: 8.7216\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 230.4377 - mae: 11.0767 - val_loss: 151.3112 - val_mae: 8.7880\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.7110 - mae: 10.9594 - val_loss: 150.7566 - val_mae: 8.8669\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.5973 - mae: 11.0411 - val_loss: 149.6216 - val_mae: 8.6999\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.5397 - mae: 10.9182 - val_loss: 159.0240 - val_mae: 9.6297\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.7544 - mae: 11.1141 - val_loss: 148.9091 - val_mae: 8.6870\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.1492 - mae: 10.9517 - val_loss: 149.5535 - val_mae: 8.7114\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.4264 - mae: 10.9592 - val_loss: 150.3176 - val_mae: 8.9271\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.3757 - mae: 10.8789 - val_loss: 146.4679 - val_mae: 8.7530\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 221.7624 - mae: 10.8086 - val_loss: 143.8887 - val_mae: 8.5404\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.1853 - mae: 10.8168 - val_loss: 149.5702 - val_mae: 9.1438\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.6668 - mae: 10.8652 - val_loss: 142.0935 - val_mae: 8.4109\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.3736 - mae: 10.6217 - val_loss: 144.7339 - val_mae: 8.7542\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.1499 - mae: 10.6725 - val_loss: 142.8934 - val_mae: 8.5948\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 217.9921 - mae: 10.6728 - val_loss: 142.8815 - val_mae: 8.6718\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.5823 - mae: 10.5774 - val_loss: 141.5715 - val_mae: 8.5625\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.3474 - mae: 10.5731 - val_loss: 148.7997 - val_mae: 9.2242\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 215.7562 - mae: 10.6668 - val_loss: 139.0944 - val_mae: 8.3123\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.4655 - mae: 10.5488 - val_loss: 147.3322 - val_mae: 9.1445\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 215.1822 - mae: 10.6486 - val_loss: 135.9451 - val_mae: 8.2399\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.2284 - mae: 10.4882 - val_loss: 134.8463 - val_mae: 8.1262\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.5027 - mae: 10.3903 - val_loss: 138.0499 - val_mae: 8.4977\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 212.1169 - mae: 10.5255 - val_loss: 134.2213 - val_mae: 8.1124\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 210.1834 - mae: 10.3685 - val_loss: 133.5087 - val_mae: 8.0658\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.6935 - mae: 10.2696 - val_loss: 135.7648 - val_mae: 8.4026\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.4716 - mae: 10.3350 - val_loss: 133.8583 - val_mae: 8.2320\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 206.2457 - mae: 10.2781 - val_loss: 130.0679 - val_mae: 7.9835\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 203.0387 - mae: 10.1175 - val_loss: 135.5598 - val_mae: 8.6748\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.8920 - mae: 10.1992 - val_loss: 125.9404 - val_mae: 7.8800\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.3852 - mae: 10.0024 - val_loss: 125.1510 - val_mae: 7.9250\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 195.4348 - mae: 9.9379 - val_loss: 125.2116 - val_mae: 7.9344\n",
      "5/5 [==============================] - 0s 578us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=2, model__n_neurons=125, model__optimizer=nesterov; total time=   2.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 501.5731 - mae: 18.1686 - val_loss: 249.3996 - val_mae: 13.1900\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 352.2027 - mae: 15.0704 - val_loss: 218.1966 - val_mae: 11.9420\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 328.8196 - mae: 14.2984 - val_loss: 208.4858 - val_mae: 11.5577\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 315.3930 - mae: 13.8762 - val_loss: 201.8346 - val_mae: 11.1917\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 310.6677 - mae: 13.7105 - val_loss: 196.1845 - val_mae: 10.8697\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 304.9984 - mae: 13.5266 - val_loss: 187.5333 - val_mae: 10.4967\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 296.7801 - mae: 13.2544 - val_loss: 183.5652 - val_mae: 10.4250\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 291.1600 - mae: 13.0760 - val_loss: 183.9185 - val_mae: 10.5140\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 283.5759 - mae: 12.8828 - val_loss: 183.9494 - val_mae: 10.5694\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 281.5709 - mae: 12.8458 - val_loss: 183.3848 - val_mae: 10.5278\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 280.9807 - mae: 12.8422 - val_loss: 174.5049 - val_mae: 9.9538\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.6422 - mae: 12.6917 - val_loss: 179.5606 - val_mae: 10.3077\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 278.9052 - mae: 12.7352 - val_loss: 178.7072 - val_mae: 10.2528\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 279.6284 - mae: 12.7849 - val_loss: 174.2468 - val_mae: 9.9342\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.2046 - mae: 12.6317 - val_loss: 174.4155 - val_mae: 9.9584\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.9243 - mae: 12.6443 - val_loss: 172.5877 - val_mae: 9.8401\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.4911 - mae: 12.5941 - val_loss: 178.5643 - val_mae: 10.2824\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 277.9394 - mae: 12.6755 - val_loss: 173.3943 - val_mae: 9.9087\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.5719 - mae: 12.5394 - val_loss: 174.8807 - val_mae: 10.0255\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.4692 - mae: 12.6115 - val_loss: 175.1309 - val_mae: 10.0599\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.4593 - mae: 12.5926 - val_loss: 170.7126 - val_mae: 9.7182\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 275.5390 - mae: 12.5081 - val_loss: 170.2239 - val_mae: 9.6872\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.0376 - mae: 12.4480 - val_loss: 173.3186 - val_mae: 9.9369\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 274.9217 - mae: 12.5244 - val_loss: 174.0780 - val_mae: 9.9766\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 273.4752 - mae: 12.4956 - val_loss: 168.1438 - val_mae: 9.6351\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 271.0566 - mae: 12.3891 - val_loss: 171.8079 - val_mae: 9.9478\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 269.6284 - mae: 12.3615 - val_loss: 164.6783 - val_mae: 9.3901\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 270.6911 - mae: 12.3710 - val_loss: 164.4575 - val_mae: 9.3814\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.8813 - mae: 12.2841 - val_loss: 164.9176 - val_mae: 9.4230\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.9607 - mae: 12.2559 - val_loss: 165.3674 - val_mae: 9.4670\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 268.6988 - mae: 12.3251 - val_loss: 163.5305 - val_mae: 9.2990\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 269.6146 - mae: 12.1565 - val_loss: 175.8123 - val_mae: 10.2438\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.5001 - mae: 12.3200 - val_loss: 167.3472 - val_mae: 9.6331\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 266.2739 - mae: 12.2032 - val_loss: 170.1438 - val_mae: 9.8499\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 266.3527 - mae: 12.2316 - val_loss: 167.5370 - val_mae: 9.6460\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 266.6550 - mae: 12.2476 - val_loss: 165.9609 - val_mae: 9.5090\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.3911 - mae: 12.2446 - val_loss: 163.1768 - val_mae: 9.2746\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 267.2243 - mae: 12.1851 - val_loss: 162.6047 - val_mae: 9.2320\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 265.6606 - mae: 12.1804 - val_loss: 163.1207 - val_mae: 9.2807\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 265.0992 - mae: 12.1049 - val_loss: 168.4514 - val_mae: 9.7278\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 266.2049 - mae: 12.2299 - val_loss: 162.2943 - val_mae: 9.2179\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 265.1992 - mae: 12.1507 - val_loss: 161.5926 - val_mae: 9.1617\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 264.8104 - mae: 12.1043 - val_loss: 163.0942 - val_mae: 9.3050\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.9269 - mae: 12.0738 - val_loss: 163.0184 - val_mae: 9.3171\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.0947 - mae: 12.1826 - val_loss: 159.9323 - val_mae: 9.0590\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.8584 - mae: 12.0341 - val_loss: 159.2481 - val_mae: 9.0438\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.1619 - mae: 11.9852 - val_loss: 159.7335 - val_mae: 9.1219\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.5051 - mae: 11.9853 - val_loss: 162.8643 - val_mae: 9.3981\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 260.1941 - mae: 11.9006 - val_loss: 180.6831 - val_mae: 10.6631\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 262.8023 - mae: 12.1886 - val_loss: 158.1548 - val_mae: 8.9998\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.1562 - mae: 11.9414 - val_loss: 161.1046 - val_mae: 9.2690\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.2379 - mae: 12.1044 - val_loss: 160.9651 - val_mae: 9.2528\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.4966 - mae: 11.9128 - val_loss: 160.9316 - val_mae: 9.2646\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.8119 - mae: 11.9865 - val_loss: 157.6167 - val_mae: 8.9719\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.6368 - mae: 11.8697 - val_loss: 165.8823 - val_mae: 9.6643\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 261.3135 - mae: 12.0493 - val_loss: 159.6205 - val_mae: 9.1518\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.2480 - mae: 11.9028 - val_loss: 159.5115 - val_mae: 9.1358\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 258.7693 - mae: 11.8791 - val_loss: 160.1825 - val_mae: 9.2076\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 259.4703 - mae: 11.8841 - val_loss: 161.6759 - val_mae: 9.3359\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 260.1726 - mae: 11.9184 - val_loss: 161.7963 - val_mae: 9.3514\n",
      "Epoch 60: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=2, model__n_neurons=125, model__optimizer=nesterov; total time=   1.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 389.1541 - mae: 16.2605 - val_loss: 296.1433 - val_mae: 13.8606\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 290.8481 - mae: 13.4844 - val_loss: 273.6124 - val_mae: 12.9816\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 276.1136 - mae: 12.9211 - val_loss: 264.0002 - val_mae: 12.6690\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 263.7976 - mae: 12.4614 - val_loss: 252.5264 - val_mae: 12.2988\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 255.3468 - mae: 12.1855 - val_loss: 246.3936 - val_mae: 11.9934\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 251.3818 - mae: 12.0132 - val_loss: 240.2922 - val_mae: 11.8078\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 248.3039 - mae: 11.9397 - val_loss: 237.9104 - val_mae: 11.8332\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 243.4802 - mae: 11.8421 - val_loss: 233.3170 - val_mae: 11.4987\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 240.5095 - mae: 11.5987 - val_loss: 231.1109 - val_mae: 11.4767\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 239.3949 - mae: 11.6026 - val_loss: 229.9202 - val_mae: 11.4017\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.5240 - mae: 11.5413 - val_loss: 228.6025 - val_mae: 11.3965\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 238.6742 - mae: 11.5639 - val_loss: 229.3250 - val_mae: 11.3827\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 237.7215 - mae: 11.4758 - val_loss: 226.1624 - val_mae: 11.2977\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 234.4859 - mae: 11.4006 - val_loss: 221.9574 - val_mae: 11.1611\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 230.8010 - mae: 11.3063 - val_loss: 220.3218 - val_mae: 11.0608\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.9710 - mae: 11.2210 - val_loss: 219.9340 - val_mae: 11.1191\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 228.7094 - mae: 11.2664 - val_loss: 219.6749 - val_mae: 11.0093\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 229.0474 - mae: 11.1938 - val_loss: 217.5670 - val_mae: 10.9600\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 227.8935 - mae: 11.1669 - val_loss: 217.5192 - val_mae: 10.9559\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 227.4709 - mae: 11.1113 - val_loss: 216.6375 - val_mae: 10.9094\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 227.8446 - mae: 11.1526 - val_loss: 216.2469 - val_mae: 10.9060\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 226.3255 - mae: 11.0390 - val_loss: 215.4193 - val_mae: 10.9116\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.8507 - mae: 11.0981 - val_loss: 215.3827 - val_mae: 10.8730\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.9243 - mae: 11.0164 - val_loss: 216.1868 - val_mae: 11.0099\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 225.9063 - mae: 11.0971 - val_loss: 213.7401 - val_mae: 10.8155\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 224.5680 - mae: 10.9835 - val_loss: 214.2372 - val_mae: 10.9301\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 223.5990 - mae: 11.0612 - val_loss: 211.4464 - val_mae: 10.7262\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.6542 - mae: 10.9583 - val_loss: 210.6704 - val_mae: 10.7163\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 221.4869 - mae: 10.8895 - val_loss: 210.2279 - val_mae: 10.6763\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 221.4509 - mae: 10.8816 - val_loss: 210.2280 - val_mae: 10.7041\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.7957 - mae: 10.8783 - val_loss: 209.3095 - val_mae: 10.6449\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.8438 - mae: 10.8329 - val_loss: 210.3362 - val_mae: 10.7713\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 221.0346 - mae: 10.9313 - val_loss: 210.6840 - val_mae: 10.6794\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 221.1486 - mae: 10.8589 - val_loss: 207.9913 - val_mae: 10.5780\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.5628 - mae: 10.7896 - val_loss: 207.6509 - val_mae: 10.5736\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.2787 - mae: 10.8274 - val_loss: 208.8708 - val_mae: 10.5993\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.4766 - mae: 10.8815 - val_loss: 209.4792 - val_mae: 10.6198\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.7765 - mae: 10.8304 - val_loss: 208.2854 - val_mae: 10.5722\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.9012 - mae: 10.7795 - val_loss: 206.5768 - val_mae: 10.5405\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 218.6339 - mae: 10.7728 - val_loss: 206.5894 - val_mae: 10.5074\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.0330 - mae: 10.7862 - val_loss: 206.7425 - val_mae: 10.4992\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 217.9850 - mae: 10.6321 - val_loss: 219.8757 - val_mae: 11.3892\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 220.8001 - mae: 10.9763 - val_loss: 205.1115 - val_mae: 10.4677\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.8157 - mae: 10.7031 - val_loss: 204.8327 - val_mae: 10.4446\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 216.0966 - mae: 10.6338 - val_loss: 203.6171 - val_mae: 10.4384\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.7314 - mae: 10.6169 - val_loss: 203.6206 - val_mae: 10.4428\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.6702 - mae: 10.6558 - val_loss: 204.7737 - val_mae: 10.4476\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.7436 - mae: 10.6179 - val_loss: 203.2146 - val_mae: 10.3749\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.3208 - mae: 10.6155 - val_loss: 202.0701 - val_mae: 10.3402\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 214.0761 - mae: 10.5831 - val_loss: 202.5415 - val_mae: 10.4048\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 212.6569 - mae: 10.5781 - val_loss: 200.1479 - val_mae: 10.2589\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 212.4565 - mae: 10.4907 - val_loss: 199.2011 - val_mae: 10.2392\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 210.7413 - mae: 10.4448 - val_loss: 200.1553 - val_mae: 10.3680\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 210.2109 - mae: 10.4732 - val_loss: 199.5372 - val_mae: 10.3323\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.2396 - mae: 10.5353 - val_loss: 198.1691 - val_mae: 10.1948\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 210.9406 - mae: 10.4945 - val_loss: 198.6575 - val_mae: 10.2001\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 210.0464 - mae: 10.4053 - val_loss: 197.3156 - val_mae: 10.1504\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.9364 - mae: 10.4183 - val_loss: 197.2396 - val_mae: 10.1552\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.6780 - mae: 10.4237 - val_loss: 198.0451 - val_mae: 10.2538\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.7010 - mae: 10.4895 - val_loss: 199.5112 - val_mae: 10.2534\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.3116 - mae: 10.3189 - val_loss: 196.9318 - val_mae: 10.1615\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.6239 - mae: 10.4210 - val_loss: 196.5002 - val_mae: 10.0964\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.7653 - mae: 10.3825 - val_loss: 197.8754 - val_mae: 10.1576\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.8579 - mae: 10.3193 - val_loss: 196.0692 - val_mae: 10.1147\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.5744 - mae: 10.3872 - val_loss: 196.7523 - val_mae: 10.0780\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 209.5881 - mae: 10.3434 - val_loss: 196.2916 - val_mae: 10.1297\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 208.0565 - mae: 10.3473 - val_loss: 195.0400 - val_mae: 10.0977\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 207.1235 - mae: 10.3893 - val_loss: 194.5257 - val_mae: 10.0378\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.7292 - mae: 10.1957 - val_loss: 192.5052 - val_mae: 10.0110\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.6689 - mae: 10.2799 - val_loss: 194.4479 - val_mae: 10.0548\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 204.4524 - mae: 10.1737 - val_loss: 192.0906 - val_mae: 9.9528\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 203.4507 - mae: 10.1956 - val_loss: 188.9780 - val_mae: 9.8460\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.3561 - mae: 9.9971 - val_loss: 188.0718 - val_mae: 9.8408\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.4586 - mae: 10.0918 - val_loss: 187.6843 - val_mae: 9.7801\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.1548 - mae: 10.0689 - val_loss: 187.7844 - val_mae: 9.7663\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.8525 - mae: 10.0250 - val_loss: 189.6750 - val_mae: 9.9738\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.5649 - mae: 10.1235 - val_loss: 186.8970 - val_mae: 9.7546\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.2722 - mae: 10.0374 - val_loss: 188.4300 - val_mae: 9.8837\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.5419 - mae: 10.0774 - val_loss: 189.8171 - val_mae: 9.9000\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.1371 - mae: 9.9681 - val_loss: 187.3122 - val_mae: 9.7519\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.8150 - mae: 10.0334 - val_loss: 187.8883 - val_mae: 9.8592\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.7707 - mae: 10.0955 - val_loss: 186.4552 - val_mae: 9.7234\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 199.8518 - mae: 10.0431 - val_loss: 188.4811 - val_mae: 9.9086\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.1751 - mae: 10.1222 - val_loss: 186.4974 - val_mae: 9.7160\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.5227 - mae: 9.9832 - val_loss: 185.2227 - val_mae: 9.7316\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 196.8227 - mae: 9.9439 - val_loss: 184.4156 - val_mae: 9.6962\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 197.0993 - mae: 9.9837 - val_loss: 182.5191 - val_mae: 9.5695\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.6969 - mae: 9.8129 - val_loss: 179.1592 - val_mae: 9.4941\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.4436 - mae: 9.7417 - val_loss: 178.1577 - val_mae: 9.4643\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 192.1551 - mae: 9.7593 - val_loss: 180.8322 - val_mae: 9.6477\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 192.1030 - mae: 9.8216 - val_loss: 178.1881 - val_mae: 9.4595\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.8551 - mae: 9.7513 - val_loss: 183.1557 - val_mae: 9.8130\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 192.0595 - mae: 9.8645 - val_loss: 177.7234 - val_mae: 9.4033\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.9727 - mae: 9.8144 - val_loss: 178.0480 - val_mae: 9.4162\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.1301 - mae: 9.6644 - val_loss: 178.8555 - val_mae: 9.5300\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 191.3489 - mae: 9.8202 - val_loss: 178.6356 - val_mae: 9.4342\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.7873 - mae: 9.6705 - val_loss: 177.7525 - val_mae: 9.4040\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.4143 - mae: 9.6704 - val_loss: 177.4711 - val_mae: 9.3834\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 190.9636 - mae: 9.7133 - val_loss: 177.8003 - val_mae: 9.3922\n",
      "Epoch 99: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.5, model__n_hidden=2, model__n_neurons=125, model__optimizer=nesterov; total time=   2.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 24560.8418 - mae: 47.7436 - val_loss: 449.2088 - val_mae: 20.2755\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.4406 - mae: 22.6973 - val_loss: 448.7928 - val_mae: 20.2652\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.8909 - mae: 22.6850 - val_loss: 448.2163 - val_mae: 20.2509\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.2090 - mae: 22.6699 - val_loss: 447.5802 - val_mae: 20.2350\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.4811 - mae: 22.6536 - val_loss: 446.9167 - val_mae: 20.2183\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.7402 - mae: 22.6368 - val_loss: 446.2477 - val_mae: 20.2013\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.9880 - mae: 22.6199 - val_loss: 445.5891 - val_mae: 20.1845\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.2444 - mae: 22.6031 - val_loss: 444.9397 - val_mae: 20.1677\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.5181 - mae: 22.5863 - val_loss: 444.2919 - val_mae: 20.1510\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.7934 - mae: 22.5695 - val_loss: 443.6487 - val_mae: 20.1342\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.0706 - mae: 22.5529 - val_loss: 443.0201 - val_mae: 20.1176\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.3650 - mae: 22.5364 - val_loss: 442.3979 - val_mae: 20.1012\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.6653 - mae: 22.5199 - val_loss: 441.7842 - val_mae: 20.0848\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.9772 - mae: 22.5035 - val_loss: 441.1752 - val_mae: 20.0684\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.2957 - mae: 22.4872 - val_loss: 440.5758 - val_mae: 20.0522\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 588.6249 - mae: 22.4711 - val_loss: 439.9844 - val_mae: 20.0360\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.9534 - mae: 22.4551 - val_loss: 439.4096 - val_mae: 20.0203\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.3035 - mae: 22.4393 - val_loss: 438.8391 - val_mae: 20.0045\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.6531 - mae: 22.4236 - val_loss: 438.2780 - val_mae: 19.9888\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.0221 - mae: 22.4079 - val_loss: 437.7190 - val_mae: 19.9731\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 585.3933 - mae: 22.3921 - val_loss: 437.1649 - val_mae: 19.9574\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.7668 - mae: 22.3766 - val_loss: 436.6199 - val_mae: 19.9419\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.1471 - mae: 22.3612 - val_loss: 436.0881 - val_mae: 19.9266\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 583.5454 - mae: 22.3459 - val_loss: 435.5591 - val_mae: 19.9113\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 582.9498 - mae: 22.3305 - val_loss: 435.0341 - val_mae: 19.8960\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.3519 - mae: 22.3153 - val_loss: 434.5196 - val_mae: 19.8809\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 581.7638 - mae: 22.3003 - val_loss: 434.0141 - val_mae: 19.8660\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 581.1912 - mae: 22.2854 - val_loss: 433.5133 - val_mae: 19.8511\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.6190 - mae: 22.2705 - val_loss: 433.0216 - val_mae: 19.8363\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 580.0643 - mae: 22.2557 - val_loss: 432.5310 - val_mae: 19.8215\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 579.5059 - mae: 22.2410 - val_loss: 432.0525 - val_mae: 19.8069\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 578.9569 - mae: 22.2265 - val_loss: 431.5842 - val_mae: 19.7925\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 578.4210 - mae: 22.2121 - val_loss: 431.1166 - val_mae: 19.7781\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.8830 - mae: 22.1977 - val_loss: 430.6569 - val_mae: 19.7638\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.3553 - mae: 22.1834 - val_loss: 430.2024 - val_mae: 19.7495\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 576.8430 - mae: 22.1691 - val_loss: 429.7491 - val_mae: 19.7352\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 576.3216 - mae: 22.1549 - val_loss: 429.3096 - val_mae: 19.7212\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.8148 - mae: 22.1410 - val_loss: 428.8783 - val_mae: 19.7073\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.3188 - mae: 22.1272 - val_loss: 428.4536 - val_mae: 19.6936\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.8235 - mae: 22.1135 - val_loss: 428.0342 - val_mae: 19.6799\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 574.3478 - mae: 22.0998 - val_loss: 427.6121 - val_mae: 19.6661\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 573.8608 - mae: 22.0862 - val_loss: 427.2002 - val_mae: 19.6525\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 573.3884 - mae: 22.0729 - val_loss: 426.7937 - val_mae: 19.6389\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.9163 - mae: 22.0597 - val_loss: 426.3969 - val_mae: 19.6256\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.4604 - mae: 22.0466 - val_loss: 426.0011 - val_mae: 19.6122\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.0023 - mae: 22.0334 - val_loss: 425.6118 - val_mae: 19.5990\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.5491 - mae: 22.0205 - val_loss: 425.2313 - val_mae: 19.5859\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 571.1079 - mae: 22.0076 - val_loss: 424.8552 - val_mae: 19.5729\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.6675 - mae: 21.9950 - val_loss: 424.4828 - val_mae: 19.5599\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.2341 - mae: 21.9822 - val_loss: 424.1155 - val_mae: 19.5470\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.8049 - mae: 21.9695 - val_loss: 423.7544 - val_mae: 19.5343\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.3869 - mae: 21.9570 - val_loss: 423.3943 - val_mae: 19.5214\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.9653 - mae: 21.9444 - val_loss: 423.0417 - val_mae: 19.5088\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.5601 - mae: 21.9320 - val_loss: 422.6895 - val_mae: 19.4960\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.1451 - mae: 21.9195 - val_loss: 422.3506 - val_mae: 19.4837\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.7477 - mae: 21.9074 - val_loss: 422.0138 - val_mae: 19.4713\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.3524 - mae: 21.8952 - val_loss: 421.6808 - val_mae: 19.4590\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.9596 - mae: 21.8832 - val_loss: 421.3553 - val_mae: 19.4468\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.5804 - mae: 21.8712 - val_loss: 421.0287 - val_mae: 19.4348\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.1972 - mae: 21.8591 - val_loss: 420.7091 - val_mae: 19.4236\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.8179 - mae: 21.8474 - val_loss: 420.3964 - val_mae: 19.4125\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.4551 - mae: 21.8356 - val_loss: 420.0845 - val_mae: 19.4014\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.0859 - mae: 21.8240 - val_loss: 419.7794 - val_mae: 19.3905\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.7228 - mae: 21.8126 - val_loss: 419.4800 - val_mae: 19.3796\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.3661 - mae: 21.8012 - val_loss: 419.1833 - val_mae: 19.3688\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.0164 - mae: 21.7900 - val_loss: 418.8921 - val_mae: 19.3581\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.6705 - mae: 21.7788 - val_loss: 418.6043 - val_mae: 19.3475\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.3280 - mae: 21.7677 - val_loss: 418.3196 - val_mae: 19.3369\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.9958 - mae: 21.7566 - val_loss: 418.0330 - val_mae: 19.3261\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.6500 - mae: 21.7455 - val_loss: 417.7568 - val_mae: 19.3156\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.3257 - mae: 21.7345 - val_loss: 417.4819 - val_mae: 19.3052\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.9918 - mae: 21.7237 - val_loss: 417.2182 - val_mae: 19.2950\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.6812 - mae: 21.7129 - val_loss: 416.9506 - val_mae: 19.2847\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.3574 - mae: 21.7024 - val_loss: 416.6920 - val_mae: 19.2745\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.0474 - mae: 21.6922 - val_loss: 416.4331 - val_mae: 19.2644\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.7334 - mae: 21.6821 - val_loss: 416.1812 - val_mae: 19.2544\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.4363 - mae: 21.6719 - val_loss: 415.9298 - val_mae: 19.2443\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.1349 - mae: 21.6620 - val_loss: 415.6806 - val_mae: 19.2343\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.8322 - mae: 21.6522 - val_loss: 415.4377 - val_mae: 19.2244\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.5402 - mae: 21.6422 - val_loss: 415.1968 - val_mae: 19.2146\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.2514 - mae: 21.6327 - val_loss: 414.9575 - val_mae: 19.2047\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.9582 - mae: 21.6229 - val_loss: 414.7283 - val_mae: 19.1952\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.6812 - mae: 21.6135 - val_loss: 414.4983 - val_mae: 19.1855\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.4013 - mae: 21.6039 - val_loss: 414.2713 - val_mae: 19.1759\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.1226 - mae: 21.5945 - val_loss: 414.0493 - val_mae: 19.1665\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.8531 - mae: 21.5852 - val_loss: 413.8291 - val_mae: 19.1571\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.5880 - mae: 21.5758 - val_loss: 413.6087 - val_mae: 19.1475\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.3161 - mae: 21.5664 - val_loss: 413.3961 - val_mae: 19.1382\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.0553 - mae: 21.5570 - val_loss: 413.1838 - val_mae: 19.1289\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.8013 - mae: 21.5479 - val_loss: 412.9734 - val_mae: 19.1196\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.5400 - mae: 21.5388 - val_loss: 412.7699 - val_mae: 19.1105\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.2922 - mae: 21.5297 - val_loss: 412.5665 - val_mae: 19.1014\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.0400 - mae: 21.5208 - val_loss: 412.3694 - val_mae: 19.0924\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.7962 - mae: 21.5119 - val_loss: 412.1744 - val_mae: 19.0835\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.5588 - mae: 21.5032 - val_loss: 411.9789 - val_mae: 19.0745\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.3156 - mae: 21.4943 - val_loss: 411.7883 - val_mae: 19.0657\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.0780 - mae: 21.4856 - val_loss: 411.6019 - val_mae: 19.0572\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.8524 - mae: 21.4771 - val_loss: 411.4117 - val_mae: 19.0489\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.6138 - mae: 21.4684 - val_loss: 411.2291 - val_mae: 19.0409\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.3815 - mae: 21.4600 - val_loss: 411.0504 - val_mae: 19.0331\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=25, model__optimizer=momentum; total time=   2.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 1982.5214 - mae: 29.6061 - val_loss: 449.1884 - val_mae: 20.2750\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.9261 - mae: 23.1140 - val_loss: 448.4431 - val_mae: 20.2566\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.8581 - mae: 23.0909 - val_loss: 447.3215 - val_mae: 20.2287\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.4918 - mae: 23.0609 - val_loss: 446.0307 - val_mae: 20.1965\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.9805 - mae: 23.0280 - val_loss: 444.6875 - val_mae: 20.1627\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.4535 - mae: 22.9937 - val_loss: 443.3228 - val_mae: 20.1281\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.8884 - mae: 22.9593 - val_loss: 441.9797 - val_mae: 20.0938\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.3334 - mae: 22.9253 - val_loss: 440.6638 - val_mae: 20.0599\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.8399 - mae: 22.8911 - val_loss: 439.3409 - val_mae: 20.0257\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.3307 - mae: 22.8568 - val_loss: 438.0284 - val_mae: 19.9914\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.8317 - mae: 22.8227 - val_loss: 436.7353 - val_mae: 19.9574\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.3455 - mae: 22.7890 - val_loss: 435.4732 - val_mae: 19.9240\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.8995 - mae: 22.7555 - val_loss: 434.2202 - val_mae: 19.8905\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 619.4639 - mae: 22.7221 - val_loss: 432.9838 - val_mae: 19.8573\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 618.0409 - mae: 22.6891 - val_loss: 431.7712 - val_mae: 19.8244\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 616.6618 - mae: 22.6561 - val_loss: 430.5599 - val_mae: 19.7914\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 615.2563 - mae: 22.6234 - val_loss: 429.3808 - val_mae: 19.7589\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 613.9021 - mae: 22.5909 - val_loss: 428.2063 - val_mae: 19.7264\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 612.5386 - mae: 22.5587 - val_loss: 427.0605 - val_mae: 19.6944\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 611.2256 - mae: 22.5265 - val_loss: 425.9174 - val_mae: 19.6623\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 609.9204 - mae: 22.4943 - val_loss: 424.7867 - val_mae: 19.6302\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 608.6064 - mae: 22.4626 - val_loss: 423.6849 - val_mae: 19.5988\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 607.3326 - mae: 22.4313 - val_loss: 422.5989 - val_mae: 19.5675\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 606.0778 - mae: 22.4000 - val_loss: 421.5210 - val_mae: 19.5363\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 604.8322 - mae: 22.3687 - val_loss: 420.4508 - val_mae: 19.5051\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 603.5906 - mae: 22.3377 - val_loss: 419.4045 - val_mae: 19.4743\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 602.3771 - mae: 22.3070 - val_loss: 418.3725 - val_mae: 19.4437\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 601.1757 - mae: 22.2767 - val_loss: 417.3678 - val_mae: 19.4137\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 600.0089 - mae: 22.2467 - val_loss: 416.3712 - val_mae: 19.3837\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.8465 - mae: 22.2168 - val_loss: 415.3882 - val_mae: 19.3539\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 597.7022 - mae: 22.1870 - val_loss: 414.4158 - val_mae: 19.3242\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 596.5632 - mae: 22.1574 - val_loss: 413.4652 - val_mae: 19.2949\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 595.4523 - mae: 22.1280 - val_loss: 412.5129 - val_mae: 19.2654\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 594.3344 - mae: 22.0987 - val_loss: 411.5790 - val_mae: 19.2362\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 593.2337 - mae: 22.0696 - val_loss: 410.6617 - val_mae: 19.2073\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 592.1716 - mae: 22.0405 - val_loss: 409.7413 - val_mae: 19.1781\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 591.0873 - mae: 22.0116 - val_loss: 408.8447 - val_mae: 19.1494\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 590.0363 - mae: 21.9831 - val_loss: 407.9656 - val_mae: 19.1211\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 589.0072 - mae: 21.9548 - val_loss: 407.0972 - val_mae: 19.0929\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 587.9709 - mae: 21.9268 - val_loss: 406.2474 - val_mae: 19.0651\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 586.9795 - mae: 21.8988 - val_loss: 405.3954 - val_mae: 19.0370\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 585.9744 - mae: 21.8709 - val_loss: 404.5594 - val_mae: 19.0092\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.9781 - mae: 21.8433 - val_loss: 403.7426 - val_mae: 18.9819\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 584.0076 - mae: 21.8160 - val_loss: 402.9346 - val_mae: 18.9546\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 583.0718 - mae: 21.7885 - val_loss: 402.1215 - val_mae: 18.9270\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 582.0928 - mae: 21.7613 - val_loss: 401.3397 - val_mae: 18.9002\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 581.1669 - mae: 21.7345 - val_loss: 400.5674 - val_mae: 18.8735\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 580.2428 - mae: 21.7080 - val_loss: 399.8108 - val_mae: 18.8472\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 579.3295 - mae: 21.6817 - val_loss: 399.0608 - val_mae: 18.8209\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 578.4350 - mae: 21.6554 - val_loss: 398.3119 - val_mae: 18.7945\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 577.5477 - mae: 21.6290 - val_loss: 397.5769 - val_mae: 18.7683\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 576.6710 - mae: 21.6031 - val_loss: 396.8508 - val_mae: 18.7422\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 575.7978 - mae: 21.5773 - val_loss: 396.1384 - val_mae: 18.7165\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.9499 - mae: 21.5517 - val_loss: 395.4317 - val_mae: 18.6907\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 574.0982 - mae: 21.5264 - val_loss: 394.7435 - val_mae: 18.6654\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 573.2664 - mae: 21.5012 - val_loss: 394.0595 - val_mae: 18.6401\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 572.4396 - mae: 21.4762 - val_loss: 393.3850 - val_mae: 18.6150\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 571.6299 - mae: 21.4513 - val_loss: 392.7195 - val_mae: 18.5905\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.8168 - mae: 21.4267 - val_loss: 392.0703 - val_mae: 18.5677\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 570.0396 - mae: 21.4020 - val_loss: 391.4158 - val_mae: 18.5446\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 569.2513 - mae: 21.3775 - val_loss: 390.7719 - val_mae: 18.5216\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 568.4738 - mae: 21.3533 - val_loss: 390.1437 - val_mae: 18.4991\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 567.7118 - mae: 21.3295 - val_loss: 389.5272 - val_mae: 18.4767\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.9619 - mae: 21.3060 - val_loss: 388.9193 - val_mae: 18.4545\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 566.2128 - mae: 21.2828 - val_loss: 388.3252 - val_mae: 18.4327\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 565.4869 - mae: 21.2599 - val_loss: 387.7385 - val_mae: 18.4109\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.7802 - mae: 21.2367 - val_loss: 387.1486 - val_mae: 18.3889\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 564.0544 - mae: 21.2139 - val_loss: 386.5782 - val_mae: 18.3674\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 563.3635 - mae: 21.1912 - val_loss: 386.0039 - val_mae: 18.3456\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 562.6484 - mae: 21.1685 - val_loss: 385.4490 - val_mae: 18.3243\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.9800 - mae: 21.1458 - val_loss: 384.8917 - val_mae: 18.3028\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 561.2819 - mae: 21.1236 - val_loss: 384.3586 - val_mae: 18.2821\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 560.6258 - mae: 21.1024 - val_loss: 383.8231 - val_mae: 18.2611\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.9613 - mae: 21.0810 - val_loss: 383.2952 - val_mae: 18.2403\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 559.3110 - mae: 21.0596 - val_loss: 382.7701 - val_mae: 18.2193\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.6472 - mae: 21.0389 - val_loss: 382.2628 - val_mae: 18.1990\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 558.0272 - mae: 21.0180 - val_loss: 381.7556 - val_mae: 18.1784\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.4119 - mae: 20.9976 - val_loss: 381.2438 - val_mae: 18.1575\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.7720 - mae: 20.9769 - val_loss: 380.7555 - val_mae: 18.1375\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.1661 - mae: 20.9566 - val_loss: 380.2704 - val_mae: 18.1173\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.5564 - mae: 20.9369 - val_loss: 379.7950 - val_mae: 18.0975\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.9554 - mae: 20.9170 - val_loss: 379.3330 - val_mae: 18.0780\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.3738 - mae: 20.8977 - val_loss: 378.8733 - val_mae: 18.0584\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.8035 - mae: 20.8779 - val_loss: 378.4110 - val_mae: 18.0386\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.2186 - mae: 20.8585 - val_loss: 377.9638 - val_mae: 18.0193\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.6576 - mae: 20.8390 - val_loss: 377.5204 - val_mae: 18.0000\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.0953 - mae: 20.8200 - val_loss: 377.0867 - val_mae: 17.9810\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.5439 - mae: 20.8012 - val_loss: 376.6555 - val_mae: 17.9619\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.0024 - mae: 20.7819 - val_loss: 376.2245 - val_mae: 17.9426\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.4619 - mae: 20.7632 - val_loss: 375.8006 - val_mae: 17.9236\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.9222 - mae: 20.7447 - val_loss: 375.3909 - val_mae: 17.9050\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.4010 - mae: 20.7261 - val_loss: 374.9844 - val_mae: 17.8864\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.8726 - mae: 20.7077 - val_loss: 374.5901 - val_mae: 17.8682\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.3708 - mae: 20.6897 - val_loss: 374.1922 - val_mae: 17.8497\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.8756 - mae: 20.6717 - val_loss: 373.7967 - val_mae: 17.8320\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.3599 - mae: 20.6533 - val_loss: 373.4186 - val_mae: 17.8156\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.8754 - mae: 20.6359 - val_loss: 373.0419 - val_mae: 17.7990\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.3964 - mae: 20.6185 - val_loss: 372.6640 - val_mae: 17.7823\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.9089 - mae: 20.6011 - val_loss: 372.2976 - val_mae: 17.7660\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.4308 - mae: 20.5838 - val_loss: 371.9391 - val_mae: 17.7498\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=25, model__optimizer=momentum; total time=   2.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 777402.3750 - mae: 190.3587 - val_loss: 548.5880 - val_mae: 21.8356\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.1003 - mae: 21.8917 - val_loss: 548.3011 - val_mae: 21.8291\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.7581 - mae: 21.8838 - val_loss: 547.9014 - val_mae: 21.8198\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.3322 - mae: 21.8741 - val_loss: 547.4599 - val_mae: 21.8096\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.8844 - mae: 21.8636 - val_loss: 546.9999 - val_mae: 21.7989\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.4224 - mae: 21.8528 - val_loss: 546.5376 - val_mae: 21.7880\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.9577 - mae: 21.8420 - val_loss: 546.0795 - val_mae: 21.7772\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.5038 - mae: 21.8311 - val_loss: 545.6198 - val_mae: 21.7662\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.0420 - mae: 21.8202 - val_loss: 545.1705 - val_mae: 21.7555\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.5930 - mae: 21.8095 - val_loss: 544.7272 - val_mae: 21.7448\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.1501 - mae: 21.7988 - val_loss: 544.2880 - val_mae: 21.7342\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.7124 - mae: 21.7882 - val_loss: 543.8542 - val_mae: 21.7236\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.2802 - mae: 21.7777 - val_loss: 543.4277 - val_mae: 21.7131\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.8539 - mae: 21.7672 - val_loss: 543.0058 - val_mae: 21.7027\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.4370 - mae: 21.7568 - val_loss: 542.5859 - val_mae: 21.6922\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.0172 - mae: 21.7464 - val_loss: 542.1742 - val_mae: 21.6819\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.6093 - mae: 21.7360 - val_loss: 541.7637 - val_mae: 21.6715\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.1990 - mae: 21.7258 - val_loss: 541.3626 - val_mae: 21.6614\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.7966 - mae: 21.7157 - val_loss: 540.9687 - val_mae: 21.6513\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.4029 - mae: 21.7056 - val_loss: 540.5800 - val_mae: 21.6413\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.0161 - mae: 21.6956 - val_loss: 540.1936 - val_mae: 21.6313\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.6283 - mae: 21.6857 - val_loss: 539.8151 - val_mae: 21.6215\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.2475 - mae: 21.6759 - val_loss: 539.4417 - val_mae: 21.6117\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.8764 - mae: 21.6660 - val_loss: 539.0686 - val_mae: 21.6018\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.5051 - mae: 21.6562 - val_loss: 538.6984 - val_mae: 21.5920\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.1348 - mae: 21.6464 - val_loss: 538.3348 - val_mae: 21.5823\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.7738 - mae: 21.6367 - val_loss: 537.9749 - val_mae: 21.5726\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.4158 - mae: 21.6271 - val_loss: 537.6204 - val_mae: 21.5630\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.0607 - mae: 21.6175 - val_loss: 537.2710 - val_mae: 21.5535\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.7138 - mae: 21.6080 - val_loss: 536.9257 - val_mae: 21.5440\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.3704 - mae: 21.5986 - val_loss: 536.5839 - val_mae: 21.5346\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.0252 - mae: 21.5892 - val_loss: 536.2499 - val_mae: 21.5253\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.6952 - mae: 21.5799 - val_loss: 535.9160 - val_mae: 21.5160\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.3630 - mae: 21.5706 - val_loss: 535.5894 - val_mae: 21.5068\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.0344 - mae: 21.5615 - val_loss: 535.2689 - val_mae: 21.4977\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 543.7159 - mae: 21.5524 - val_loss: 534.9495 - val_mae: 21.4886\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 543.4030 - mae: 21.5433 - val_loss: 534.6335 - val_mae: 21.4796\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 543.0867 - mae: 21.5343 - val_loss: 534.3256 - val_mae: 21.4707\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.7781 - mae: 21.5254 - val_loss: 534.0227 - val_mae: 21.4619\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.4726 - mae: 21.5167 - val_loss: 533.7236 - val_mae: 21.4531\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.1740 - mae: 21.5079 - val_loss: 533.4262 - val_mae: 21.4444\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 541.8739 - mae: 21.4992 - val_loss: 533.1345 - val_mae: 21.4358\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 541.5823 - mae: 21.4905 - val_loss: 532.8410 - val_mae: 21.4277\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 541.2914 - mae: 21.4819 - val_loss: 532.5518 - val_mae: 21.4197\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 541.0021 - mae: 21.4733 - val_loss: 532.2690 - val_mae: 21.4118\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.7204 - mae: 21.4648 - val_loss: 531.9877 - val_mae: 21.4038\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.4438 - mae: 21.4564 - val_loss: 531.7091 - val_mae: 21.3959\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.1628 - mae: 21.4480 - val_loss: 531.4395 - val_mae: 21.3882\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.8940 - mae: 21.4398 - val_loss: 531.1711 - val_mae: 21.3805\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.6267 - mae: 21.4315 - val_loss: 530.9050 - val_mae: 21.3729\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.3623 - mae: 21.4233 - val_loss: 530.6422 - val_mae: 21.3652\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.0991 - mae: 21.4152 - val_loss: 530.3846 - val_mae: 21.3577\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.8394 - mae: 21.4071 - val_loss: 530.1309 - val_mae: 21.3502\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.5871 - mae: 21.3991 - val_loss: 529.8774 - val_mae: 21.3427\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.3320 - mae: 21.3911 - val_loss: 529.6285 - val_mae: 21.3353\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.0851 - mae: 21.3833 - val_loss: 529.3821 - val_mae: 21.3278\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.8378 - mae: 21.3754 - val_loss: 529.1406 - val_mae: 21.3205\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.5973 - mae: 21.3677 - val_loss: 528.8999 - val_mae: 21.3132\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.3547 - mae: 21.3599 - val_loss: 528.6639 - val_mae: 21.3060\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.1205 - mae: 21.3522 - val_loss: 528.4280 - val_mae: 21.2987\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.8845 - mae: 21.3446 - val_loss: 528.1981 - val_mae: 21.2916\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.6573 - mae: 21.3370 - val_loss: 527.9675 - val_mae: 21.2844\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.4280 - mae: 21.3294 - val_loss: 527.7417 - val_mae: 21.2773\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.1995 - mae: 21.3219 - val_loss: 527.5229 - val_mae: 21.2704\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 535.9843 - mae: 21.3145 - val_loss: 527.3026 - val_mae: 21.2634\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 535.7627 - mae: 21.3071 - val_loss: 527.0880 - val_mae: 21.2565\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 535.5474 - mae: 21.2998 - val_loss: 526.8741 - val_mae: 21.2496\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 535.3354 - mae: 21.2925 - val_loss: 526.6621 - val_mae: 21.2427\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 535.1213 - mae: 21.2852 - val_loss: 526.4566 - val_mae: 21.2360\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 534.9160 - mae: 21.2781 - val_loss: 526.2499 - val_mae: 21.2292\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 534.7097 - mae: 21.2709 - val_loss: 526.0481 - val_mae: 21.2225\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 534.5084 - mae: 21.2638 - val_loss: 525.8476 - val_mae: 21.2158\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 534.3062 - mae: 21.2568 - val_loss: 525.6520 - val_mae: 21.2093\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 534.1128 - mae: 21.2497 - val_loss: 525.4567 - val_mae: 21.2027\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 533.9172 - mae: 21.2428 - val_loss: 525.2647 - val_mae: 21.1961\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 533.7261 - mae: 21.2359 - val_loss: 525.0745 - val_mae: 21.1896\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 533.5375 - mae: 21.2291 - val_loss: 524.8854 - val_mae: 21.1831\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 533.3487 - mae: 21.2222 - val_loss: 524.6999 - val_mae: 21.1767\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 533.1676 - mae: 21.2156 - val_loss: 524.5132 - val_mae: 21.1702\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.9791 - mae: 21.2089 - val_loss: 524.3356 - val_mae: 21.1640\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.7990 - mae: 21.2025 - val_loss: 524.1607 - val_mae: 21.1578\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.6250 - mae: 21.1961 - val_loss: 523.9827 - val_mae: 21.1515\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.4446 - mae: 21.1898 - val_loss: 523.8093 - val_mae: 21.1453\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.2708 - mae: 21.1835 - val_loss: 523.6364 - val_mae: 21.1390\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.1019 - mae: 21.1772 - val_loss: 523.4642 - val_mae: 21.1328\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.9299 - mae: 21.1710 - val_loss: 523.2972 - val_mae: 21.1267\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.7627 - mae: 21.1648 - val_loss: 523.1333 - val_mae: 21.1207\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.5991 - mae: 21.1589 - val_loss: 522.9716 - val_mae: 21.1147\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.4366 - mae: 21.1528 - val_loss: 522.8122 - val_mae: 21.1088\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.2769 - mae: 21.1468 - val_loss: 522.6547 - val_mae: 21.1029\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.1182 - mae: 21.1409 - val_loss: 522.4999 - val_mae: 21.0971\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.9623 - mae: 21.1350 - val_loss: 522.3456 - val_mae: 21.0912\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.8096 - mae: 21.1291 - val_loss: 522.1898 - val_mae: 21.0852\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.6568 - mae: 21.1231 - val_loss: 522.0364 - val_mae: 21.0794\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.5022 - mae: 21.1173 - val_loss: 521.8891 - val_mae: 21.0737\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.3563 - mae: 21.1116 - val_loss: 521.7409 - val_mae: 21.0679\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.2072 - mae: 21.1060 - val_loss: 521.5976 - val_mae: 21.0623\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.0654 - mae: 21.1003 - val_loss: 521.4538 - val_mae: 21.0566\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.9210 - mae: 21.0947 - val_loss: 521.3126 - val_mae: 21.0511\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.7817 - mae: 21.0890 - val_loss: 521.1718 - val_mae: 21.0459\n",
      "5/5 [==============================] - 0s 998us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=3, model__n_neurons=25, model__optimizer=momentum; total time=   2.6s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 24492.2461 - mae: 74.6546"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=0, model__n_neurons=25, model__optimizer=adam; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=0, model__n_neurons=25, model__optimizer=adam; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=1e-05, model__momentum=0.5, model__n_hidden=0, model__n_neurons=25, model__optimizer=adam; total time=   0.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 666.6857 - mae: 23.7770 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7147 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=nesterov; total time=   0.7s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 694.9358 - mae: 23.2822 - val_loss: 449.2949 - val_mae: 20.2775\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3297 - mae: 23.1227 - val_loss: 449.2824 - val_mae: 20.2771\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3176 - mae: 23.1224 - val_loss: 449.2662 - val_mae: 20.2765\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.2935 - mae: 23.1217 - val_loss: 449.2266 - val_mae: 20.2752\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.2642 - mae: 23.1208 - val_loss: 449.2000 - val_mae: 20.2742\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.2399 - mae: 23.1200 - val_loss: 449.1736 - val_mae: 20.2733\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.2151 - mae: 23.1193 - val_loss: 449.1458 - val_mae: 20.2724\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.1858 - mae: 23.1184 - val_loss: 449.1172 - val_mae: 20.2714\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.1477 - mae: 23.1173 - val_loss: 449.0878 - val_mae: 20.2703\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.0899 - mae: 23.1158 - val_loss: 448.9638 - val_mae: 20.2663\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.7739 - mae: 23.1086 - val_loss: 448.4753 - val_mae: 20.2547\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=nesterov; total time=   0.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 14ms/step - loss: 2375.7041 - mae: 29.8348 - val_loss: 548.1690 - val_mae: 21.8260\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 556.5341 - mae: 21.8788 - val_loss: 547.5615 - val_mae: 21.8121\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.9267 - mae: 21.8647 - val_loss: 546.9570 - val_mae: 21.7981\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 555.3221 - mae: 21.8510 - val_loss: 546.3585 - val_mae: 21.7843\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.7236 - mae: 21.8370 - val_loss: 545.7650 - val_mae: 21.7705\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 554.1300 - mae: 21.8232 - val_loss: 545.1751 - val_mae: 21.7568\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 553.5399 - mae: 21.8096 - val_loss: 544.5842 - val_mae: 21.7430\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.9493 - mae: 21.7956 - val_loss: 544.0004 - val_mae: 21.7293\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 552.3655 - mae: 21.7821 - val_loss: 543.4221 - val_mae: 21.7157\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.7867 - mae: 21.7686 - val_loss: 542.8448 - val_mae: 21.7021\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 551.2094 - mae: 21.7549 - val_loss: 542.2719 - val_mae: 21.6885\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.6370 - mae: 21.7414 - val_loss: 541.7070 - val_mae: 21.6751\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 550.0716 - mae: 21.7280 - val_loss: 541.1418 - val_mae: 21.6616\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 549.5063 - mae: 21.7146 - val_loss: 540.5798 - val_mae: 21.6482\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.9443 - mae: 21.7010 - val_loss: 540.0230 - val_mae: 21.6349\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 548.3871 - mae: 21.6877 - val_loss: 539.4646 - val_mae: 21.6214\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.8290 - mae: 21.6742 - val_loss: 538.9149 - val_mae: 21.6082\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 547.2792 - mae: 21.6610 - val_loss: 538.3685 - val_mae: 21.5949\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.7328 - mae: 21.6479 - val_loss: 537.8276 - val_mae: 21.5818\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 546.1915 - mae: 21.6348 - val_loss: 537.2866 - val_mae: 21.5686\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.6507 - mae: 21.6216 - val_loss: 536.7519 - val_mae: 21.5556\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 545.1156 - mae: 21.6087 - val_loss: 536.2185 - val_mae: 21.5425\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.5822 - mae: 21.5957 - val_loss: 535.6868 - val_mae: 21.5294\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 544.0501 - mae: 21.5825 - val_loss: 535.1559 - val_mae: 21.5163\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 543.5191 - mae: 21.5694 - val_loss: 534.6298 - val_mae: 21.5033\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.9929 - mae: 21.5564 - val_loss: 534.1080 - val_mae: 21.4903\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 542.4711 - mae: 21.5434 - val_loss: 533.5909 - val_mae: 21.4775\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 541.9539 - mae: 21.5305 - val_loss: 533.0742 - val_mae: 21.4645\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 541.4371 - mae: 21.5177 - val_loss: 532.5644 - val_mae: 21.4518\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.9269 - mae: 21.5048 - val_loss: 532.0551 - val_mae: 21.4389\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 540.4176 - mae: 21.4920 - val_loss: 531.5494 - val_mae: 21.4262\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.9116 - mae: 21.4795 - val_loss: 531.0460 - val_mae: 21.4134\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 539.4086 - mae: 21.4666 - val_loss: 530.5518 - val_mae: 21.4009\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.9140 - mae: 21.4540 - val_loss: 530.0577 - val_mae: 21.3883\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 538.4194 - mae: 21.4416 - val_loss: 529.5645 - val_mae: 21.3757\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.9268 - mae: 21.4289 - val_loss: 529.0817 - val_mae: 21.3633\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 537.4438 - mae: 21.4163 - val_loss: 528.6006 - val_mae: 21.3509\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.9626 - mae: 21.4041 - val_loss: 528.1226 - val_mae: 21.3386\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.4842 - mae: 21.3918 - val_loss: 527.6442 - val_mae: 21.3262\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 536.0053 - mae: 21.3796 - val_loss: 527.1688 - val_mae: 21.3139\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 535.5300 - mae: 21.3672 - val_loss: 526.6979 - val_mae: 21.3016\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 535.0582 - mae: 21.3551 - val_loss: 526.2206 - val_mae: 21.2891\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 534.5812 - mae: 21.3426 - val_loss: 525.7540 - val_mae: 21.2769\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 534.1146 - mae: 21.3303 - val_loss: 525.2921 - val_mae: 21.2647\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 533.6520 - mae: 21.3182 - val_loss: 524.8285 - val_mae: 21.2525\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 533.1885 - mae: 21.3059 - val_loss: 524.3723 - val_mae: 21.2404\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.7324 - mae: 21.2937 - val_loss: 523.9205 - val_mae: 21.2284\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 532.2801 - mae: 21.2819 - val_loss: 523.4695 - val_mae: 21.2164\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.8288 - mae: 21.2698 - val_loss: 523.0202 - val_mae: 21.2044\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 531.3795 - mae: 21.2578 - val_loss: 522.5746 - val_mae: 21.1924\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.9337 - mae: 21.2458 - val_loss: 522.1333 - val_mae: 21.1806\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.4922 - mae: 21.2340 - val_loss: 521.6928 - val_mae: 21.1687\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 530.0510 - mae: 21.2223 - val_loss: 521.2531 - val_mae: 21.1568\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.6111 - mae: 21.2103 - val_loss: 520.8166 - val_mae: 21.1449\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 529.1746 - mae: 21.1985 - val_loss: 520.3850 - val_mae: 21.1332\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 528.7430 - mae: 21.1867 - val_loss: 519.9573 - val_mae: 21.1215\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 528.3147 - mae: 21.1751 - val_loss: 519.5287 - val_mae: 21.1097\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 527.8859 - mae: 21.1633 - val_loss: 519.1035 - val_mae: 21.0980\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 527.4604 - mae: 21.1518 - val_loss: 518.6786 - val_mae: 21.0863\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 527.0358 - mae: 21.1399 - val_loss: 518.2628 - val_mae: 21.0748\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 526.6191 - mae: 21.1285 - val_loss: 517.8434 - val_mae: 21.0631\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 526.1998 - mae: 21.1167 - val_loss: 517.4304 - val_mae: 21.0516\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 525.7867 - mae: 21.1052 - val_loss: 517.0223 - val_mae: 21.0402\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 525.3784 - mae: 21.0940 - val_loss: 516.6146 - val_mae: 21.0288\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 524.9705 - mae: 21.0824 - val_loss: 516.2115 - val_mae: 21.0174\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 524.5668 - mae: 21.0711 - val_loss: 515.8052 - val_mae: 21.0059\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 524.1603 - mae: 21.0597 - val_loss: 515.4044 - val_mae: 20.9946\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 523.7595 - mae: 21.0483 - val_loss: 515.0099 - val_mae: 20.9834\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 523.3641 - mae: 21.0373 - val_loss: 514.6099 - val_mae: 20.9720\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 522.9645 - mae: 21.0258 - val_loss: 514.2198 - val_mae: 20.9608\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 522.5738 - mae: 21.0147 - val_loss: 513.8290 - val_mae: 20.9496\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 522.1828 - mae: 21.0035 - val_loss: 513.4423 - val_mae: 20.9385\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 521.7961 - mae: 20.9925 - val_loss: 513.0589 - val_mae: 20.9274\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 521.4121 - mae: 20.9813 - val_loss: 512.6765 - val_mae: 20.9163\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 521.0294 - mae: 20.9703 - val_loss: 512.2965 - val_mae: 20.9053\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 520.6490 - mae: 20.9592 - val_loss: 511.9178 - val_mae: 20.8943\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 520.2703 - mae: 20.9481 - val_loss: 511.5426 - val_mae: 20.8833\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 519.8946 - mae: 20.9371 - val_loss: 511.1669 - val_mae: 20.8723\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 519.5192 - mae: 20.9258 - val_loss: 510.8015 - val_mae: 20.8615\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 519.1533 - mae: 20.9154 - val_loss: 510.4357 - val_mae: 20.8507\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 518.7866 - mae: 20.9047 - val_loss: 510.0643 - val_mae: 20.8397\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 518.4152 - mae: 20.8936 - val_loss: 509.6985 - val_mae: 20.8294\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 518.0488 - mae: 20.8830 - val_loss: 509.3326 - val_mae: 20.8193\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 517.6828 - mae: 20.8722 - val_loss: 508.9731 - val_mae: 20.8094\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 517.3233 - mae: 20.8613 - val_loss: 508.6185 - val_mae: 20.7995\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 516.9683 - mae: 20.8508 - val_loss: 508.2652 - val_mae: 20.7897\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 516.6147 - mae: 20.8403 - val_loss: 507.9152 - val_mae: 20.7799\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 516.2642 - mae: 20.8299 - val_loss: 507.5661 - val_mae: 20.7701\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 515.9149 - mae: 20.8194 - val_loss: 507.2193 - val_mae: 20.7603\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 515.5682 - mae: 20.8090 - val_loss: 506.8759 - val_mae: 20.7506\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 515.2238 - mae: 20.7987 - val_loss: 506.5304 - val_mae: 20.7408\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 514.8777 - mae: 20.7882 - val_loss: 506.1839 - val_mae: 20.7310\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 514.5313 - mae: 20.7775 - val_loss: 505.8448 - val_mae: 20.7213\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 514.1923 - mae: 20.7671 - val_loss: 505.5109 - val_mae: 20.7118\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 513.8576 - mae: 20.7570 - val_loss: 505.1737 - val_mae: 20.7021\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 513.5206 - mae: 20.7465 - val_loss: 504.8447 - val_mae: 20.6926\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 513.1909 - mae: 20.7365 - val_loss: 504.5138 - val_mae: 20.6831\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 512.8597 - mae: 20.7262 - val_loss: 504.1849 - val_mae: 20.6735\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 512.5306 - mae: 20.7160 - val_loss: 503.8581 - val_mae: 20.6640\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 512.2036 - mae: 20.7057 - val_loss: 503.5362 - val_mae: 20.6547\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=5, model__optimizer=nesterov; total time=   2.6s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 436.2610 - mae: 17.1696 - val_loss: 240.3051 - val_mae: 12.8341\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 306.2765 - mae: 13.9760 - val_loss: 188.7251 - val_mae: 10.9857\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 253.6181 - mae: 12.2094 - val_loss: 153.4293 - val_mae: 9.4771\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 219.2367 - mae: 10.9914 - val_loss: 133.6079 - val_mae: 8.4339\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.4752 - mae: 10.4116 - val_loss: 122.3226 - val_mae: 7.9550\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 188.1859 - mae: 9.8587 - val_loss: 114.2818 - val_mae: 7.4835\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 182.4386 - mae: 9.4785 - val_loss: 110.4159 - val_mae: 7.3224\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 175.9230 - mae: 9.3320 - val_loss: 105.8070 - val_mae: 7.1012\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 172.0093 - mae: 9.2489 - val_loss: 103.4409 - val_mae: 6.9239\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 168.8444 - mae: 9.1143 - val_loss: 100.3184 - val_mae: 6.7781\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 165.3070 - mae: 8.7943 - val_loss: 102.8560 - val_mae: 7.0878\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 164.3150 - mae: 8.8893 - val_loss: 98.4123 - val_mae: 6.6706\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 162.6736 - mae: 8.6556 - val_loss: 100.7813 - val_mae: 6.9523\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 163.8890 - mae: 9.1102 - val_loss: 96.6722 - val_mae: 6.4352\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 164.1458 - mae: 8.7100 - val_loss: 101.9873 - val_mae: 7.0897\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 161.2532 - mae: 8.7380 - val_loss: 96.1579 - val_mae: 6.4395\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 160.5846 - mae: 8.5388 - val_loss: 97.7196 - val_mae: 6.6540\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 159.6262 - mae: 8.6607 - val_loss: 96.8083 - val_mae: 6.5456\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 160.8710 - mae: 8.5406 - val_loss: 102.6090 - val_mae: 7.1684\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 162.6522 - mae: 8.8904 - val_loss: 94.9553 - val_mae: 6.2996\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 161.1060 - mae: 8.8010 - val_loss: 94.8598 - val_mae: 6.2872\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 157.9213 - mae: 8.3959 - val_loss: 97.3811 - val_mae: 6.6008\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 157.9643 - mae: 8.4961 - val_loss: 97.4171 - val_mae: 6.6380\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 157.0471 - mae: 8.6322 - val_loss: 94.0896 - val_mae: 6.2035\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 157.0734 - mae: 8.5148 - val_loss: 93.7252 - val_mae: 6.1476\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 155.3790 - mae: 8.2879 - val_loss: 98.5383 - val_mae: 6.8036\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 155.5249 - mae: 8.4342 - val_loss: 95.0503 - val_mae: 6.3593\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 153.7712 - mae: 8.3298 - val_loss: 94.2172 - val_mae: 6.2377\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 152.8188 - mae: 8.2407 - val_loss: 95.9302 - val_mae: 6.4910\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 152.1512 - mae: 8.1879 - val_loss: 93.5652 - val_mae: 6.1571\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 151.6739 - mae: 8.2340 - val_loss: 93.2254 - val_mae: 6.0991\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 150.7817 - mae: 7.9673 - val_loss: 96.4819 - val_mae: 6.5402\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 151.0146 - mae: 8.3539 - val_loss: 94.4532 - val_mae: 6.2349\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 149.5632 - mae: 8.1058 - val_loss: 93.8885 - val_mae: 6.2264\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 149.9489 - mae: 8.0132 - val_loss: 96.7223 - val_mae: 6.5732\n",
      "Epoch 35: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=125, model__optimizer=adam; total time=   1.1s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 469.7854 - mae: 17.4296 - val_loss: 230.4288 - val_mae: 12.5424\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 305.9581 - mae: 13.7904 - val_loss: 174.3458 - val_mae: 10.4142\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 252.7470 - mae: 12.1651 - val_loss: 138.3891 - val_mae: 8.8662\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 222.7653 - mae: 11.1169 - val_loss: 129.2147 - val_mae: 8.4229\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 211.8480 - mae: 10.7301 - val_loss: 122.2968 - val_mae: 8.0286\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 206.9807 - mae: 10.6459 - val_loss: 114.2614 - val_mae: 7.4879\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 201.8904 - mae: 10.0793 - val_loss: 115.8946 - val_mae: 7.6870\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 198.1590 - mae: 10.1199 - val_loss: 113.4019 - val_mae: 7.5223\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 193.7534 - mae: 10.0166 - val_loss: 105.0606 - val_mae: 6.9942\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 187.7164 - mae: 9.8666 - val_loss: 101.9494 - val_mae: 6.9009\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 179.9484 - mae: 9.4023 - val_loss: 101.1439 - val_mae: 7.0669\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 175.9591 - mae: 9.2842 - val_loss: 97.5249 - val_mae: 6.8021\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 173.1281 - mae: 9.2759 - val_loss: 96.6472 - val_mae: 6.7375\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 171.9789 - mae: 9.2613 - val_loss: 92.1730 - val_mae: 6.2660\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 171.2240 - mae: 8.8902 - val_loss: 101.0176 - val_mae: 7.1581\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 170.3322 - mae: 9.2259 - val_loss: 91.0288 - val_mae: 6.1402\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 169.5359 - mae: 8.7628 - val_loss: 97.4526 - val_mae: 6.9679\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 165.8624 - mae: 9.0514 - val_loss: 89.8362 - val_mae: 6.2195\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 164.1030 - mae: 8.6610 - val_loss: 97.6001 - val_mae: 7.0048\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 164.6709 - mae: 8.8721 - val_loss: 89.2369 - val_mae: 6.2289\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 164.5602 - mae: 9.1388 - val_loss: 86.3462 - val_mae: 5.9694\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 159.1695 - mae: 8.4325 - val_loss: 93.4160 - val_mae: 6.7597\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 157.6834 - mae: 8.5884 - val_loss: 86.2604 - val_mae: 6.1924\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 152.6991 - mae: 8.6351 - val_loss: 80.3374 - val_mae: 5.6794\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 151.5680 - mae: 8.3151 - val_loss: 80.3408 - val_mae: 5.7196\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 148.3921 - mae: 8.0960 - val_loss: 85.7387 - val_mae: 6.2987\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 148.6147 - mae: 8.2586 - val_loss: 80.7801 - val_mae: 5.8105\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 146.0730 - mae: 8.1283 - val_loss: 82.2782 - val_mae: 5.9181\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 144.4679 - mae: 7.9782 - val_loss: 82.9920 - val_mae: 6.0313\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 143.5081 - mae: 7.9406 - val_loss: 83.3599 - val_mae: 6.0679\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 143.2044 - mae: 8.0252 - val_loss: 80.0165 - val_mae: 5.6768\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 141.7290 - mae: 7.7838 - val_loss: 84.4417 - val_mae: 6.1799\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 141.1660 - mae: 8.1233 - val_loss: 79.1037 - val_mae: 5.5439\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 137.5616 - mae: 7.6169 - val_loss: 86.1829 - val_mae: 6.3149\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 143.5565 - mae: 8.0161 - val_loss: 84.3184 - val_mae: 6.1738\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 141.0122 - mae: 8.1437 - val_loss: 81.7731 - val_mae: 5.7056\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 138.7849 - mae: 7.9265 - val_loss: 79.5655 - val_mae: 5.5047\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 136.6149 - mae: 7.5594 - val_loss: 83.0631 - val_mae: 6.0295\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 132.5578 - mae: 7.4787 - val_loss: 78.5130 - val_mae: 5.4514\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 132.0563 - mae: 7.3558 - val_loss: 85.9419 - val_mae: 6.3690\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 132.3186 - mae: 7.5648 - val_loss: 79.5159 - val_mae: 5.5503\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 130.2502 - mae: 7.4683 - val_loss: 79.8865 - val_mae: 5.5234\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 129.3451 - mae: 7.3340 - val_loss: 80.5043 - val_mae: 5.7770\n",
      "Epoch 43: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=125, model__optimizer=adam; total time=   1.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 16875]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 415.9501 - mae: 16.8006 - val_loss: 315.6375 - val_mae: 14.5705\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 290.8422 - mae: 13.7118 - val_loss: 251.0947 - val_mae: 12.4354\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 235.0567 - mae: 11.8096 - val_loss: 206.8299 - val_mae: 11.0135\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 200.0186 - mae: 10.5398 - val_loss: 180.7345 - val_mae: 9.8961\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 185.0271 - mae: 10.0321 - val_loss: 163.4297 - val_mae: 9.2796\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 170.0770 - mae: 9.2665 - val_loss: 148.9133 - val_mae: 8.7925\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 157.4335 - mae: 8.9070 - val_loss: 135.3117 - val_mae: 8.2606\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 145.2966 - mae: 8.6148 - val_loss: 126.5148 - val_mae: 7.9081\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 140.4499 - mae: 7.9946 - val_loss: 124.5349 - val_mae: 7.7969\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 136.9805 - mae: 8.1307 - val_loss: 122.0147 - val_mae: 7.6114\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 134.8375 - mae: 7.8427 - val_loss: 119.6326 - val_mae: 7.5121\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 131.3354 - mae: 7.7494 - val_loss: 115.0848 - val_mae: 7.3069\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 128.0168 - mae: 7.5907 - val_loss: 114.1124 - val_mae: 7.2486\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 127.3116 - mae: 7.4974 - val_loss: 114.2138 - val_mae: 7.1972\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.4469 - mae: 7.5710 - val_loss: 112.8205 - val_mae: 7.1303\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 125.8614 - mae: 7.3762 - val_loss: 112.1054 - val_mae: 7.0519\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.6308 - mae: 7.4887 - val_loss: 114.3224 - val_mae: 7.2076\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 127.0419 - mae: 7.5090 - val_loss: 110.8889 - val_mae: 7.0112\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 126.3532 - mae: 7.3559 - val_loss: 113.3411 - val_mae: 7.1322\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 124.5323 - mae: 7.4718 - val_loss: 109.9774 - val_mae: 6.9634\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 122.9897 - mae: 7.3883 - val_loss: 109.6259 - val_mae: 6.9661\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 121.4851 - mae: 7.0473 - val_loss: 109.6749 - val_mae: 6.9383\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 123.4319 - mae: 7.2883 - val_loss: 109.4547 - val_mae: 6.8731\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 121.7934 - mae: 7.2475 - val_loss: 107.3062 - val_mae: 6.7921\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 119.8327 - mae: 7.2932 - val_loss: 107.8168 - val_mae: 6.9080\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.5321 - mae: 7.0268 - val_loss: 109.4976 - val_mae: 6.9340\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 119.0331 - mae: 7.1963 - val_loss: 106.4348 - val_mae: 6.7833\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 118.3264 - mae: 7.0331 - val_loss: 105.0805 - val_mae: 6.6986\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 117.1489 - mae: 6.9017 - val_loss: 104.5922 - val_mae: 6.6469\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.8718 - mae: 6.8436 - val_loss: 103.8778 - val_mae: 6.6166\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 115.7677 - mae: 6.9997 - val_loss: 107.5302 - val_mae: 6.9477\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 116.2291 - mae: 6.9259 - val_loss: 103.8850 - val_mae: 6.5953\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 114.9682 - mae: 6.8566 - val_loss: 102.6050 - val_mae: 6.5524\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 113.7384 - mae: 6.7665 - val_loss: 103.0419 - val_mae: 6.6480\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.9905 - mae: 6.7271 - val_loss: 101.5134 - val_mae: 6.4784\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 112.9326 - mae: 6.7026 - val_loss: 101.2122 - val_mae: 6.4452\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 112.5463 - mae: 6.7975 - val_loss: 103.7286 - val_mae: 6.7247\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 113.6437 - mae: 6.8533 - val_loss: 106.6944 - val_mae: 6.9316\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 114.9784 - mae: 6.9682 - val_loss: 101.1655 - val_mae: 6.5939\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 108.6057 - mae: 6.5350 - val_loss: 96.6066 - val_mae: 6.2971\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.6888 - mae: 6.6159 - val_loss: 97.8663 - val_mae: 6.3329\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 107.6386 - mae: 6.5992 - val_loss: 97.7557 - val_mae: 6.3131\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 108.5958 - mae: 6.8082 - val_loss: 97.5305 - val_mae: 6.4233\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 106.5668 - mae: 6.5159 - val_loss: 95.4467 - val_mae: 6.2470\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 104.8349 - mae: 6.3920 - val_loss: 94.5857 - val_mae: 6.1278\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 105.2805 - mae: 6.4761 - val_loss: 95.7147 - val_mae: 6.2644\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.4966 - mae: 6.6001 - val_loss: 101.0624 - val_mae: 6.7132\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.3928 - mae: 6.6173 - val_loss: 96.8106 - val_mae: 6.3866\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.9035 - mae: 6.4994 - val_loss: 101.1048 - val_mae: 6.7370\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 105.1570 - mae: 6.4580 - val_loss: 97.4474 - val_mae: 6.4392\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.4771 - mae: 6.3519 - val_loss: 96.2040 - val_mae: 6.3228\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.5168 - mae: 6.3449 - val_loss: 94.1520 - val_mae: 6.1115\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 103.8620 - mae: 6.3695 - val_loss: 93.4633 - val_mae: 6.0028\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.4329 - mae: 6.2642 - val_loss: 94.3221 - val_mae: 6.1026\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 104.7009 - mae: 6.5102 - val_loss: 93.0961 - val_mae: 5.9662\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.7707 - mae: 6.3316 - val_loss: 93.3580 - val_mae: 6.0146\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.1742 - mae: 6.2648 - val_loss: 94.5735 - val_mae: 6.1422\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.1245 - mae: 6.2044 - val_loss: 94.9212 - val_mae: 6.1815\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.4496 - mae: 6.1988 - val_loss: 92.6495 - val_mae: 5.9161\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 99.8534 - mae: 6.1942 - val_loss: 95.4781 - val_mae: 6.2300\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 100.7262 - mae: 6.2397 - val_loss: 94.7727 - val_mae: 6.1716\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.7726 - mae: 6.3130 - val_loss: 100.1114 - val_mae: 6.6398\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.3085 - mae: 6.3297 - val_loss: 95.5079 - val_mae: 6.2370\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 102.1925 - mae: 6.3191 - val_loss: 92.3768 - val_mae: 5.8468\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 101.8408 - mae: 6.2891 - val_loss: 92.6532 - val_mae: 5.9320\n",
      "Epoch 65: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=3, model__n_neurons=125, model__optimizer=adam; total time=   2.0s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 16750]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 2186.4521 - mae: 29.8714 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7147 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.7146 - mae: 22.7033 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=nesterov; total time=   0.5s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 1s - loss: 23461.8613 - mae: 107.5405"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 3651.9534 - mae: 34.1740 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.3428 - mae: 23.1231 - val_loss: 449.3011 - val_mae: 20.2778\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 498us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=nesterov; total time=   0.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 675]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 4612.2666 - mae: 36.2953 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2674 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 755us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.1, model__n_hidden=1, model__n_neurons=5, model__optimizer=nesterov; total time=   0.4s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 10ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 670]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=0, model__n_neurons=25, model__optimizer=adam; total time=   0.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 754us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=0, model__n_neurons=25, model__optimizer=adam; total time=   0.3s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.9, model__n_hidden=0, model__n_neurons=25, model__optimizer=adam; total time=   0.3s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8679 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2227 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23399.2207 - mae: 72.8680 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=0, model__n_neurons=125, model__optimizer=momentum; total time=   0.5s\n",
      "Epoch 1/100\n",
      "8/8 [==============================] - 0s 11ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9844 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9785 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23112.9805 - mae: 72.6047 - val_loss: 24142.5352 - val_mae: 71.7670\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=0, model__n_neurons=125, model__optimizer=momentum; total time=   0.4s\n",
      "Epoch 1/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 21635.4844 - mae: 71.4221"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 1755]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 11ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8281 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8223 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 23041.8242 - mae: 71.6140 - val_loss: 23629.0898 - val_mae: 73.5344\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.0001, model__momentum=0.9, model__n_hidden=0, model__n_neurons=125, model__optimizer=momentum; total time=   0.4s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 1742]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 13ms/step - loss: 134275.8281 - mae: 104.7854 - val_loss: 449.2911 - val_mae: 20.2775\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.6913 - mae: 22.7028 - val_loss: 449.2650 - val_mae: 20.2769\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.6620 - mae: 22.7021 - val_loss: 449.2390 - val_mae: 20.2762\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.6331 - mae: 22.7015 - val_loss: 449.2128 - val_mae: 20.2756\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.6036 - mae: 22.7009 - val_loss: 449.1867 - val_mae: 20.2750\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.5746 - mae: 22.7002 - val_loss: 449.1609 - val_mae: 20.2743\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.5456 - mae: 22.6996 - val_loss: 449.1350 - val_mae: 20.2737\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.5167 - mae: 22.6989 - val_loss: 449.1091 - val_mae: 20.2730\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.4876 - mae: 22.6983 - val_loss: 449.0830 - val_mae: 20.2724\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.4584 - mae: 22.6976 - val_loss: 449.0572 - val_mae: 20.2717\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 598.4295 - mae: 22.6970 - val_loss: 449.0315 - val_mae: 20.2711\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 757us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   0.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 1143.4994 - mae: 26.2249 - val_loss: 449.2441 - val_mae: 20.2764\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.2029 - mae: 23.1201 - val_loss: 449.0848 - val_mae: 20.2724\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 637.0211 - mae: 23.1162 - val_loss: 448.9246 - val_mae: 20.2685\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.8381 - mae: 23.1122 - val_loss: 448.7645 - val_mae: 20.2645\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.6558 - mae: 23.1083 - val_loss: 448.6053 - val_mae: 20.2606\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.4747 - mae: 23.1043 - val_loss: 448.4471 - val_mae: 20.2567\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.2944 - mae: 23.1004 - val_loss: 448.2894 - val_mae: 20.2528\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 636.1147 - mae: 23.0966 - val_loss: 448.1312 - val_mae: 20.2488\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.9337 - mae: 23.0926 - val_loss: 447.9721 - val_mae: 20.2449\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.7521 - mae: 23.0886 - val_loss: 447.8133 - val_mae: 20.2410\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.5712 - mae: 23.0847 - val_loss: 447.6560 - val_mae: 20.2370\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.3920 - mae: 23.0808 - val_loss: 447.4983 - val_mae: 20.2331\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.2117 - mae: 23.0769 - val_loss: 447.3406 - val_mae: 20.2292\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 635.0320 - mae: 23.0730 - val_loss: 447.1839 - val_mae: 20.2253\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.8533 - mae: 23.0691 - val_loss: 447.0268 - val_mae: 20.2214\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.6737 - mae: 23.0651 - val_loss: 446.8701 - val_mae: 20.2175\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.4949 - mae: 23.0613 - val_loss: 446.7129 - val_mae: 20.2135\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.3154 - mae: 23.0573 - val_loss: 446.5567 - val_mae: 20.2096\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 634.1373 - mae: 23.0535 - val_loss: 446.4004 - val_mae: 20.2057\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.9586 - mae: 23.0495 - val_loss: 446.2446 - val_mae: 20.2018\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.7808 - mae: 23.0456 - val_loss: 446.0892 - val_mae: 20.1979\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.6035 - mae: 23.0417 - val_loss: 445.9345 - val_mae: 20.1940\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.4268 - mae: 23.0378 - val_loss: 445.7794 - val_mae: 20.1902\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.2495 - mae: 23.0339 - val_loss: 445.6234 - val_mae: 20.1862\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 633.0711 - mae: 23.0300 - val_loss: 445.4688 - val_mae: 20.1823\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.8948 - mae: 23.0261 - val_loss: 445.3143 - val_mae: 20.1785\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.7184 - mae: 23.0222 - val_loss: 445.1617 - val_mae: 20.1746\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.5446 - mae: 23.0184 - val_loss: 445.0090 - val_mae: 20.1708\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.3697 - mae: 23.0145 - val_loss: 444.8561 - val_mae: 20.1669\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.1948 - mae: 23.0107 - val_loss: 444.7031 - val_mae: 20.1630\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 632.0200 - mae: 23.0068 - val_loss: 444.5514 - val_mae: 20.1592\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.8466 - mae: 23.0030 - val_loss: 444.3979 - val_mae: 20.1553\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.6705 - mae: 22.9991 - val_loss: 444.2448 - val_mae: 20.1515\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.4958 - mae: 22.9952 - val_loss: 444.0925 - val_mae: 20.1476\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.3216 - mae: 22.9914 - val_loss: 443.9397 - val_mae: 20.1437\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 631.1467 - mae: 22.9875 - val_loss: 443.7874 - val_mae: 20.1399\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.9728 - mae: 22.9836 - val_loss: 443.6365 - val_mae: 20.1360\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.8005 - mae: 22.9798 - val_loss: 443.4861 - val_mae: 20.1322\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.6284 - mae: 22.9760 - val_loss: 443.3352 - val_mae: 20.1284\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.4556 - mae: 22.9722 - val_loss: 443.1842 - val_mae: 20.1245\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.2827 - mae: 22.9683 - val_loss: 443.0334 - val_mae: 20.1207\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 630.1104 - mae: 22.9644 - val_loss: 442.8832 - val_mae: 20.1169\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.9385 - mae: 22.9607 - val_loss: 442.7332 - val_mae: 20.1130\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.7665 - mae: 22.9568 - val_loss: 442.5828 - val_mae: 20.1092\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.5947 - mae: 22.9529 - val_loss: 442.4332 - val_mae: 20.1054\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.4236 - mae: 22.9492 - val_loss: 442.2846 - val_mae: 20.1016\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.2535 - mae: 22.9453 - val_loss: 442.1366 - val_mae: 20.0978\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 629.0840 - mae: 22.9416 - val_loss: 441.9873 - val_mae: 20.0940\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.9125 - mae: 22.9378 - val_loss: 441.8373 - val_mae: 20.0901\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.7408 - mae: 22.9339 - val_loss: 441.6892 - val_mae: 20.0863\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 628.5716 - mae: 22.9301 - val_loss: 441.5411 - val_mae: 20.0825\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.4017 - mae: 22.9263 - val_loss: 441.3929 - val_mae: 20.0787\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.2318 - mae: 22.9225 - val_loss: 441.2449 - val_mae: 20.0749\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 628.0625 - mae: 22.9187 - val_loss: 441.0981 - val_mae: 20.0711\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.8943 - mae: 22.9149 - val_loss: 440.9503 - val_mae: 20.0673\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.7245 - mae: 22.9111 - val_loss: 440.8025 - val_mae: 20.0635\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.5553 - mae: 22.9073 - val_loss: 440.6555 - val_mae: 20.0597\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.3870 - mae: 22.9035 - val_loss: 440.5090 - val_mae: 20.0559\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.2189 - mae: 22.8998 - val_loss: 440.3617 - val_mae: 20.0521\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 627.0496 - mae: 22.8959 - val_loss: 440.2144 - val_mae: 20.0483\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.8811 - mae: 22.8921 - val_loss: 440.0686 - val_mae: 20.0445\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.7142 - mae: 22.8883 - val_loss: 439.9233 - val_mae: 20.0408\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.5477 - mae: 22.8846 - val_loss: 439.7781 - val_mae: 20.0370\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.3809 - mae: 22.8808 - val_loss: 439.6328 - val_mae: 20.0332\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.2145 - mae: 22.8771 - val_loss: 439.4885 - val_mae: 20.0295\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 626.0488 - mae: 22.8733 - val_loss: 439.3433 - val_mae: 20.0257\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.8821 - mae: 22.8695 - val_loss: 439.1994 - val_mae: 20.0220\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.7172 - mae: 22.8658 - val_loss: 439.0544 - val_mae: 20.0182\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.5505 - mae: 22.8620 - val_loss: 438.9099 - val_mae: 20.0144\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.3848 - mae: 22.8583 - val_loss: 438.7658 - val_mae: 20.0107\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.2196 - mae: 22.8544 - val_loss: 438.6229 - val_mae: 20.0069\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 625.0557 - mae: 22.8508 - val_loss: 438.4793 - val_mae: 20.0032\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.8904 - mae: 22.8470 - val_loss: 438.3355 - val_mae: 19.9994\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.7252 - mae: 22.8433 - val_loss: 438.1915 - val_mae: 19.9957\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.5599 - mae: 22.8395 - val_loss: 438.0480 - val_mae: 19.9919\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.3953 - mae: 22.8358 - val_loss: 437.9058 - val_mae: 19.9882\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.2320 - mae: 22.8320 - val_loss: 437.7622 - val_mae: 19.9844\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 624.0668 - mae: 22.8282 - val_loss: 437.6205 - val_mae: 19.9807\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.9045 - mae: 22.8245 - val_loss: 437.4786 - val_mae: 19.9770\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.7413 - mae: 22.8207 - val_loss: 437.3365 - val_mae: 19.9732\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.5780 - mae: 22.8170 - val_loss: 437.1955 - val_mae: 19.9695\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.4163 - mae: 22.8134 - val_loss: 437.0545 - val_mae: 19.9658\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.2538 - mae: 22.8097 - val_loss: 436.9125 - val_mae: 19.9621\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 623.0906 - mae: 22.8059 - val_loss: 436.7717 - val_mae: 19.9583\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.9290 - mae: 22.8022 - val_loss: 436.6311 - val_mae: 19.9546\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.7672 - mae: 22.7985 - val_loss: 436.4909 - val_mae: 19.9509\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.6061 - mae: 22.7948 - val_loss: 436.3500 - val_mae: 19.9472\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.4438 - mae: 22.7911 - val_loss: 436.2087 - val_mae: 19.9435\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.2813 - mae: 22.7873 - val_loss: 436.0681 - val_mae: 19.9397\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 622.1199 - mae: 22.7836 - val_loss: 435.9290 - val_mae: 19.9361\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.9601 - mae: 22.7799 - val_loss: 435.7894 - val_mae: 19.9324\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.7994 - mae: 22.7762 - val_loss: 435.6501 - val_mae: 19.9287\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.6391 - mae: 22.7726 - val_loss: 435.5101 - val_mae: 19.9249\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.4778 - mae: 22.7688 - val_loss: 435.3712 - val_mae: 19.9212\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.3182 - mae: 22.7650 - val_loss: 435.2328 - val_mae: 19.9176\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 621.1592 - mae: 22.7614 - val_loss: 435.0947 - val_mae: 19.9139\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.9999 - mae: 22.7577 - val_loss: 434.9555 - val_mae: 19.9102\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.8395 - mae: 22.7540 - val_loss: 434.8175 - val_mae: 19.9065\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.6808 - mae: 22.7503 - val_loss: 434.6795 - val_mae: 19.9028\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 620.5220 - mae: 22.7467 - val_loss: 434.5426 - val_mae: 19.8991\n",
      "5/5 [==============================] - 0s 748us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   2.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [135, 3375]\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 12ms/step - loss: 51151.5938 - mae: 58.3296 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2674 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 557.2675 - mae: 21.8955 - val_loss: 548.6489 - val_mae: 21.8370\n",
      "Epoch 11: early stopping\n",
      "5/5 [==============================] - 0s 749us/step\n",
      "[CV] END model__learning_rate=0.001, model__momentum=0.1, model__n_hidden=2, model__n_neurons=25, model__optimizer=momentum; total time=   0.5s\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:776: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 429, in _passthrough_scorer\n",
      "    return estimator.score(*args, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1100, in score\n",
      "    return self.scorer(y, y_pred, sample_weight=sample_weight, **score_args)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\scikeras\\wrappers.py\", line 1697, in scorer\n",
      "    return sklearn_r2_score(y_true, y_pred, **kwargs)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 911, in r2_score\n",
      "    y_type, y_true, y_pred, multioutput = _check_reg_targets(\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_regression.py\", line 100, in _check_reg_targets\n",
      "    check_consistent_length(y_true, y_pred)\n",
      "  File \"C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 387, in check_consistent_length\n",
      "    raise ValueError(\n",
      "ValueError: Found input variables with inconsistent numbers of samples: [134, 3350]\n",
      "\n",
      "  warnings.warn(\n",
      "C:\\Users\\Justyna\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:953: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 8ms/step - loss: 817.9228 - mae: 22.9142 - val_loss: 505.7443 - val_mae: 21.5189\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 595.0746 - mae: 22.4903 - val_loss: 505.3595 - val_mae: 21.5100\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 594.5524 - mae: 22.4787 - val_loss: 504.7759 - val_mae: 21.4964\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 593.9330 - mae: 22.4648 - val_loss: 504.1537 - val_mae: 21.4819\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 593.2544 - mae: 22.4497 - val_loss: 503.4906 - val_mae: 21.4664\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 592.5570 - mae: 22.4340 - val_loss: 502.8230 - val_mae: 21.4509\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.8530 - mae: 22.4184 - val_loss: 502.1373 - val_mae: 21.4348\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 591.1281 - mae: 22.4023 - val_loss: 501.4252 - val_mae: 21.4181\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 590.3480 - mae: 22.3848 - val_loss: 500.6489 - val_mae: 21.3999\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 589.5220 - mae: 22.3662 - val_loss: 499.8268 - val_mae: 21.3806\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 588.6459 - mae: 22.3464 - val_loss: 498.9721 - val_mae: 21.3605\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 587.7319 - mae: 22.3258 - val_loss: 498.0729 - val_mae: 21.3394\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 586.7674 - mae: 22.3043 - val_loss: 497.1223 - val_mae: 21.3169\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 585.7440 - mae: 22.2810 - val_loss: 496.0987 - val_mae: 21.2927\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 584.6391 - mae: 22.2560 - val_loss: 494.9991 - val_mae: 21.2667\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 583.4491 - mae: 22.2292 - val_loss: 493.8151 - val_mae: 21.2386\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 582.1623 - mae: 22.2002 - val_loss: 492.4947 - val_mae: 21.2072\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 580.7261 - mae: 22.1673 - val_loss: 491.0827 - val_mae: 21.1735\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 579.1835 - mae: 22.1320 - val_loss: 489.5002 - val_mae: 21.1356\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 577.4520 - mae: 22.0923 - val_loss: 487.7648 - val_mae: 21.0940\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 575.5474 - mae: 22.0485 - val_loss: 485.7903 - val_mae: 21.0464\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 573.3783 - mae: 21.9992 - val_loss: 483.6102 - val_mae: 20.9936\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 570.9791 - mae: 21.9434 - val_loss: 481.1804 - val_mae: 20.9346\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 568.2998 - mae: 21.8805 - val_loss: 478.4280 - val_mae: 20.8674\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 565.2624 - mae: 21.8098 - val_loss: 475.3245 - val_mae: 20.7911\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 561.8337 - mae: 21.7290 - val_loss: 471.8319 - val_mae: 20.7047\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 557.9754 - mae: 21.6381 - val_loss: 467.9232 - val_mae: 20.6073\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 553.6531 - mae: 21.5348 - val_loss: 463.4481 - val_mae: 20.4948\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 548.7096 - mae: 21.4152 - val_loss: 458.4535 - val_mae: 20.3680\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 543.1927 - mae: 21.2829 - val_loss: 452.8622 - val_mae: 20.2243\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 537.0178 - mae: 21.1319 - val_loss: 446.5243 - val_mae: 20.0593\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 530.0292 - mae: 20.9571 - val_loss: 439.5054 - val_mae: 19.8738\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 522.3019 - mae: 20.7617 - val_loss: 431.7090 - val_mae: 19.6640\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 513.7281 - mae: 20.5397 - val_loss: 423.0082 - val_mae: 19.4251\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 504.1887 - mae: 20.2886 - val_loss: 413.5525 - val_mae: 19.1594\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 493.8490 - mae: 20.0091 - val_loss: 403.4153 - val_mae: 18.8669\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 482.7825 - mae: 19.7050 - val_loss: 392.4094 - val_mae: 18.5395\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 470.8221 - mae: 19.3631 - val_loss: 380.8871 - val_mae: 18.1849\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 458.3239 - mae: 19.0019 - val_loss: 368.6727 - val_mae: 17.7940\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 445.1406 - mae: 18.6012 - val_loss: 356.2770 - val_mae: 17.3835\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 431.7973 - mae: 18.1802 - val_loss: 343.3061 - val_mae: 16.9441\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 417.8984 - mae: 17.7159 - val_loss: 330.5260 - val_mae: 16.4914\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 404.2380 - mae: 17.2688 - val_loss: 317.9129 - val_mae: 16.0171\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 390.8103 - mae: 16.8030 - val_loss: 305.8089 - val_mae: 15.5319\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 377.9735 - mae: 16.3259 - val_loss: 294.3448 - val_mae: 15.0506\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 365.8361 - mae: 15.8546 - val_loss: 283.8658 - val_mae: 14.5874\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 354.7468 - mae: 15.4135 - val_loss: 274.0823 - val_mae: 14.1376\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 344.3847 - mae: 14.9939 - val_loss: 265.6978 - val_mae: 13.7432\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 335.5078 - mae: 14.6320 - val_loss: 258.2413 - val_mae: 13.3819\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 327.5666 - mae: 14.3203 - val_loss: 251.7741 - val_mae: 13.0488\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 320.6331 - mae: 14.0240 - val_loss: 246.3123 - val_mae: 12.7463\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 314.7253 - mae: 13.7931 - val_loss: 241.8883 - val_mae: 12.4910\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 309.8974 - mae: 13.5839 - val_loss: 238.3274 - val_mae: 12.2830\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 305.9272 - mae: 13.4257 - val_loss: 235.4434 - val_mae: 12.1263\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 302.6184 - mae: 13.2791 - val_loss: 233.2853 - val_mae: 12.0119\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 300.0945 - mae: 13.1784 - val_loss: 231.6822 - val_mae: 11.9238\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 298.1150 - mae: 13.0989 - val_loss: 230.4276 - val_mae: 11.8632\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 296.5046 - mae: 13.0513 - val_loss: 229.5808 - val_mae: 11.8332\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 295.3521 - mae: 13.0161 - val_loss: 228.9427 - val_mae: 11.8188\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 294.3945 - mae: 12.9969 - val_loss: 228.5158 - val_mae: 11.8118\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 293.7077 - mae: 12.9884 - val_loss: 228.2403 - val_mae: 11.8078\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 293.1618 - mae: 12.9903 - val_loss: 228.0856 - val_mae: 11.8047\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 292.8190 - mae: 12.9905 - val_loss: 227.9850 - val_mae: 11.8014\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 292.5060 - mae: 13.0016 - val_loss: 227.9484 - val_mae: 11.7991\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 292.3134 - mae: 13.0070 - val_loss: 227.9403 - val_mae: 11.7972\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 292.1583 - mae: 13.0115 - val_loss: 227.9590 - val_mae: 11.7949\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 292.0161 - mae: 13.0161 - val_loss: 227.9942 - val_mae: 11.7933\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 291.9218 - mae: 13.0288 - val_loss: 228.0479 - val_mae: 11.7929\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 291.8276 - mae: 13.0374 - val_loss: 228.1015 - val_mae: 11.7938\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 291.7839 - mae: 13.0371 - val_loss: 228.1542 - val_mae: 11.7955\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 291.7445 - mae: 13.0499 - val_loss: 228.1773 - val_mae: 11.7963\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 291.7362 - mae: 13.0570 - val_loss: 228.1956 - val_mae: 11.7970\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 291.7354 - mae: 13.0605 - val_loss: 228.2334 - val_mae: 11.7986\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 291.7164 - mae: 13.0637 - val_loss: 228.2560 - val_mae: 11.7996\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 291.7134 - mae: 13.0659 - val_loss: 228.2709 - val_mae: 11.8003\n",
      "Epoch 75: early stopping\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(callbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000002B0D5833EE0&gt;], model=&lt;function build_model at 0x000002B0D6B6EDC0&gt;),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={&#x27;model__learning_rate&#x27;: [1e-05, 0.0001,\n",
       "                                                                 0.001],\n",
       "                                        &#x27;model__momentum&#x27;: [0.1, 0.5, 0.9],\n",
       "                                        &#x27;model__n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;model__n_neurons&#x27;: [5, 25, 125],\n",
       "                                        &#x27;model__optimizer&#x27;: [&#x27;sgd&#x27;, &#x27;nesterov&#x27;,\n",
       "                                                             &#x27;momentum&#x27;,\n",
       "                                                             &#x27;adam&#x27;]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(callbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000002B0D5833EE0&gt;], model=&lt;function build_model at 0x000002B0D6B6EDC0&gt;),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={&#x27;model__learning_rate&#x27;: [1e-05, 0.0001,\n",
       "                                                                 0.001],\n",
       "                                        &#x27;model__momentum&#x27;: [0.1, 0.5, 0.9],\n",
       "                                        &#x27;model__n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;model__n_neurons&#x27;: [5, 25, 125],\n",
       "                                        &#x27;model__optimizer&#x27;: [&#x27;sgd&#x27;, &#x27;nesterov&#x27;,\n",
       "                                                             &#x27;momentum&#x27;,\n",
       "                                                             &#x27;adam&#x27;]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function build_model at 0x000002B0D6B6EDC0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000002B0D5833EE0&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>KerasRegressor(\n",
       "\tmodel=&lt;function build_model at 0x000002B0D6B6EDC0&gt;\n",
       "\tbuild_fn=None\n",
       "\twarm_start=False\n",
       "\trandom_state=None\n",
       "\toptimizer=rmsprop\n",
       "\tloss=None\n",
       "\tmetrics=None\n",
       "\tbatch_size=None\n",
       "\tvalidation_batch_size=None\n",
       "\tverbose=1\n",
       "\tcallbacks=[&lt;keras.callbacks.EarlyStopping object at 0x000002B0D5833EE0&gt;]\n",
       "\tvalidation_split=0.0\n",
       "\tshuffle=True\n",
       "\trun_eagerly=False\n",
       "\tepochs=1\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=KerasRegressor(callbacks=[<keras.callbacks.EarlyStopping object at 0x000002B0D5833EE0>], model=<function build_model at 0x000002B0D6B6EDC0>),\n",
       "                   n_iter=30,\n",
       "                   param_distributions={'model__learning_rate': [1e-05, 0.0001,\n",
       "                                                                 0.001],\n",
       "                                        'model__momentum': [0.1, 0.5, 0.9],\n",
       "                                        'model__n_hidden': [0, 1, 2, 3],\n",
       "                                        'model__n_neurons': [5, 25, 125],\n",
       "                                        'model__optimizer': ['sgd', 'nesterov',\n",
       "                                                             'momentum',\n",
       "                                                             'adam']},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg,\n",
    "param_distribs,\n",
    "n_iter=30,\n",
    "cv=3,\n",
    "verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a49ec2b-25b3-4be2-86cb-ffc3cfd404a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__optimizer': 'sgd',\n",
       " 'model__n_neurons': 25,\n",
       " 'model__n_hidden': 3,\n",
       " 'model__momentum': 0.9,\n",
       " 'model__learning_rate': 0.001}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp = rnd_search_cv.best_params_\n",
    "bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c40c9d49-6b67-482f-a1cb-289cb69f9ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "f6 = open(\"rnd_search.pkl\", \"wb\")\n",
    "pickle.dump(bp, f6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae376812-ff4e-4995-9ae7-7c16fe804b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
